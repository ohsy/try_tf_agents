2024-11-12 20:32:12.558799: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/yoh/tf_venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(
online arguments=['play_mini.py', '-e', 'Reacher-v2_discrete', '-a', 'CDQN_multiagent', '-n', '3']
2024-11-12 20:32:17,320 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 10000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 256, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 256, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-12 20:32:17,320 - INFO - args=Namespace(environment='Reacher-v2_discrete', environment_wrapper=None, agent='CDQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3, num_init_collect_steps=None)
2024-11-12 20:32:17,320 - INFO - environment=Reacher-v2_discrete
2024-11-12 20:32:17,320 - INFO - envWrapper=None
2024-11-12 20:32:17,320 - INFO - agent=CDQN_multiagent
objc[19728]: Class GLFWApplicationDelegate is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x134ff5778) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13964f7e8). One of the two will be used. Which one is undefined.
objc[19728]: Class GLFWWindowDelegate is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x134ff5700) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13964f810). One of the two will be used. Which one is undefined.
objc[19728]: Class GLFWContentView is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x134ff57a0) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13964f860). One of the two will be used. Which one is undefined.
objc[19728]: Class GLFWWindow is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x134ff5818) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13964f8d8). One of the two will be used. Which one is undefined.
2024-11-12 20:32:17,797 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))
2024-11-12 20:32:17,797 - INFO - tf_action_spec: BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))
2024-11-12 20:32:17,798 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))})
2024-11-12 20:32:18,226 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308)),
 'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-12 20:32:18,578 - WARNING - From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-12 20:32:22,393 - INFO - random_policy avg_return=-74.14368438720703
2024-11-12 20:32:22,393 - INFO - replay_buffer.capacity=256
2024-11-12 20:32:22,398 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-12 20:32:24,456 - INFO - after filling with random_policies, replay_buffer.num_frames()=256
2024-11-12 20:32:34,896 - INFO - before training, avg_return=-61.8564338684082
WARNING:tensorflow:From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-12 20:32:35,135 - WARNING - From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-12 20:32:51,467 - INFO - train_step=40 loss=7.474 time=16.570
2024-11-12 20:32:54,155 - INFO - train_step=80 loss=7.540 time=2.688
2024-11-12 20:32:56,757 - INFO - train_step=120 loss=7.245 time=2.602
2024-11-12 20:32:59,417 - INFO - train_step=160 loss=7.016 time=2.660
2024-11-12 20:33:02,001 - INFO - train_step=200 loss=6.943 time=2.583
2024-11-12 20:33:12,795 - INFO - train_step=200 avg_return=-11.525
2024-11-12 20:33:15,180 - INFO - train_step=240 loss=6.343 time=13.180
2024-11-12 20:33:17,838 - INFO - train_step=280 loss=7.140 time=2.658
2024-11-12 20:33:20,529 - INFO - train_step=320 loss=6.933 time=2.691
2024-11-12 20:33:23,216 - INFO - train_step=360 loss=7.259 time=2.687
2024-11-12 20:33:25,844 - INFO - train_step=400 loss=6.995 time=2.628
2024-11-12 20:33:37,366 - INFO - train_step=400 avg_return=-12.092
2024-11-12 20:33:39,921 - INFO - train_step=440 loss=6.849 time=14.077
2024-11-12 20:33:42,648 - INFO - train_step=480 loss=6.650 time=2.727
2024-11-12 20:33:45,845 - INFO - train_step=520 loss=6.838 time=3.196
2024-11-12 20:33:48,877 - INFO - train_step=560 loss=6.756 time=3.033
2024-11-12 20:33:51,700 - INFO - train_step=600 loss=6.688 time=2.823
2024-11-12 20:34:04,961 - INFO - train_step=600 avg_return=-12.351
2024-11-12 20:34:08,440 - INFO - train_step=640 loss=6.500 time=16.739
2024-11-12 20:34:11,525 - INFO - train_step=680 loss=6.499 time=3.085
2024-11-12 20:34:14,891 - INFO - train_step=720 loss=6.565 time=3.366
2024-11-12 20:34:18,005 - INFO - train_step=760 loss=6.451 time=3.114
2024-11-12 20:34:20,804 - INFO - train_step=800 loss=6.484 time=2.800
2024-11-12 20:34:32,443 - INFO - train_step=800 avg_return=-30.987
2024-11-12 20:34:34,913 - INFO - train_step=840 loss=6.486 time=14.109
2024-11-12 20:34:37,512 - INFO - train_step=880 loss=6.421 time=2.599
2024-11-12 20:34:40,174 - INFO - train_step=920 loss=6.524 time=2.662
2024-11-12 20:34:42,762 - INFO - train_step=960 loss=6.960 time=2.588
2024-11-12 20:34:45,374 - INFO - train_step=1000 loss=6.705 time=2.611
2024-11-12 20:34:56,380 - INFO - train_step=1000 avg_return=-17.452
2024-11-12 20:34:58,661 - INFO - train_step=1040 loss=6.730 time=13.287
2024-11-12 20:35:01,272 - INFO - train_step=1080 loss=6.631 time=2.611
2024-11-12 20:35:04,117 - INFO - train_step=1120 loss=6.180 time=2.846
2024-11-12 20:35:06,736 - INFO - train_step=1160 loss=6.136 time=2.618
2024-11-12 20:35:09,715 - INFO - train_step=1200 loss=6.041 time=2.979
2024-11-12 20:35:20,848 - INFO - train_step=1200 avg_return=-12.968
2024-11-12 20:35:23,106 - INFO - train_step=1240 loss=5.899 time=13.391
2024-11-12 20:35:25,876 - INFO - train_step=1280 loss=5.838 time=2.770
2024-11-12 20:35:28,502 - INFO - train_step=1320 loss=6.535 time=2.626
2024-11-12 20:35:31,190 - INFO - train_step=1360 loss=6.388 time=2.688
2024-11-12 20:35:34,629 - INFO - train_step=1400 loss=6.114 time=3.439
2024-11-12 20:35:48,271 - INFO - train_step=1400 avg_return=-18.735
2024-11-12 20:35:50,670 - INFO - train_step=1440 loss=6.242 time=16.041
2024-11-12 20:35:53,364 - INFO - train_step=1480 loss=6.628 time=2.694
2024-11-12 20:35:56,229 - INFO - train_step=1520 loss=6.743 time=2.864
2024-11-12 20:35:58,877 - INFO - train_step=1560 loss=6.600 time=2.649
2024-11-12 20:36:01,745 - INFO - train_step=1600 loss=6.392 time=2.868
2024-11-12 20:36:13,910 - INFO - train_step=1600 avg_return=-45.796
2024-11-12 20:36:16,368 - INFO - train_step=1640 loss=6.033 time=14.623
2024-11-12 20:36:18,926 - INFO - train_step=1680 loss=5.787 time=2.558
2024-11-12 20:36:21,734 - INFO - train_step=1720 loss=5.912 time=2.809
2024-11-12 20:36:24,487 - INFO - train_step=1760 loss=6.065 time=2.753
2024-11-12 20:36:27,175 - INFO - train_step=1800 loss=6.346 time=2.688
2024-11-12 20:36:39,264 - INFO - train_step=1800 avg_return=-26.377
2024-11-12 20:36:41,506 - INFO - train_step=1840 loss=6.183 time=14.331
2024-11-12 20:36:44,895 - INFO - train_step=1880 loss=5.743 time=3.390
2024-11-12 20:36:48,838 - INFO - train_step=1920 loss=5.365 time=3.942
2024-11-12 20:36:51,784 - INFO - train_step=1960 loss=4.828 time=2.946
2024-11-12 20:36:54,497 - INFO - train_step=2000 loss=5.668 time=2.713
2024-11-12 20:37:07,367 - INFO - train_step=2000 avg_return=-17.397
2024-11-12 20:37:10,677 - INFO - train_step=2040 loss=5.523 time=16.181
2024-11-12 20:37:14,473 - INFO - train_step=2080 loss=6.047 time=3.795
2024-11-12 20:37:17,859 - INFO - train_step=2120 loss=6.135 time=3.386
2024-11-12 20:37:21,151 - INFO - train_step=2160 loss=5.948 time=3.292
2024-11-12 20:37:24,536 - INFO - train_step=2200 loss=5.964 time=3.385
2024-11-12 20:37:36,767 - INFO - train_step=2200 avg_return=-14.414
2024-11-12 20:37:39,185 - INFO - train_step=2240 loss=5.929 time=14.649
2024-11-12 20:37:41,896 - INFO - train_step=2280 loss=5.990 time=2.712
2024-11-12 20:37:44,621 - INFO - train_step=2320 loss=6.062 time=2.724
2024-11-12 20:37:47,370 - INFO - train_step=2360 loss=6.046 time=2.749
2024-11-12 20:37:50,032 - INFO - train_step=2400 loss=5.816 time=2.662
2024-11-12 20:38:01,508 - INFO - train_step=2400 avg_return=-11.062
2024-11-12 20:38:03,775 - INFO - train_step=2440 loss=5.779 time=13.743
2024-11-12 20:38:06,353 - INFO - train_step=2480 loss=5.621 time=2.577
2024-11-12 20:38:09,242 - INFO - train_step=2520 loss=5.612 time=2.889
2024-11-12 20:38:12,078 - INFO - train_step=2560 loss=6.141 time=2.837
2024-11-12 20:38:14,750 - INFO - train_step=2600 loss=6.688 time=2.672
2024-11-12 20:38:26,092 - INFO - train_step=2600 avg_return=-72.869
2024-11-12 20:38:28,367 - INFO - train_step=2640 loss=6.071 time=13.616
2024-11-12 20:38:30,756 - INFO - train_step=2680 loss=6.219 time=2.389
2024-11-12 20:38:33,421 - INFO - train_step=2720 loss=5.688 time=2.665
2024-11-12 20:38:36,076 - INFO - train_step=2760 loss=6.674 time=2.655
2024-11-12 20:38:38,673 - INFO - train_step=2800 loss=6.357 time=2.597
2024-11-12 20:38:51,140 - INFO - train_step=2800 avg_return=-11.500
2024-11-12 20:38:53,463 - INFO - train_step=2840 loss=6.523 time=14.790
2024-11-12 20:38:55,942 - INFO - train_step=2880 loss=6.395 time=2.479
2024-11-12 20:38:58,736 - INFO - train_step=2920 loss=5.828 time=2.794
2024-11-12 20:39:01,581 - INFO - train_step=2960 loss=6.086 time=2.845
2024-11-12 20:39:04,555 - INFO - train_step=3000 loss=5.821 time=2.974
2024-11-12 20:39:17,654 - INFO - train_step=3000 avg_return=-30.038
2024-11-12 20:39:19,858 - INFO - train_step=3040 loss=5.791 time=15.303
2024-11-12 20:39:22,339 - INFO - train_step=3080 loss=5.920 time=2.481
2024-11-12 20:39:25,501 - INFO - train_step=3120 loss=5.916 time=3.162
2024-11-12 20:39:28,586 - INFO - train_step=3160 loss=6.043 time=3.085
2024-11-12 20:39:31,553 - INFO - train_step=3200 loss=5.714 time=2.967
2024-11-12 20:39:43,165 - INFO - train_step=3200 avg_return=-19.023
2024-11-12 20:39:45,329 - INFO - train_step=3240 loss=5.603 time=13.776
2024-11-12 20:39:47,711 - INFO - train_step=3280 loss=6.396 time=2.382
2024-11-12 20:39:50,220 - INFO - train_step=3320 loss=5.685 time=2.508
2024-11-12 20:39:52,902 - INFO - train_step=3360 loss=5.787 time=2.683
2024-11-12 20:39:55,464 - INFO - train_step=3400 loss=6.004 time=2.562
2024-11-12 20:40:07,713 - INFO - train_step=3400 avg_return=-27.355
2024-11-12 20:40:09,890 - INFO - train_step=3440 loss=5.729 time=14.426
2024-11-12 20:40:12,607 - INFO - train_step=3480 loss=5.989 time=2.717
2024-11-12 20:40:15,260 - INFO - train_step=3520 loss=6.041 time=2.653
2024-11-12 20:40:17,893 - INFO - train_step=3560 loss=6.119 time=2.633
2024-11-12 20:40:20,385 - INFO - train_step=3600 loss=6.104 time=2.492
2024-11-12 20:40:31,861 - INFO - train_step=3600 avg_return=-22.199
2024-11-12 20:40:34,077 - INFO - train_step=3640 loss=6.001 time=13.692
2024-11-12 20:40:36,408 - INFO - train_step=3680 loss=6.091 time=2.331
2024-11-12 20:40:38,886 - INFO - train_step=3720 loss=5.827 time=2.478
2024-11-12 20:40:41,497 - INFO - train_step=3760 loss=6.204 time=2.611
2024-11-12 20:40:44,057 - INFO - train_step=3800 loss=6.276 time=2.560
2024-11-12 20:40:56,330 - INFO - train_step=3800 avg_return=-31.788
2024-11-12 20:40:58,489 - INFO - train_step=3840 loss=6.595 time=14.432
2024-11-12 20:41:01,102 - INFO - train_step=3880 loss=6.640 time=2.614
2024-11-12 20:41:03,716 - INFO - train_step=3920 loss=6.542 time=2.613
2024-11-12 20:41:06,802 - INFO - train_step=3960 loss=6.561 time=3.087
2024-11-12 20:41:09,488 - INFO - train_step=4000 loss=6.623 time=2.685
2024-11-12 20:41:21,429 - INFO - train_step=4000 avg_return=-46.639
2024-11-12 20:41:23,724 - INFO - train_step=4040 loss=6.353 time=14.236
2024-11-12 20:41:26,378 - INFO - train_step=4080 loss=6.069 time=2.654
2024-11-12 20:41:29,191 - INFO - train_step=4120 loss=5.881 time=2.814
2024-11-12 20:41:31,759 - INFO - train_step=4160 loss=6.082 time=2.567
2024-11-12 20:41:34,661 - INFO - train_step=4200 loss=6.150 time=2.902
2024-11-12 20:41:47,064 - INFO - train_step=4200 avg_return=-17.888
2024-11-12 20:41:49,374 - INFO - train_step=4240 loss=6.201 time=14.713
2024-11-12 20:41:51,843 - INFO - train_step=4280 loss=5.988 time=2.469
2024-11-12 20:41:54,557 - INFO - train_step=4320 loss=5.959 time=2.714
2024-11-12 20:41:57,128 - INFO - train_step=4360 loss=5.956 time=2.571
2024-11-12 20:41:59,982 - INFO - train_step=4400 loss=5.797 time=2.853
2024-11-12 20:42:12,568 - INFO - train_step=4400 avg_return=-24.090
2024-11-12 20:42:14,960 - INFO - train_step=4440 loss=5.932 time=14.978
2024-11-12 20:42:17,428 - INFO - train_step=4480 loss=5.906 time=2.468
2024-11-12 20:42:19,955 - INFO - train_step=4520 loss=5.772 time=2.527
2024-11-12 20:42:22,746 - INFO - train_step=4560 loss=5.770 time=2.791
2024-11-12 20:42:25,631 - INFO - train_step=4600 loss=5.560 time=2.885
2024-11-12 20:42:39,561 - INFO - train_step=4600 avg_return=-18.019
2024-11-12 20:42:42,816 - INFO - train_step=4640 loss=5.764 time=17.185
2024-11-12 20:42:45,782 - INFO - train_step=4680 loss=5.647 time=2.966
2024-11-12 20:42:49,550 - INFO - train_step=4720 loss=5.711 time=3.768
2024-11-12 20:42:53,285 - INFO - train_step=4760 loss=5.997 time=3.736
2024-11-12 20:42:56,299 - INFO - train_step=4800 loss=6.144 time=3.014
2024-11-12 20:43:08,897 - INFO - train_step=4800 avg_return=-71.378
2024-11-12 20:43:11,165 - INFO - train_step=4840 loss=6.497 time=14.865
2024-11-12 20:43:13,739 - INFO - train_step=4880 loss=6.608 time=2.574
2024-11-12 20:43:16,292 - INFO - train_step=4920 loss=6.551 time=2.554
2024-11-12 20:43:19,411 - INFO - train_step=4960 loss=6.389 time=3.119
2024-11-12 20:43:22,084 - INFO - train_step=5000 loss=6.387 time=2.673
2024-11-12 20:43:34,118 - INFO - train_step=5000 avg_return=-59.517
2024-11-12 20:43:36,136 - INFO - train_step=5040 loss=6.280 time=14.052
2024-11-12 20:43:38,535 - INFO - train_step=5080 loss=6.149 time=2.399
2024-11-12 20:43:40,903 - INFO - train_step=5120 loss=6.189 time=2.368
2024-11-12 20:43:43,441 - INFO - train_step=5160 loss=6.014 time=2.538
2024-11-12 20:43:46,579 - INFO - train_step=5200 loss=5.465 time=3.139
2024-11-12 20:43:59,942 - INFO - train_step=5200 avg_return=-10.972
2024-11-12 20:44:02,513 - INFO - train_step=5240 loss=5.806 time=15.934
2024-11-12 20:44:05,754 - INFO - train_step=5280 loss=6.051 time=3.241
2024-11-12 20:44:08,225 - INFO - train_step=5320 loss=5.797 time=2.471
2024-11-12 20:44:10,778 - INFO - train_step=5360 loss=6.240 time=2.553
2024-11-12 20:44:13,389 - INFO - train_step=5400 loss=6.351 time=2.611
2024-11-12 20:44:25,323 - INFO - train_step=5400 avg_return=-25.529
2024-11-12 20:44:27,302 - INFO - train_step=5440 loss=6.231 time=13.913
2024-11-12 20:44:29,949 - INFO - train_step=5480 loss=6.060 time=2.647
2024-11-12 20:44:32,502 - INFO - train_step=5520 loss=6.355 time=2.554
2024-11-12 20:44:35,293 - INFO - train_step=5560 loss=6.037 time=2.791
2024-11-12 20:44:38,153 - INFO - train_step=5600 loss=5.920 time=2.860
2024-11-12 20:44:50,934 - INFO - train_step=5600 avg_return=-26.814
2024-11-12 20:44:52,922 - INFO - train_step=5640 loss=6.000 time=14.769
2024-11-12 20:44:55,252 - INFO - train_step=5680 loss=6.273 time=2.330
2024-11-12 20:44:57,623 - INFO - train_step=5720 loss=6.194 time=2.371
2024-11-12 20:45:00,045 - INFO - train_step=5760 loss=5.982 time=2.421
2024-11-12 20:45:02,585 - INFO - train_step=5800 loss=5.903 time=2.540
2024-11-12 20:45:14,644 - INFO - train_step=5800 avg_return=-27.495
2024-11-12 20:45:16,556 - INFO - train_step=5840 loss=5.738 time=13.972
2024-11-12 20:45:19,094 - INFO - train_step=5880 loss=5.669 time=2.537
2024-11-12 20:45:22,365 - INFO - train_step=5920 loss=5.714 time=3.271
2024-11-12 20:45:25,510 - INFO - train_step=5960 loss=5.343 time=3.146
2024-11-12 20:45:28,501 - INFO - train_step=6000 loss=5.610 time=2.991
2024-11-12 20:45:45,646 - INFO - train_step=6000 avg_return=-64.920
2024-11-12 20:45:47,669 - INFO - train_step=6040 loss=6.179 time=19.168
2024-11-12 20:45:50,051 - INFO - train_step=6080 loss=5.848 time=2.382
2024-11-12 20:45:52,478 - INFO - train_step=6120 loss=5.867 time=2.427
2024-11-12 20:45:54,977 - INFO - train_step=6160 loss=5.982 time=2.499
2024-11-12 20:45:57,486 - INFO - train_step=6200 loss=5.855 time=2.509
2024-11-12 20:46:09,847 - INFO - train_step=6200 avg_return=-13.674
2024-11-12 20:46:12,715 - INFO - train_step=6240 loss=6.079 time=15.229
2024-11-12 20:46:15,706 - INFO - train_step=6280 loss=6.341 time=2.992
2024-11-12 20:46:18,349 - INFO - train_step=6320 loss=6.479 time=2.643
2024-11-12 20:46:20,814 - INFO - train_step=6360 loss=6.537 time=2.465
2024-11-12 20:46:23,323 - INFO - train_step=6400 loss=6.300 time=2.509
2024-11-12 20:46:36,729 - INFO - train_step=6400 avg_return=-17.439
2024-11-12 20:46:38,721 - INFO - train_step=6440 loss=6.211 time=15.398
2024-11-12 20:46:41,180 - INFO - train_step=6480 loss=6.238 time=2.459
2024-11-12 20:46:43,635 - INFO - train_step=6520 loss=6.349 time=2.455
2024-11-12 20:46:46,058 - INFO - train_step=6560 loss=6.256 time=2.424
2024-11-12 20:46:48,649 - INFO - train_step=6600 loss=6.284 time=2.590
2024-11-12 20:47:02,977 - INFO - train_step=6600 avg_return=-22.653
2024-11-12 20:47:05,160 - INFO - train_step=6640 loss=6.170 time=16.512
2024-11-12 20:47:07,826 - INFO - train_step=6680 loss=5.976 time=2.666
2024-11-12 20:47:10,431 - INFO - train_step=6720 loss=5.981 time=2.605
2024-11-12 20:47:12,855 - INFO - train_step=6760 loss=5.889 time=2.425
2024-11-12 20:47:15,286 - INFO - train_step=6800 loss=5.949 time=2.430
2024-11-12 20:47:28,274 - INFO - train_step=6800 avg_return=-17.036
2024-11-12 20:47:30,323 - INFO - train_step=6840 loss=6.136 time=15.038
2024-11-12 20:47:32,730 - INFO - train_step=6880 loss=6.064 time=2.406
2024-11-12 20:47:35,136 - INFO - train_step=6920 loss=6.136 time=2.407
2024-11-12 20:47:37,644 - INFO - train_step=6960 loss=6.006 time=2.507
2024-11-12 20:47:40,089 - INFO - train_step=7000 loss=5.852 time=2.446
2024-11-12 20:47:52,875 - INFO - train_step=7000 avg_return=-11.659
2024-11-12 20:47:55,969 - INFO - train_step=7040 loss=5.698 time=15.879
2024-11-12 20:47:58,397 - INFO - train_step=7080 loss=5.886 time=2.429
2024-11-12 20:48:00,999 - INFO - train_step=7120 loss=5.746 time=2.602
2024-11-12 20:48:03,614 - INFO - train_step=7160 loss=5.652 time=2.615
2024-11-12 20:48:06,075 - INFO - train_step=7200 loss=5.815 time=2.462
2024-11-12 20:48:19,088 - INFO - train_step=7200 avg_return=-8.461
2024-11-12 20:48:21,237 - INFO - train_step=7240 loss=5.809 time=15.162
2024-11-12 20:48:23,671 - INFO - train_step=7280 loss=5.847 time=2.432
2024-11-12 20:48:26,187 - INFO - train_step=7320 loss=6.034 time=2.518
2024-11-12 20:48:29,615 - INFO - train_step=7360 loss=5.814 time=3.428
2024-11-12 20:48:31,974 - INFO - train_step=7400 loss=5.878 time=2.358
2024-11-12 20:48:46,277 - INFO - train_step=7400 avg_return=-12.256
2024-11-12 20:48:48,341 - INFO - train_step=7440 loss=5.992 time=16.367
2024-11-12 20:48:50,898 - INFO - train_step=7480 loss=5.897 time=2.557
2024-11-12 20:48:53,527 - INFO - train_step=7520 loss=5.899 time=2.629
2024-11-12 20:48:56,243 - INFO - train_step=7560 loss=5.830 time=2.716
2024-11-12 20:48:58,743 - INFO - train_step=7600 loss=5.628 time=2.500
2024-11-12 20:49:12,878 - INFO - train_step=7600 avg_return=-12.857
2024-11-12 20:49:14,827 - INFO - train_step=7640 loss=5.949 time=16.084
2024-11-12 20:49:17,169 - INFO - train_step=7680 loss=6.026 time=2.342
2024-11-12 20:49:19,585 - INFO - train_step=7720 loss=6.111 time=2.416
2024-11-12 20:49:22,369 - INFO - train_step=7760 loss=6.148 time=2.783
2024-11-12 20:49:24,799 - INFO - train_step=7800 loss=6.042 time=2.431
2024-11-12 20:49:38,065 - INFO - train_step=7800 avg_return=-9.011
2024-11-12 20:49:40,099 - INFO - train_step=7840 loss=6.085 time=15.300
2024-11-12 20:49:42,592 - INFO - train_step=7880 loss=6.132 time=2.493
2024-11-12 20:49:45,217 - INFO - train_step=7920 loss=5.812 time=2.625
2024-11-12 20:49:47,874 - INFO - train_step=7960 loss=5.824 time=2.656
2024-11-12 20:49:50,419 - INFO - train_step=8000 loss=6.406 time=2.545
2024-11-12 20:50:05,128 - INFO - train_step=8000 avg_return=-13.362
2024-11-12 20:50:07,312 - INFO - train_step=8040 loss=6.417 time=16.893
2024-11-12 20:50:09,848 - INFO - train_step=8080 loss=6.778 time=2.536
2024-11-12 20:50:12,302 - INFO - train_step=8120 loss=6.362 time=2.454
2024-11-12 20:50:14,827 - INFO - train_step=8160 loss=6.647 time=2.525
2024-11-12 20:50:17,131 - INFO - train_step=8200 loss=6.240 time=2.304
2024-11-12 20:50:30,678 - INFO - train_step=8200 avg_return=-32.139
2024-11-12 20:50:32,740 - INFO - train_step=8240 loss=5.953 time=15.609
2024-11-12 20:50:35,218 - INFO - train_step=8280 loss=6.086 time=2.479
2024-11-12 20:50:37,678 - INFO - train_step=8320 loss=5.959 time=2.459
2024-11-12 20:50:40,186 - INFO - train_step=8360 loss=6.102 time=2.509
2024-11-12 20:50:42,719 - INFO - train_step=8400 loss=6.048 time=2.533
2024-11-12 20:50:56,140 - INFO - train_step=8400 avg_return=-11.404
2024-11-12 20:50:58,117 - INFO - train_step=8440 loss=6.291 time=15.398
2024-11-12 20:51:00,469 - INFO - train_step=8480 loss=6.028 time=2.352
2024-11-12 20:51:02,867 - INFO - train_step=8520 loss=6.055 time=2.399
2024-11-12 20:51:05,357 - INFO - train_step=8560 loss=5.969 time=2.489
2024-11-12 20:51:07,889 - INFO - train_step=8600 loss=5.942 time=2.532
2024-11-12 20:51:22,667 - INFO - train_step=8600 avg_return=-19.569
2024-11-12 20:51:24,896 - INFO - train_step=8640 loss=6.034 time=17.008
2024-11-12 20:51:27,712 - INFO - train_step=8680 loss=6.004 time=2.816
2024-11-12 20:51:30,631 - INFO - train_step=8720 loss=6.070 time=2.918
2024-11-12 20:51:33,087 - INFO - train_step=8760 loss=6.055 time=2.456
2024-11-12 20:51:35,506 - INFO - train_step=8800 loss=5.877 time=2.419
2024-11-12 20:51:48,708 - INFO - train_step=8800 avg_return=-19.723
2024-11-12 20:51:50,702 - INFO - train_step=8840 loss=5.844 time=15.195
2024-11-12 20:51:53,102 - INFO - train_step=8880 loss=5.830 time=2.401
2024-11-12 20:51:55,562 - INFO - train_step=8920 loss=5.861 time=2.459
2024-11-12 20:51:58,082 - INFO - train_step=8960 loss=6.040 time=2.521
2024-11-12 20:52:00,663 - INFO - train_step=9000 loss=5.930 time=2.581
2024-11-12 20:52:15,189 - INFO - train_step=9000 avg_return=-27.616
2024-11-12 20:52:18,436 - INFO - train_step=9040 loss=5.946 time=17.773
2024-11-12 20:52:22,080 - INFO - train_step=9080 loss=5.774 time=3.644
2024-11-12 20:52:24,981 - INFO - train_step=9120 loss=5.893 time=2.901
2024-11-12 20:52:28,294 - INFO - train_step=9160 loss=5.684 time=3.313
2024-11-12 20:52:30,963 - INFO - train_step=9200 loss=5.608 time=2.668
2024-11-12 20:52:44,541 - INFO - train_step=9200 avg_return=-13.800
2024-11-12 20:52:46,581 - INFO - train_step=9240 loss=5.499 time=15.618
2024-11-12 20:52:49,138 - INFO - train_step=9280 loss=5.618 time=2.557
2024-11-12 20:52:51,609 - INFO - train_step=9320 loss=5.590 time=2.470
2024-11-12 20:52:54,068 - INFO - train_step=9360 loss=5.678 time=2.459
2024-11-12 20:52:56,558 - INFO - train_step=9400 loss=5.596 time=2.490
2024-11-12 20:53:09,917 - INFO - train_step=9400 avg_return=-12.235
2024-11-12 20:53:11,954 - INFO - train_step=9440 loss=5.690 time=15.397
2024-11-12 20:53:14,347 - INFO - train_step=9480 loss=5.799 time=2.393
2024-11-12 20:53:17,001 - INFO - train_step=9520 loss=5.817 time=2.654
2024-11-12 20:53:19,900 - INFO - train_step=9560 loss=5.806 time=2.899
2024-11-12 20:53:22,229 - INFO - train_step=9600 loss=5.506 time=2.330
2024-11-12 20:53:36,401 - INFO - train_step=9600 avg_return=-12.209
2024-11-12 20:53:38,439 - INFO - train_step=9640 loss=5.575 time=16.209
2024-11-12 20:53:40,843 - INFO - train_step=9680 loss=5.671 time=2.404
2024-11-12 20:53:43,405 - INFO - train_step=9720 loss=5.646 time=2.562
2024-11-12 20:53:45,893 - INFO - train_step=9760 loss=5.860 time=2.488
2024-11-12 20:53:48,174 - INFO - train_step=9800 loss=6.054 time=2.282
2024-11-12 20:54:01,549 - INFO - train_step=9800 avg_return=-8.749
2024-11-12 20:54:03,859 - INFO - train_step=9840 loss=6.018 time=15.685
2024-11-12 20:54:06,323 - INFO - train_step=9880 loss=5.937 time=2.464
2024-11-12 20:54:08,771 - INFO - train_step=9920 loss=6.014 time=2.448
2024-11-12 20:54:11,236 - INFO - train_step=9960 loss=5.851 time=2.464
2024-11-12 20:54:13,660 - INFO - train_step=10000 loss=5.988 time=2.424
2024-11-12 20:54:26,509 - INFO - train_step=10000 avg_return=-13.093
2024-11-12 20:54:26,509 - INFO - total_time=1322.047
2024-11-12 20:54:26,509 - INFO - saving, checkpointPath_toSave=./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model
2024-11-12 20:54:26,521 - INFO - Checkpoint available: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/0/ckpt-10000
2024-11-12 20:54:26,628 - INFO - Sharding callback duration: 46
2024-11-12 20:54:26,662 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/0/ckpt-10000
2024-11-12 20:54:26,664 - INFO - Checkpoint available: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/1/ckpt-10000
2024-11-12 20:54:26,779 - INFO - Sharding callback duration: 21
2024-11-12 20:54:26,796 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/1/ckpt-10000
