2024-11-16 07:10:48.485301: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-16 07:10:48.485405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-16 07:10:48.486108: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-16 07:10:48.490838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-16 07:10:49.119256: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'DaisoSokcho_discrete', '-a', 'CDQN_multiagent', '-n', '3', '-i', '500', '-g', '0.01']
2024-11-16 07:10:50.358441: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-16 07:10:50.358480: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-16 07:10:50.358486: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-16 07:10:50.358636: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-16 07:10:50.358658: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-16 07:10:50.358662: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-16 07:10:50,372 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 10000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'epsilon_greedy': 0.1, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-16 07:10:50,372 - INFO - args=Namespace(environment='DaisoSokcho_discrete', environment_wrapper=None, agent='CDQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3, num_init_collect_steps=500, epsilon_greedy=0.01)
2024-11-16 07:10:50,372 - INFO - environment=DaisoSokcho_discrete
2024-11-16 07:10:50,372 - INFO - envWrapper=None
2024-11-16 07:10:50,372 - INFO - agent=CDQN_multiagent
Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

2024-11-16 07:10:51,026 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))
2024-11-16 07:10:51,026 - INFO - tf_action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32))
2024-11-16 07:10:51,027 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))})
2024-11-16 07:10:51,367 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32)),
 'action': BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-16 07:10:51,473 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-16 07:11:17,471 - INFO - random_policy avg_return=-349.78863525390625
2024-11-16 07:11:17,471 - INFO - replay_buffer.capacity=10000
2024-11-16 07:11:17,475 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-16 07:11:32,755 - INFO - after filling with random_policies, replay_buffer.num_frames()=500
2024-11-16 07:12:13,190 - INFO - before training, avg_return=-499.5428771972656
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-16 07:12:13,348 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
WARNING:tensorflow:5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.categorical_dqn.categorical_dqn_agent.CategoricalDqnAgent object at 0x7f5e240f0580>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-16 07:12:28,809 - WARNING - 5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.categorical_dqn.categorical_dqn_agent.CategoricalDqnAgent object at 0x7f5e240f0580>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-16 07:12:31,908 - INFO - train_step=40 loss=30.772 time=18.717
2024-11-16 07:12:35,099 - INFO - train_step=80 loss=13.837 time=3.191
2024-11-16 07:12:38,235 - INFO - train_step=120 loss=12.147 time=3.136
2024-11-16 07:12:41,409 - INFO - train_step=160 loss=9.879 time=3.174
2024-11-16 07:12:44,748 - INFO - train_step=200 loss=9.637 time=3.339
2024-11-16 07:13:32,926 - INFO - train_step=200 avg_return=-273.144
2024-11-16 07:13:36,090 - INFO - train_step=240 loss=7.348 time=51.341
2024-11-16 07:13:39,269 - INFO - train_step=280 loss=9.571 time=3.179
2024-11-16 07:13:42,469 - INFO - train_step=320 loss=6.636 time=3.200
2024-11-16 07:13:45,675 - INFO - train_step=360 loss=5.966 time=3.206
2024-11-16 07:13:48,898 - INFO - train_step=400 loss=7.949 time=3.223
2024-11-16 07:14:36,398 - INFO - train_step=400 avg_return=-283.005
2024-11-16 07:14:39,556 - INFO - train_step=440 loss=4.317 time=50.658
2024-11-16 07:14:42,766 - INFO - train_step=480 loss=6.168 time=3.210
2024-11-16 07:14:46,162 - INFO - train_step=520 loss=4.277 time=3.396
2024-11-16 07:14:49,353 - INFO - train_step=560 loss=6.479 time=3.191
2024-11-16 07:14:52,505 - INFO - train_step=600 loss=6.763 time=3.152
2024-11-16 07:15:39,867 - INFO - train_step=600 avg_return=-238.189
2024-11-16 07:15:43,060 - INFO - train_step=640 loss=5.287 time=50.555
2024-11-16 07:15:46,233 - INFO - train_step=680 loss=5.291 time=3.173
2024-11-16 07:15:49,390 - INFO - train_step=720 loss=7.958 time=3.157
2024-11-16 07:15:52,590 - INFO - train_step=760 loss=4.079 time=3.199
2024-11-16 07:15:55,722 - INFO - train_step=800 loss=6.238 time=3.133
2024-11-16 07:16:43,178 - INFO - train_step=800 avg_return=-433.771
2024-11-16 07:16:46,563 - INFO - train_step=840 loss=7.707 time=50.841
2024-11-16 07:16:49,921 - INFO - train_step=880 loss=8.566 time=3.357
2024-11-16 07:16:53,237 - INFO - train_step=920 loss=5.013 time=3.317
2024-11-16 07:16:56,701 - INFO - train_step=960 loss=5.392 time=3.464
2024-11-16 07:17:00,114 - INFO - train_step=1000 loss=3.765 time=3.413
2024-11-16 07:17:48,713 - INFO - train_step=1000 avg_return=-460.572
2024-11-16 07:17:52,005 - INFO - train_step=1040 loss=4.078 time=51.891
2024-11-16 07:17:55,456 - INFO - train_step=1080 loss=4.179 time=3.452
2024-11-16 07:17:58,886 - INFO - train_step=1120 loss=8.157 time=3.429
2024-11-16 07:18:02,288 - INFO - train_step=1160 loss=6.058 time=3.403
2024-11-16 07:18:05,662 - INFO - train_step=1200 loss=5.124 time=3.373
2024-11-16 07:18:53,769 - INFO - train_step=1200 avg_return=-288.722
2024-11-16 07:18:56,970 - INFO - train_step=1240 loss=6.295 time=51.309
2024-11-16 07:19:00,130 - INFO - train_step=1280 loss=4.952 time=3.160
2024-11-16 07:19:03,325 - INFO - train_step=1320 loss=2.995 time=3.195
2024-11-16 07:19:06,496 - INFO - train_step=1360 loss=3.921 time=3.171
2024-11-16 07:19:09,692 - INFO - train_step=1400 loss=2.657 time=3.196
2024-11-16 07:19:57,402 - INFO - train_step=1400 avg_return=-271.742
2024-11-16 07:20:00,761 - INFO - train_step=1440 loss=4.587 time=51.069
2024-11-16 07:20:04,228 - INFO - train_step=1480 loss=2.219 time=3.467
2024-11-16 07:20:07,579 - INFO - train_step=1520 loss=2.173 time=3.351
2024-11-16 07:20:10,860 - INFO - train_step=1560 loss=3.473 time=3.280
2024-11-16 07:20:14,244 - INFO - train_step=1600 loss=7.865 time=3.384
2024-11-16 07:21:02,627 - INFO - train_step=1600 avg_return=-502.582
2024-11-16 07:21:05,956 - INFO - train_step=1640 loss=4.254 time=51.712
2024-11-16 07:21:09,415 - INFO - train_step=1680 loss=2.249 time=3.459
2024-11-16 07:21:12,696 - INFO - train_step=1720 loss=4.357 time=3.281
2024-11-16 07:21:16,143 - INFO - train_step=1760 loss=2.487 time=3.447
2024-11-16 07:21:19,550 - INFO - train_step=1800 loss=2.096 time=3.407
2024-11-16 07:22:07,235 - INFO - train_step=1800 avg_return=-320.034
2024-11-16 07:22:10,498 - INFO - train_step=1840 loss=2.466 time=50.948
2024-11-16 07:22:13,740 - INFO - train_step=1880 loss=1.717 time=3.242
2024-11-16 07:22:16,962 - INFO - train_step=1920 loss=2.114 time=3.222
2024-11-16 07:22:20,150 - INFO - train_step=1960 loss=1.714 time=3.188
2024-11-16 07:22:23,332 - INFO - train_step=2000 loss=1.931 time=3.181
2024-11-16 07:23:11,117 - INFO - train_step=2000 avg_return=-348.261
2024-11-16 07:23:14,460 - INFO - train_step=2040 loss=1.789 time=51.128
2024-11-16 07:23:17,889 - INFO - train_step=2080 loss=2.269 time=3.430
2024-11-16 07:23:21,323 - INFO - train_step=2120 loss=1.095 time=3.434
2024-11-16 07:23:24,723 - INFO - train_step=2160 loss=2.147 time=3.400
2024-11-16 07:23:28,187 - INFO - train_step=2200 loss=2.406 time=3.464
2024-11-16 07:24:16,440 - INFO - train_step=2200 avg_return=-382.213
2024-11-16 07:24:19,604 - INFO - train_step=2240 loss=1.960 time=51.417
2024-11-16 07:24:22,792 - INFO - train_step=2280 loss=1.367 time=3.188
2024-11-16 07:24:25,936 - INFO - train_step=2320 loss=0.762 time=3.144
2024-11-16 07:24:29,128 - INFO - train_step=2360 loss=3.848 time=3.192
2024-11-16 07:24:32,382 - INFO - train_step=2400 loss=2.575 time=3.254
2024-11-16 07:25:21,133 - INFO - train_step=2400 avg_return=-427.369
2024-11-16 07:25:24,548 - INFO - train_step=2440 loss=4.340 time=52.166
2024-11-16 07:25:27,824 - INFO - train_step=2480 loss=3.726 time=3.276
2024-11-16 07:25:31,222 - INFO - train_step=2520 loss=2.296 time=3.399
2024-11-16 07:25:34,601 - INFO - train_step=2560 loss=3.186 time=3.378
2024-11-16 07:25:38,033 - INFO - train_step=2600 loss=1.528 time=3.432
2024-11-16 07:26:25,993 - INFO - train_step=2600 avg_return=-329.862
2024-11-16 07:26:29,150 - INFO - train_step=2640 loss=1.928 time=51.118
2024-11-16 07:26:32,417 - INFO - train_step=2680 loss=1.622 time=3.266
2024-11-16 07:26:35,550 - INFO - train_step=2720 loss=3.833 time=3.134
2024-11-16 07:26:38,763 - INFO - train_step=2760 loss=2.348 time=3.213
2024-11-16 07:26:41,987 - INFO - train_step=2800 loss=2.180 time=3.224
2024-11-16 07:27:29,884 - INFO - train_step=2800 avg_return=-236.663
2024-11-16 07:27:33,279 - INFO - train_step=2840 loss=1.774 time=51.292
2024-11-16 07:27:36,691 - INFO - train_step=2880 loss=1.701 time=3.411
2024-11-16 07:27:39,962 - INFO - train_step=2920 loss=4.622 time=3.272
2024-11-16 07:27:43,225 - INFO - train_step=2960 loss=1.939 time=3.263
2024-11-16 07:27:46,581 - INFO - train_step=3000 loss=6.512 time=3.356
2024-11-16 07:28:34,798 - INFO - train_step=3000 avg_return=-150.060
2024-11-16 07:28:38,014 - INFO - train_step=3040 loss=3.410 time=51.433
2024-11-16 07:28:41,195 - INFO - train_step=3080 loss=2.875 time=3.180
2024-11-16 07:28:44,386 - INFO - train_step=3120 loss=2.224 time=3.191
2024-11-16 07:28:47,569 - INFO - train_step=3160 loss=2.419 time=3.183
2024-11-16 07:28:50,765 - INFO - train_step=3200 loss=2.049 time=3.196
2024-11-16 07:29:38,303 - INFO - train_step=3200 avg_return=-180.398
2024-11-16 07:29:41,560 - INFO - train_step=3240 loss=1.270 time=50.795
2024-11-16 07:29:44,723 - INFO - train_step=3280 loss=1.804 time=3.163
2024-11-16 07:29:47,928 - INFO - train_step=3320 loss=1.856 time=3.205
2024-11-16 07:29:51,146 - INFO - train_step=3360 loss=2.357 time=3.219
2024-11-16 07:29:54,307 - INFO - train_step=3400 loss=3.398 time=3.161
2024-11-16 07:30:41,822 - INFO - train_step=3400 avg_return=-338.765
2024-11-16 07:30:45,210 - INFO - train_step=3440 loss=2.395 time=50.903
2024-11-16 07:30:48,425 - INFO - train_step=3480 loss=3.848 time=3.214
2024-11-16 07:30:51,610 - INFO - train_step=3520 loss=1.650 time=3.186
2024-11-16 07:30:55,013 - INFO - train_step=3560 loss=1.433 time=3.403
2024-11-16 07:30:58,410 - INFO - train_step=3600 loss=3.337 time=3.397
2024-11-16 07:31:45,729 - INFO - train_step=3600 avg_return=-281.484
2024-11-16 07:31:49,302 - INFO - train_step=3640 loss=1.267 time=50.892
2024-11-16 07:31:52,499 - INFO - train_step=3680 loss=3.576 time=3.197
2024-11-16 07:31:55,718 - INFO - train_step=3720 loss=2.666 time=3.219
2024-11-16 07:31:58,862 - INFO - train_step=3760 loss=2.565 time=3.144
2024-11-16 07:32:02,069 - INFO - train_step=3800 loss=1.889 time=3.207
2024-11-16 07:32:48,686 - INFO - train_step=3800 avg_return=-359.407
2024-11-16 07:32:52,251 - INFO - train_step=3840 loss=2.407 time=50.182
2024-11-16 07:32:55,733 - INFO - train_step=3880 loss=2.298 time=3.482
2024-11-16 07:32:58,902 - INFO - train_step=3920 loss=3.633 time=3.168
2024-11-16 07:33:02,126 - INFO - train_step=3960 loss=2.777 time=3.225
2024-11-16 07:33:05,339 - INFO - train_step=4000 loss=2.025 time=3.213
2024-11-16 07:33:51,932 - INFO - train_step=4000 avg_return=-333.373
2024-11-16 07:33:55,547 - INFO - train_step=4040 loss=1.330 time=50.208
2024-11-16 07:33:59,140 - INFO - train_step=4080 loss=1.068 time=3.593
2024-11-16 07:34:02,401 - INFO - train_step=4120 loss=1.166 time=3.261
2024-11-16 07:34:05,598 - INFO - train_step=4160 loss=3.054 time=3.198
2024-11-16 07:34:08,766 - INFO - train_step=4200 loss=1.440 time=3.167
2024-11-16 07:34:55,227 - INFO - train_step=4200 avg_return=-431.012
2024-11-16 07:34:59,039 - INFO - train_step=4240 loss=1.386 time=50.274
2024-11-16 07:35:02,815 - INFO - train_step=4280 loss=2.456 time=3.775
2024-11-16 07:35:06,351 - INFO - train_step=4320 loss=1.496 time=3.537
2024-11-16 07:35:09,759 - INFO - train_step=4360 loss=1.930 time=3.407
2024-11-16 07:35:13,125 - INFO - train_step=4400 loss=3.457 time=3.367
2024-11-16 07:36:00,660 - INFO - train_step=4400 avg_return=-290.099
2024-11-16 07:36:04,201 - INFO - train_step=4440 loss=2.362 time=51.076
2024-11-16 07:36:08,032 - INFO - train_step=4480 loss=6.209 time=3.831
2024-11-16 07:36:11,216 - INFO - train_step=4520 loss=2.509 time=3.184
2024-11-16 07:36:14,401 - INFO - train_step=4560 loss=2.400 time=3.185
2024-11-16 07:36:17,569 - INFO - train_step=4600 loss=2.238 time=3.168
2024-11-16 07:37:03,692 - INFO - train_step=4600 avg_return=-452.203
2024-11-16 07:37:07,424 - INFO - train_step=4640 loss=1.471 time=49.855
2024-11-16 07:37:10,928 - INFO - train_step=4680 loss=5.603 time=3.504
2024-11-16 07:37:14,359 - INFO - train_step=4720 loss=4.799 time=3.432
2024-11-16 07:37:17,519 - INFO - train_step=4760 loss=5.407 time=3.159
2024-11-16 07:37:20,680 - INFO - train_step=4800 loss=5.459 time=3.162
2024-11-16 07:38:05,516 - INFO - train_step=4800 avg_return=-152.909
2024-11-16 07:38:09,761 - INFO - train_step=4840 loss=5.188 time=49.081
2024-11-16 07:38:13,526 - INFO - train_step=4880 loss=5.414 time=3.765
2024-11-16 07:38:17,173 - INFO - train_step=4920 loss=5.851 time=3.647
2024-11-16 07:38:20,540 - INFO - train_step=4960 loss=5.382 time=3.367
2024-11-16 07:38:23,696 - INFO - train_step=5000 loss=4.761 time=3.156
2024-11-16 07:39:08,733 - INFO - train_step=5000 avg_return=-122.591
2024-11-16 07:39:12,799 - INFO - train_step=5040 loss=4.674 time=49.103
2024-11-16 07:39:16,786 - INFO - train_step=5080 loss=4.946 time=3.987
2024-11-16 07:39:20,398 - INFO - train_step=5120 loss=4.777 time=3.612
2024-11-16 07:39:24,167 - INFO - train_step=5160 loss=5.848 time=3.769
2024-11-16 07:39:27,543 - INFO - train_step=5200 loss=7.024 time=3.376
2024-11-16 07:40:13,537 - INFO - train_step=5200 avg_return=-335.585
2024-11-16 07:40:17,714 - INFO - train_step=5240 loss=5.217 time=50.171
2024-11-16 07:40:21,641 - INFO - train_step=5280 loss=5.272 time=3.927
2024-11-16 07:40:25,338 - INFO - train_step=5320 loss=4.458 time=3.697
2024-11-16 07:40:29,002 - INFO - train_step=5360 loss=4.441 time=3.665
2024-11-16 07:40:32,286 - INFO - train_step=5400 loss=4.859 time=3.283
2024-11-16 07:41:18,418 - INFO - train_step=5400 avg_return=-392.742
2024-11-16 07:41:22,604 - INFO - train_step=5440 loss=3.855 time=50.318
2024-11-16 07:41:26,514 - INFO - train_step=5480 loss=4.839 time=3.910
2024-11-16 07:41:30,195 - INFO - train_step=5520 loss=4.585 time=3.681
2024-11-16 07:41:33,873 - INFO - train_step=5560 loss=4.690 time=3.678
2024-11-16 07:41:37,277 - INFO - train_step=5600 loss=4.638 time=3.404
2024-11-16 07:42:24,050 - INFO - train_step=5600 avg_return=-387.715
2024-11-16 07:42:28,173 - INFO - train_step=5640 loss=6.179 time=50.896
2024-11-16 07:42:32,104 - INFO - train_step=5680 loss=5.155 time=3.931
2024-11-16 07:42:35,801 - INFO - train_step=5720 loss=4.724 time=3.697
2024-11-16 07:42:39,257 - INFO - train_step=5760 loss=4.072 time=3.456
2024-11-16 07:42:42,561 - INFO - train_step=5800 loss=3.671 time=3.304
2024-11-16 07:43:28,772 - INFO - train_step=5800 avg_return=-340.269
2024-11-16 07:43:32,760 - INFO - train_step=5840 loss=3.828 time=50.199
2024-11-16 07:43:36,637 - INFO - train_step=5880 loss=5.148 time=3.877
2024-11-16 07:43:40,271 - INFO - train_step=5920 loss=4.194 time=3.634
2024-11-16 07:43:43,403 - INFO - train_step=5960 loss=4.948 time=3.132
2024-11-16 07:43:46,620 - INFO - train_step=6000 loss=5.140 time=3.216
2024-11-16 07:44:31,720 - INFO - train_step=6000 avg_return=-276.397
2024-11-16 07:44:35,938 - INFO - train_step=6040 loss=4.558 time=49.318
2024-11-16 07:44:40,211 - INFO - train_step=6080 loss=4.648 time=4.273
2024-11-16 07:44:43,889 - INFO - train_step=6120 loss=5.436 time=3.678
2024-11-16 07:44:47,187 - INFO - train_step=6160 loss=3.929 time=3.298
2024-11-16 07:44:50,344 - INFO - train_step=6200 loss=3.370 time=3.158
2024-11-16 07:45:35,522 - INFO - train_step=6200 avg_return=-295.333
2024-11-16 07:45:39,859 - INFO - train_step=6240 loss=4.179 time=49.515
2024-11-16 07:45:43,920 - INFO - train_step=6280 loss=6.107 time=4.061
2024-11-16 07:45:47,580 - INFO - train_step=6320 loss=3.812 time=3.659
2024-11-16 07:45:51,315 - INFO - train_step=6360 loss=4.116 time=3.736
2024-11-16 07:45:54,581 - INFO - train_step=6400 loss=4.601 time=3.266
2024-11-16 07:46:39,728 - INFO - train_step=6400 avg_return=-252.136
2024-11-16 07:46:44,032 - INFO - train_step=6440 loss=6.905 time=49.450
2024-11-16 07:46:48,178 - INFO - train_step=6480 loss=7.470 time=4.146
2024-11-16 07:46:52,164 - INFO - train_step=6520 loss=6.944 time=3.986
2024-11-16 07:46:55,867 - INFO - train_step=6560 loss=6.858 time=3.703
2024-11-16 07:46:59,126 - INFO - train_step=6600 loss=7.924 time=3.259
2024-11-16 07:47:45,007 - INFO - train_step=6600 avg_return=-340.099
2024-11-16 07:47:49,289 - INFO - train_step=6640 loss=7.067 time=50.164
2024-11-16 07:47:53,298 - INFO - train_step=6680 loss=6.923 time=4.009
2024-11-16 07:47:57,078 - INFO - train_step=6720 loss=7.117 time=3.780
2024-11-16 07:48:00,724 - INFO - train_step=6760 loss=6.568 time=3.647
2024-11-16 07:48:03,962 - INFO - train_step=6800 loss=7.296 time=3.238
2024-11-16 07:48:49,740 - INFO - train_step=6800 avg_return=-416.963
2024-11-16 07:48:53,977 - INFO - train_step=6840 loss=6.760 time=50.015
2024-11-16 07:48:58,059 - INFO - train_step=6880 loss=7.661 time=4.082
2024-11-16 07:49:01,800 - INFO - train_step=6920 loss=7.172 time=3.742
2024-11-16 07:49:05,429 - INFO - train_step=6960 loss=7.109 time=3.629
2024-11-16 07:49:08,686 - INFO - train_step=7000 loss=6.779 time=3.257
2024-11-16 07:49:55,190 - INFO - train_step=7000 avg_return=-406.043
2024-11-16 07:49:59,281 - INFO - train_step=7040 loss=7.890 time=50.595
2024-11-16 07:50:03,353 - INFO - train_step=7080 loss=6.375 time=4.073
2024-11-16 07:50:07,078 - INFO - train_step=7120 loss=6.272 time=3.725
2024-11-16 07:50:10,304 - INFO - train_step=7160 loss=6.263 time=3.226
2024-11-16 07:50:13,470 - INFO - train_step=7200 loss=6.678 time=3.166
2024-11-16 07:50:58,547 - INFO - train_step=7200 avg_return=-247.152
2024-11-16 07:51:02,681 - INFO - train_step=7240 loss=6.835 time=49.211
2024-11-16 07:51:06,707 - INFO - train_step=7280 loss=5.871 time=4.026
2024-11-16 07:51:10,749 - INFO - train_step=7320 loss=5.532 time=4.043
2024-11-16 07:51:14,238 - INFO - train_step=7360 loss=5.146 time=3.489
2024-11-16 07:51:17,517 - INFO - train_step=7400 loss=5.702 time=3.278
2024-11-16 07:52:03,817 - INFO - train_step=7400 avg_return=-178.860
2024-11-16 07:52:07,883 - INFO - train_step=7440 loss=5.541 time=50.366
2024-11-16 07:52:11,672 - INFO - train_step=7480 loss=5.576 time=3.789
2024-11-16 07:52:15,700 - INFO - train_step=7520 loss=5.415 time=4.028
2024-11-16 07:52:19,067 - INFO - train_step=7560 loss=6.847 time=3.366
2024-11-16 07:52:22,363 - INFO - train_step=7600 loss=6.541 time=3.296
2024-11-16 07:53:09,030 - INFO - train_step=7600 avg_return=-434.184
2024-11-16 07:53:13,061 - INFO - train_step=7640 loss=6.669 time=50.698
2024-11-16 07:53:16,997 - INFO - train_step=7680 loss=5.460 time=3.936
2024-11-16 07:53:20,957 - INFO - train_step=7720 loss=4.985 time=3.960
2024-11-16 07:53:24,206 - INFO - train_step=7760 loss=5.207 time=3.248
2024-11-16 07:53:27,440 - INFO - train_step=7800 loss=5.442 time=3.234
2024-11-16 07:54:14,019 - INFO - train_step=7800 avg_return=-278.423
2024-11-16 07:54:18,012 - INFO - train_step=7840 loss=5.004 time=50.572
2024-11-16 07:54:22,162 - INFO - train_step=7880 loss=4.269 time=4.150
2024-11-16 07:54:25,805 - INFO - train_step=7920 loss=5.086 time=3.643
2024-11-16 07:54:29,231 - INFO - train_step=7960 loss=4.399 time=3.426
2024-11-16 07:54:32,349 - INFO - train_step=8000 loss=4.357 time=3.118
2024-11-16 07:55:17,105 - INFO - train_step=8000 avg_return=-446.178
2024-11-16 07:55:21,137 - INFO - train_step=8040 loss=4.177 time=48.788
2024-11-16 07:55:24,903 - INFO - train_step=8080 loss=4.359 time=3.766
2024-11-16 07:55:28,852 - INFO - train_step=8120 loss=4.447 time=3.949
2024-11-16 07:55:32,479 - INFO - train_step=8160 loss=3.526 time=3.627
2024-11-16 07:55:35,758 - INFO - train_step=8200 loss=5.827 time=3.278
2024-11-16 07:56:21,873 - INFO - train_step=8200 avg_return=-255.570
2024-11-16 07:56:25,975 - INFO - train_step=8240 loss=5.012 time=50.218
2024-11-16 07:56:29,959 - INFO - train_step=8280 loss=4.489 time=3.984
2024-11-16 07:56:33,797 - INFO - train_step=8320 loss=4.479 time=3.838
2024-11-16 07:56:37,361 - INFO - train_step=8360 loss=4.842 time=3.564
2024-11-16 07:56:40,588 - INFO - train_step=8400 loss=3.271 time=3.227
2024-11-16 07:57:25,918 - INFO - train_step=8400 avg_return=-234.022
2024-11-16 07:57:30,079 - INFO - train_step=8440 loss=3.421 time=49.491
2024-11-16 07:57:34,158 - INFO - train_step=8480 loss=3.623 time=4.079
2024-11-16 07:57:38,202 - INFO - train_step=8520 loss=4.000 time=4.044
2024-11-16 07:57:41,761 - INFO - train_step=8560 loss=4.525 time=3.558
2024-11-16 07:57:45,019 - INFO - train_step=8600 loss=4.163 time=3.258
2024-11-16 07:58:31,057 - INFO - train_step=8600 avg_return=-110.888
2024-11-16 07:58:35,048 - INFO - train_step=8640 loss=3.117 time=50.029
2024-11-16 07:58:38,908 - INFO - train_step=8680 loss=4.342 time=3.861
2024-11-16 07:58:42,943 - INFO - train_step=8720 loss=4.041 time=4.035
2024-11-16 07:58:46,394 - INFO - train_step=8760 loss=3.377 time=3.452
2024-11-16 07:58:49,739 - INFO - train_step=8800 loss=3.425 time=3.345
2024-11-16 07:59:34,794 - INFO - train_step=8800 avg_return=-159.141
2024-11-16 07:59:38,763 - INFO - train_step=8840 loss=3.247 time=49.024
2024-11-16 07:59:42,743 - INFO - train_step=8880 loss=3.025 time=3.980
2024-11-16 07:59:46,782 - INFO - train_step=8920 loss=4.029 time=4.038
2024-11-16 07:59:50,428 - INFO - train_step=8960 loss=3.856 time=3.646
2024-11-16 07:59:53,815 - INFO - train_step=9000 loss=2.934 time=3.387
2024-11-16 08:00:39,991 - INFO - train_step=9000 avg_return=-384.554
2024-11-16 08:00:44,005 - INFO - train_step=9040 loss=2.956 time=50.190
2024-11-16 08:00:48,000 - INFO - train_step=9080 loss=3.921 time=3.995
2024-11-16 08:00:52,116 - INFO - train_step=9120 loss=3.104 time=4.116
2024-11-16 08:00:55,567 - INFO - train_step=9160 loss=3.365 time=3.451
2024-11-16 08:00:58,845 - INFO - train_step=9200 loss=2.391 time=3.278
2024-11-16 08:01:44,072 - INFO - train_step=9200 avg_return=-151.383
2024-11-16 08:01:48,076 - INFO - train_step=9240 loss=3.105 time=49.231
2024-11-16 08:01:52,107 - INFO - train_step=9280 loss=2.361 time=4.030
2024-11-16 08:01:56,279 - INFO - train_step=9320 loss=3.054 time=4.172
2024-11-16 08:01:59,796 - INFO - train_step=9360 loss=3.280 time=3.518
2024-11-16 08:02:02,994 - INFO - train_step=9400 loss=2.693 time=3.198
2024-11-16 08:02:47,468 - INFO - train_step=9400 avg_return=-162.104
2024-11-16 08:02:51,518 - INFO - train_step=9440 loss=3.141 time=48.524
2024-11-16 08:02:55,675 - INFO - train_step=9480 loss=2.818 time=4.156
2024-11-16 08:02:59,779 - INFO - train_step=9520 loss=3.055 time=4.104
2024-11-16 08:03:03,567 - INFO - train_step=9560 loss=2.936 time=3.788
2024-11-16 08:03:07,207 - INFO - train_step=9600 loss=3.118 time=3.640
2024-11-16 08:03:52,416 - INFO - train_step=9600 avg_return=-157.978
2024-11-16 08:03:56,449 - INFO - train_step=9640 loss=2.902 time=49.242
2024-11-16 08:04:00,445 - INFO - train_step=9680 loss=2.711 time=3.996
2024-11-16 08:04:04,558 - INFO - train_step=9720 loss=3.192 time=4.113
2024-11-16 08:04:08,300 - INFO - train_step=9760 loss=1.906 time=3.741
2024-11-16 08:04:11,562 - INFO - train_step=9800 loss=3.437 time=3.263
2024-11-16 08:04:55,574 - INFO - train_step=9800 avg_return=-99.462
2024-11-16 08:04:59,499 - INFO - train_step=9840 loss=3.325 time=47.937
2024-11-16 08:05:03,544 - INFO - train_step=9880 loss=2.203 time=4.045
2024-11-16 08:05:07,534 - INFO - train_step=9920 loss=3.123 time=3.990
2024-11-16 08:05:11,524 - INFO - train_step=9960 loss=3.100 time=3.990
2024-11-16 08:05:15,118 - INFO - train_step=10000 loss=3.753 time=3.594
2024-11-16 08:05:57,631 - INFO - train_step=10000 avg_return=-190.696
2024-11-16 08:05:57,631 - INFO - total_time=3264.876
2024-11-16 08:05:57,631 - INFO - saving, checkpointPath_toSave=./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model
2024-11-16 08:05:57,632 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/0
2024-11-16 08:05:57,668 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/0/ckpt-10000
2024-11-16 08:05:57,668 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/1
2024-11-16 08:05:57,683 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/1/ckpt-10000
2024-11-16 08:05:57,684 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/2
2024-11-16 08:05:57,700 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/2/ckpt-10000
2024-11-16 08:05:57,701 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/3
2024-11-16 08:05:57,716 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/3/ckpt-10000
2024-11-16 08:05:57,716 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/4
2024-11-16 08:05:57,728 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_CDQN_multiagent_1116_071050/model/4/ckpt-10000
