2024-11-09 06:43:38.622622: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-09 06:43:38.622679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-09 06:43:38.623384: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-09 06:43:38.628143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-09 06:43:39.198417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'DaisoSokcho_discrete', '-a', 'DQN_multiagent', '-n', '3']
2024-11-09 06:43:40.690200: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-09 06:43:40.690239: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-09 06:43:40.690244: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-09 06:43:40.690399: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-09 06:43:40.690418: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-09 06:43:40.690422: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-09 06:43:40,704 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 50000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-09 06:43:40,704 - INFO - args=Namespace(environment='DaisoSokcho_discrete', environment_wrapper=None, agent='DQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3)
2024-11-09 06:43:40,704 - INFO - environment=DaisoSokcho_discrete
2024-11-09 06:43:40,704 - INFO - envWrapper=None
2024-11-09 06:43:40,704 - INFO - agent=DQN_multiagent
Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

2024-11-09 06:43:41,367 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))
2024-11-09 06:43:41,367 - INFO - tf_action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32))
2024-11-09 06:43:41,367 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))})
2024-11-09 06:43:41,583 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32)),
 'action': BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 06:43:41,705 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 06:44:07,459 - INFO - random_policy avg_return=-338.53436279296875
2024-11-09 06:44:07,459 - INFO - replay_buffer.capacity=10000
2024-11-09 06:44:07,462 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-09 06:49:30,163 - INFO - after filling with random_policies, replay_buffer.num_frames()=10000
2024-11-09 06:50:21,302 - INFO - before training, avg_return=-564.9728393554688
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 06:50:21,405 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
WARNING:tensorflow:5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7fb0604afeb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 06:50:45,796 - WARNING - 5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7fb0604afeb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 06:51:03,738 - INFO - train_step=200 loss=42117608.000 time=42.434
2024-11-09 06:51:22,841 - INFO - train_step=400 loss=499352800.000 time=19.103
2024-11-09 06:51:43,904 - INFO - train_step=600 loss=1415559936.000 time=21.063
2024-11-09 06:52:05,198 - INFO - train_step=800 loss=1234081152.000 time=21.294
2024-11-09 06:52:26,170 - INFO - train_step=1000 loss=2663050752.000 time=20.972
2024-11-09 06:53:12,517 - INFO - train_step=1000 avg_return=-447.243
2024-11-09 06:53:29,263 - INFO - train_step=1200 loss=93397630976.000 time=63.094
2024-11-09 06:53:47,476 - INFO - train_step=1400 loss=199372636160.000 time=18.212
2024-11-09 06:54:08,425 - INFO - train_step=1600 loss=65382764544.000 time=20.949
2024-11-09 06:54:29,515 - INFO - train_step=1800 loss=179689521152.000 time=21.090
2024-11-09 06:54:50,765 - INFO - train_step=2000 loss=276867317760.000 time=21.251
2024-11-09 06:55:41,077 - INFO - train_step=2000 avg_return=-463.295
2024-11-09 06:55:56,012 - INFO - train_step=2200 loss=14736615424.000 time=65.246
2024-11-09 06:56:13,455 - INFO - train_step=2400 loss=11851507712.000 time=17.444
2024-11-09 06:56:32,619 - INFO - train_step=2600 loss=51594846208.000 time=19.164
2024-11-09 06:56:53,865 - INFO - train_step=2800 loss=26105554944.000 time=21.246
2024-11-09 06:57:14,628 - INFO - train_step=3000 loss=8882031616.000 time=20.763
2024-11-09 06:58:07,514 - INFO - train_step=3000 avg_return=-454.618
2024-11-09 06:58:22,909 - INFO - train_step=3200 loss=9528045568.000 time=68.281
2024-11-09 06:58:39,301 - INFO - train_step=3400 loss=8643366912.000 time=16.392
2024-11-09 06:58:57,856 - INFO - train_step=3600 loss=9230778368.000 time=18.555
2024-11-09 06:59:18,712 - INFO - train_step=3800 loss=6590880256.000 time=20.855
2024-11-09 06:59:39,987 - INFO - train_step=4000 loss=6550811648.000 time=21.275
2024-11-09 07:00:34,932 - INFO - train_step=4000 avg_return=-233.477
2024-11-09 07:00:51,957 - INFO - train_step=4200 loss=2450112000.000 time=71.971
2024-11-09 07:01:06,860 - INFO - train_step=4400 loss=958909312.000 time=14.903
2024-11-09 07:01:24,349 - INFO - train_step=4600 loss=966117888.000 time=17.489
2024-11-09 07:01:43,620 - INFO - train_step=4800 loss=667336448.000 time=19.271
2024-11-09 07:02:04,929 - INFO - train_step=5000 loss=900885952.000 time=21.309
2024-11-09 07:03:01,073 - INFO - train_step=5000 avg_return=-352.031
2024-11-09 07:03:19,080 - INFO - train_step=5200 loss=1555135104.000 time=74.151
2024-11-09 07:03:34,478 - INFO - train_step=5400 loss=507599424.000 time=15.398
2024-11-09 07:03:50,620 - INFO - train_step=5600 loss=450685248.000 time=16.143
2024-11-09 07:04:09,018 - INFO - train_step=5800 loss=90076792.000 time=18.398
2024-11-09 07:04:30,241 - INFO - train_step=6000 loss=349969248.000 time=21.223
2024-11-09 07:05:26,884 - INFO - train_step=6000 avg_return=-315.202
2024-11-09 07:05:45,711 - INFO - train_step=6200 loss=170204736.000 time=75.470
2024-11-09 07:06:02,865 - INFO - train_step=6400 loss=256524224.000 time=17.155
2024-11-09 07:06:17,561 - INFO - train_step=6600 loss=247700480.000 time=14.696
2024-11-09 07:06:35,376 - INFO - train_step=6800 loss=63997312.000 time=17.815
2024-11-09 07:06:54,447 - INFO - train_step=7000 loss=189583200.000 time=19.070
2024-11-09 07:07:51,176 - INFO - train_step=7000 avg_return=-367.290
2024-11-09 07:08:11,239 - INFO - train_step=7200 loss=36039620.000 time=76.792
2024-11-09 07:08:29,334 - INFO - train_step=7400 loss=219743440.000 time=18.095
2024-11-09 07:08:45,165 - INFO - train_step=7600 loss=52127492.000 time=15.831
2024-11-09 07:09:01,471 - INFO - train_step=7800 loss=69118976.000 time=16.307
2024-11-09 07:09:19,701 - INFO - train_step=8000 loss=27606446.000 time=18.230
2024-11-09 07:10:15,578 - INFO - train_step=8000 avg_return=-260.345
2024-11-09 07:10:36,455 - INFO - train_step=8200 loss=9185332.000 time=76.754
2024-11-09 07:10:54,981 - INFO - train_step=8400 loss=16999146.000 time=18.526
2024-11-09 07:11:12,443 - INFO - train_step=8600 loss=14131727.000 time=17.462
2024-11-09 07:11:26,957 - INFO - train_step=8800 loss=17685636.000 time=14.514
2024-11-09 07:11:44,746 - INFO - train_step=9000 loss=14481554.000 time=17.789
2024-11-09 07:12:39,593 - INFO - train_step=9000 avg_return=-229.086
2024-11-09 07:13:01,073 - INFO - train_step=9200 loss=5357765.000 time=76.327
2024-11-09 07:13:21,067 - INFO - train_step=9400 loss=2644225.500 time=19.994
2024-11-09 07:13:39,319 - INFO - train_step=9600 loss=4438403.500 time=18.251
2024-11-09 07:13:54,950 - INFO - train_step=9800 loss=13019233.000 time=15.631
2024-11-09 07:14:10,872 - INFO - train_step=10000 loss=5856520.000 time=15.923
2024-11-09 07:15:02,889 - INFO - train_step=10000 avg_return=-225.427
2024-11-09 07:15:23,889 - INFO - train_step=10200 loss=10121178.000 time=73.016
2024-11-09 07:15:45,010 - INFO - train_step=10400 loss=7819721.500 time=21.121
2024-11-09 07:16:03,693 - INFO - train_step=10600 loss=26564780.000 time=18.683
2024-11-09 07:16:21,324 - INFO - train_step=10800 loss=9195871.000 time=17.631
2024-11-09 07:16:35,722 - INFO - train_step=11000 loss=12048819.000 time=14.397
2024-11-09 07:17:26,991 - INFO - train_step=11000 avg_return=-180.258
2024-11-09 07:17:47,956 - INFO - train_step=11200 loss=11459678.000 time=72.234
2024-11-09 07:18:08,648 - INFO - train_step=11400 loss=7209653.500 time=20.692
2024-11-09 07:18:28,519 - INFO - train_step=11600 loss=7955882.000 time=19.870
2024-11-09 07:18:46,480 - INFO - train_step=11800 loss=16370464.000 time=17.961
2024-11-09 07:19:01,647 - INFO - train_step=12000 loss=8060813.500 time=15.167
2024-11-09 07:19:48,985 - INFO - train_step=12000 avg_return=-223.846
2024-11-09 07:20:09,729 - INFO - train_step=12200 loss=2727195.250 time=68.083
2024-11-09 07:20:30,411 - INFO - train_step=12400 loss=3761726.750 time=20.682
2024-11-09 07:20:51,200 - INFO - train_step=12600 loss=2288188.500 time=20.788
2024-11-09 07:21:10,015 - INFO - train_step=12800 loss=1298111.625 time=18.816
2024-11-09 07:21:27,835 - INFO - train_step=13000 loss=939279.938 time=17.819
2024-11-09 07:22:12,959 - INFO - train_step=13000 avg_return=-313.762
2024-11-09 07:22:33,563 - INFO - train_step=13200 loss=334582.094 time=65.728
2024-11-09 07:22:54,281 - INFO - train_step=13400 loss=288589.344 time=20.718
2024-11-09 07:23:14,971 - INFO - train_step=13600 loss=287294.375 time=20.690
2024-11-09 07:23:34,653 - INFO - train_step=13800 loss=324090.062 time=19.683
2024-11-09 07:23:52,972 - INFO - train_step=14000 loss=225439.250 time=18.319
2024-11-09 07:24:36,624 - INFO - train_step=14000 avg_return=-370.725
2024-11-09 07:24:55,828 - INFO - train_step=14200 loss=180281.141 time=62.856
2024-11-09 07:25:16,726 - INFO - train_step=14400 loss=100491.578 time=20.898
2024-11-09 07:25:37,436 - INFO - train_step=14600 loss=164711.156 time=20.710
2024-11-09 07:25:58,363 - INFO - train_step=14800 loss=72168472.000 time=20.927
2024-11-09 07:26:17,221 - INFO - train_step=15000 loss=1612894464.000 time=18.858
2024-11-09 07:27:01,408 - INFO - train_step=15000 avg_return=-254.518
2024-11-09 07:27:19,772 - INFO - train_step=15200 loss=709775936.000 time=62.551
2024-11-09 07:27:40,262 - INFO - train_step=15400 loss=405336448.000 time=20.490
2024-11-09 07:28:01,248 - INFO - train_step=15600 loss=316783328.000 time=20.986
2024-11-09 07:28:22,071 - INFO - train_step=15800 loss=134805600.000 time=20.823
2024-11-09 07:28:41,392 - INFO - train_step=16000 loss=88407904.000 time=19.320
2024-11-09 07:29:24,652 - INFO - train_step=16000 avg_return=-189.366
2024-11-09 07:29:42,723 - INFO - train_step=16200 loss=25619760.000 time=61.331
2024-11-09 07:30:02,208 - INFO - train_step=16400 loss=25786616.000 time=19.485
2024-11-09 07:30:23,734 - INFO - train_step=16600 loss=10610584.000 time=21.526
2024-11-09 07:30:44,678 - INFO - train_step=16800 loss=2917832.000 time=20.945
2024-11-09 07:31:05,546 - INFO - train_step=17000 loss=7159654.000 time=20.867
2024-11-09 07:31:50,651 - INFO - train_step=17000 avg_return=-267.853
2024-11-09 07:32:07,910 - INFO - train_step=17200 loss=9578378.000 time=62.364
2024-11-09 07:32:26,521 - INFO - train_step=17400 loss=43135844.000 time=18.612
2024-11-09 07:32:47,016 - INFO - train_step=17600 loss=4583048.000 time=20.495
2024-11-09 07:33:07,838 - INFO - train_step=17800 loss=48610060.000 time=20.822
2024-11-09 07:33:28,520 - INFO - train_step=18000 loss=33571932.000 time=20.682
2024-11-09 07:34:17,282 - INFO - train_step=18000 avg_return=-360.941
2024-11-09 07:34:33,067 - INFO - train_step=18200 loss=2866341.500 time=64.546
2024-11-09 07:34:51,276 - INFO - train_step=18400 loss=4589234.500 time=18.209
2024-11-09 07:35:11,003 - INFO - train_step=18600 loss=1283028.375 time=19.727
2024-11-09 07:35:31,930 - INFO - train_step=18800 loss=1403277.750 time=20.927
2024-11-09 07:35:52,643 - INFO - train_step=19000 loss=1191446.500 time=20.714
2024-11-09 07:36:43,159 - INFO - train_step=19000 avg_return=-318.637
2024-11-09 07:36:58,096 - INFO - train_step=19200 loss=1378429.500 time=65.453
2024-11-09 07:37:15,540 - INFO - train_step=19400 loss=593941.062 time=17.444
2024-11-09 07:37:34,080 - INFO - train_step=19600 loss=280014.562 time=18.540
2024-11-09 07:37:54,530 - INFO - train_step=19800 loss=435402.312 time=20.449
2024-11-09 07:38:16,012 - INFO - train_step=20000 loss=1502104.250 time=21.483
2024-11-09 07:39:09,556 - INFO - train_step=20000 avg_return=-295.588
2024-11-09 07:39:26,101 - INFO - train_step=20200 loss=1570171.625 time=70.088
2024-11-09 07:39:42,120 - INFO - train_step=20400 loss=3196497.500 time=16.019
2024-11-09 07:40:00,786 - INFO - train_step=20600 loss=1275677.375 time=18.666
2024-11-09 07:40:20,910 - INFO - train_step=20800 loss=561752.188 time=20.124
2024-11-09 07:40:41,967 - INFO - train_step=21000 loss=311690.500 time=21.056
2024-11-09 07:41:36,623 - INFO - train_step=21000 avg_return=-319.236
2024-11-09 07:41:54,253 - INFO - train_step=21200 loss=180401.625 time=72.286
2024-11-09 07:42:10,317 - INFO - train_step=21400 loss=659513.625 time=16.064
2024-11-09 07:42:28,082 - INFO - train_step=21600 loss=1855944.750 time=17.765
2024-11-09 07:42:47,190 - INFO - train_step=21800 loss=2125982.500 time=19.108
2024-11-09 07:43:07,991 - INFO - train_step=22000 loss=5906590.500 time=20.800
2024-11-09 07:44:04,409 - INFO - train_step=22000 avg_return=-343.139
2024-11-09 07:44:22,620 - INFO - train_step=22200 loss=14592586.000 time=74.630
2024-11-09 07:44:39,989 - INFO - train_step=22400 loss=885795.875 time=17.369
2024-11-09 07:44:55,791 - INFO - train_step=22600 loss=453460.625 time=15.802
2024-11-09 07:45:14,561 - INFO - train_step=22800 loss=97493.203 time=18.769
2024-11-09 07:45:35,032 - INFO - train_step=23000 loss=176257.875 time=20.471
2024-11-09 07:46:31,643 - INFO - train_step=23000 avg_return=-366.124
2024-11-09 07:46:51,551 - INFO - train_step=23200 loss=212256.938 time=76.519
2024-11-09 07:47:11,084 - INFO - train_step=23400 loss=117278.109 time=19.534
2024-11-09 07:47:28,941 - INFO - train_step=23600 loss=58333.832 time=17.857
2024-11-09 07:47:48,563 - INFO - train_step=23800 loss=149877.422 time=19.622
2024-11-09 07:48:09,641 - INFO - train_step=24000 loss=75501.484 time=21.078
2024-11-09 07:49:07,405 - INFO - train_step=24000 avg_return=-434.783
2024-11-09 07:49:27,893 - INFO - train_step=24200 loss=76117.305 time=78.252
2024-11-09 07:49:47,343 - INFO - train_step=24400 loss=26359.359 time=19.450
2024-11-09 07:50:06,179 - INFO - train_step=24600 loss=33201.520 time=18.836
2024-11-09 07:50:24,093 - INFO - train_step=24800 loss=24842.730 time=17.914
2024-11-09 07:50:44,002 - INFO - train_step=25000 loss=54060.984 time=19.909
2024-11-09 07:51:41,303 - INFO - train_step=25000 avg_return=-331.160
2024-11-09 07:52:02,165 - INFO - train_step=25200 loss=33451.941 time=78.163
2024-11-09 07:52:22,202 - INFO - train_step=25400 loss=64980.449 time=20.037
2024-11-09 07:52:41,561 - INFO - train_step=25600 loss=37291.102 time=19.359
2024-11-09 07:53:00,249 - INFO - train_step=25800 loss=1070938.625 time=18.689
2024-11-09 07:53:19,848 - INFO - train_step=26000 loss=1194683.000 time=19.599
2024-11-09 07:54:16,294 - INFO - train_step=26000 avg_return=-268.567
2024-11-09 07:54:37,173 - INFO - train_step=26200 loss=105449.484 time=77.324
2024-11-09 07:54:58,052 - INFO - train_step=26400 loss=128398.156 time=20.879
2024-11-09 07:55:17,908 - INFO - train_step=26600 loss=92521.797 time=19.856
2024-11-09 07:55:36,660 - INFO - train_step=26800 loss=26045.127 time=18.752
2024-11-09 07:55:54,572 - INFO - train_step=27000 loss=32144.613 time=17.912
2024-11-09 07:56:50,740 - INFO - train_step=27000 avg_return=-268.719
2024-11-09 07:57:11,969 - INFO - train_step=27200 loss=24067.906 time=77.397
2024-11-09 07:57:34,057 - INFO - train_step=27400 loss=31116.035 time=22.088
2024-11-09 07:57:54,357 - INFO - train_step=27600 loss=36189.820 time=20.300
2024-11-09 07:58:13,913 - INFO - train_step=27800 loss=4618564.500 time=19.556
2024-11-09 07:58:32,057 - INFO - train_step=28000 loss=1638446.750 time=18.144
2024-11-09 07:59:26,594 - INFO - train_step=28000 avg_return=-373.144
2024-11-09 07:59:47,963 - INFO - train_step=28200 loss=879993.000 time=75.906
2024-11-09 08:00:09,067 - INFO - train_step=28400 loss=5370852.500 time=21.104
2024-11-09 08:00:30,058 - INFO - train_step=28600 loss=645402.125 time=20.991
2024-11-09 08:00:50,103 - INFO - train_step=28800 loss=114706.625 time=20.046
2024-11-09 08:01:08,707 - INFO - train_step=29000 loss=90431.289 time=18.603
2024-11-09 08:02:01,243 - INFO - train_step=29000 avg_return=-255.037
2024-11-09 08:02:23,576 - INFO - train_step=29200 loss=227550.844 time=74.870
2024-11-09 08:02:44,924 - INFO - train_step=29400 loss=1208945.500 time=21.348
2024-11-09 08:03:05,986 - INFO - train_step=29600 loss=392627.938 time=21.062
2024-11-09 08:03:25,993 - INFO - train_step=29800 loss=60439.973 time=20.007
2024-11-09 08:03:45,535 - INFO - train_step=30000 loss=130419.250 time=19.542
2024-11-09 08:04:36,021 - INFO - train_step=30000 avg_return=-522.918
2024-11-09 08:04:57,257 - INFO - train_step=30200 loss=59608.383 time=71.722
2024-11-09 08:05:18,720 - INFO - train_step=30400 loss=28727.984 time=21.463
2024-11-09 08:05:39,767 - INFO - train_step=30600 loss=12302.357 time=21.047
2024-11-09 08:06:00,581 - INFO - train_step=30800 loss=9908.768 time=20.814
2024-11-09 08:06:20,687 - INFO - train_step=31000 loss=15480.336 time=20.105
2024-11-09 08:07:10,605 - INFO - train_step=31000 avg_return=-414.704
2024-11-09 08:07:31,619 - INFO - train_step=31200 loss=10165.699 time=70.932
2024-11-09 08:07:53,282 - INFO - train_step=31400 loss=8639.968 time=21.663
2024-11-09 08:08:14,758 - INFO - train_step=31600 loss=15534.178 time=21.476
2024-11-09 08:08:35,815 - INFO - train_step=31800 loss=179839.125 time=21.057
2024-11-09 08:08:56,165 - INFO - train_step=32000 loss=10467.744 time=20.350
2024-11-09 08:09:46,009 - INFO - train_step=32000 avg_return=-430.790
2024-11-09 08:10:06,634 - INFO - train_step=32200 loss=21557.219 time=70.469
2024-11-09 08:10:27,647 - INFO - train_step=32400 loss=17492.615 time=21.013
2024-11-09 08:10:48,984 - INFO - train_step=32600 loss=312979.406 time=21.337
2024-11-09 08:11:10,006 - INFO - train_step=32800 loss=28783.299 time=21.022
2024-11-09 08:11:30,551 - INFO - train_step=33000 loss=408718.750 time=20.545
2024-11-09 08:12:21,464 - INFO - train_step=33000 avg_return=-305.010
2024-11-09 08:12:40,801 - INFO - train_step=33200 loss=2870327.250 time=70.250
2024-11-09 08:13:02,269 - INFO - train_step=33400 loss=3985342.500 time=21.468
2024-11-09 08:13:24,220 - INFO - train_step=33600 loss=68103.609 time=21.951
2024-11-09 08:13:45,479 - INFO - train_step=33800 loss=46534.727 time=21.259
2024-11-09 08:14:06,597 - INFO - train_step=34000 loss=17682.035 time=21.118
2024-11-09 08:14:57,686 - INFO - train_step=34000 avg_return=-393.350
2024-11-09 08:15:16,862 - INFO - train_step=34200 loss=19738.828 time=70.266
2024-11-09 08:15:37,518 - INFO - train_step=34400 loss=14698.809 time=20.656
2024-11-09 08:15:58,580 - INFO - train_step=34600 loss=22325.562 time=21.062
2024-11-09 08:16:20,404 - INFO - train_step=34800 loss=26100.219 time=21.823
2024-11-09 08:16:41,528 - INFO - train_step=35000 loss=76453.180 time=21.125
2024-11-09 08:17:33,733 - INFO - train_step=35000 avg_return=-406.188
2024-11-09 08:17:52,750 - INFO - train_step=35200 loss=432577.406 time=71.222
2024-11-09 08:18:11,954 - INFO - train_step=35400 loss=29494.947 time=19.204
2024-11-09 08:18:33,162 - INFO - train_step=35600 loss=13204.486 time=21.209
2024-11-09 08:18:54,563 - INFO - train_step=35800 loss=20430.355 time=21.401
2024-11-09 08:19:16,028 - INFO - train_step=36000 loss=17243.164 time=21.464
2024-11-09 08:20:09,487 - INFO - train_step=36000 avg_return=-362.107
2024-11-09 08:20:28,185 - INFO - train_step=36200 loss=9525.733 time=72.158
2024-11-09 08:20:47,001 - INFO - train_step=36400 loss=17839.252 time=18.816
2024-11-09 08:21:07,913 - INFO - train_step=36600 loss=15743.699 time=20.911
2024-11-09 08:21:29,039 - INFO - train_step=36800 loss=26127.857 time=21.126
2024-11-09 08:21:50,202 - INFO - train_step=37000 loss=32869.547 time=21.163
2024-11-09 08:22:45,338 - INFO - train_step=37000 avg_return=-194.726
2024-11-09 08:23:04,116 - INFO - train_step=37200 loss=12743.156 time=73.914
2024-11-09 08:23:23,242 - INFO - train_step=37400 loss=608643.312 time=19.126
2024-11-09 08:23:42,200 - INFO - train_step=37600 loss=40248.328 time=18.958
2024-11-09 08:24:03,730 - INFO - train_step=37800 loss=38876.379 time=21.530
2024-11-09 08:24:25,021 - INFO - train_step=38000 loss=219926.547 time=21.291
2024-11-09 08:25:20,801 - INFO - train_step=38000 avg_return=-224.103
2024-11-09 08:25:40,771 - INFO - train_step=38200 loss=60007.160 time=75.750
2024-11-09 08:25:59,602 - INFO - train_step=38400 loss=21191.891 time=18.831
2024-11-09 08:26:18,497 - INFO - train_step=38600 loss=7333.704 time=18.895
2024-11-09 08:26:38,788 - INFO - train_step=38800 loss=13138.988 time=20.292
2024-11-09 08:27:00,037 - INFO - train_step=39000 loss=9024.836 time=21.249
2024-11-09 08:27:56,568 - INFO - train_step=39000 avg_return=-376.878
2024-11-09 08:28:16,523 - INFO - train_step=39200 loss=8599.538 time=76.485
2024-11-09 08:28:35,306 - INFO - train_step=39400 loss=9220.410 time=18.784
2024-11-09 08:28:54,648 - INFO - train_step=39600 loss=4412.420 time=19.342
2024-11-09 08:29:14,406 - INFO - train_step=39800 loss=4861.599 time=19.758
2024-11-09 08:29:35,507 - INFO - train_step=40000 loss=6707.616 time=21.101
2024-11-09 08:30:32,340 - INFO - train_step=40000 avg_return=-418.278
2024-11-09 08:30:52,528 - INFO - train_step=40200 loss=54341.242 time=77.020
2024-11-09 08:31:12,146 - INFO - train_step=40400 loss=19205.441 time=19.618
2024-11-09 08:31:30,579 - INFO - train_step=40600 loss=9029.053 time=18.433
2024-11-09 08:31:50,088 - INFO - train_step=40800 loss=1175159.750 time=19.509
2024-11-09 08:32:11,026 - INFO - train_step=41000 loss=18593.812 time=20.939
2024-11-09 08:33:08,511 - INFO - train_step=41000 avg_return=-331.151
2024-11-09 08:33:29,162 - INFO - train_step=41200 loss=10026.197 time=78.135
2024-11-09 08:33:48,842 - INFO - train_step=41400 loss=318271.531 time=19.680
2024-11-09 08:34:07,277 - INFO - train_step=41600 loss=295599.500 time=18.435
2024-11-09 08:34:26,314 - INFO - train_step=41800 loss=16783.182 time=19.037
2024-11-09 08:34:46,562 - INFO - train_step=42000 loss=18762.852 time=20.248
2024-11-09 08:35:43,320 - INFO - train_step=42000 avg_return=-198.149
2024-11-09 08:36:04,433 - INFO - train_step=42200 loss=7813.219 time=77.871
2024-11-09 08:36:24,478 - INFO - train_step=42400 loss=5982.467 time=20.045
2024-11-09 08:36:43,531 - INFO - train_step=42600 loss=11726.973 time=19.053
2024-11-09 08:37:02,225 - INFO - train_step=42800 loss=19247.662 time=18.694
2024-11-09 08:37:22,154 - INFO - train_step=43000 loss=671708.812 time=19.930
2024-11-09 08:38:17,792 - INFO - train_step=43000 avg_return=-454.870
2024-11-09 08:38:38,698 - INFO - train_step=43200 loss=250444.266 time=76.544
2024-11-09 08:38:59,504 - INFO - train_step=43400 loss=22678.174 time=20.806
2024-11-09 08:39:19,295 - INFO - train_step=43600 loss=7000.393 time=19.792
2024-11-09 08:39:37,976 - INFO - train_step=43800 loss=5137.107 time=18.681
2024-11-09 08:39:57,524 - INFO - train_step=44000 loss=28952876.000 time=19.547
2024-11-09 08:40:52,942 - INFO - train_step=44000 avg_return=-315.710
2024-11-09 08:41:13,531 - INFO - train_step=44200 loss=575088.625 time=76.008
2024-11-09 08:41:34,569 - INFO - train_step=44400 loss=54873.824 time=21.037
2024-11-09 08:41:54,846 - INFO - train_step=44600 loss=40515.809 time=20.278
2024-11-09 08:42:14,002 - INFO - train_step=44800 loss=22638.125 time=19.156
2024-11-09 08:42:32,874 - INFO - train_step=45000 loss=13739.791 time=18.872
2024-11-09 08:43:27,609 - INFO - train_step=45000 avg_return=-448.898
2024-11-09 08:43:48,228 - INFO - train_step=45200 loss=14613.424 time=75.354
2024-11-09 08:44:09,143 - INFO - train_step=45400 loss=9934.177 time=20.915
2024-11-09 08:44:30,425 - INFO - train_step=45600 loss=8935.705 time=21.282
2024-11-09 08:44:50,293 - INFO - train_step=45800 loss=8753.492 time=19.867
2024-11-09 08:45:08,734 - INFO - train_step=46000 loss=20180.094 time=18.442
2024-11-09 08:46:01,563 - INFO - train_step=46000 avg_return=-249.147
2024-11-09 08:46:22,722 - INFO - train_step=46200 loss=15928.364 time=73.988
2024-11-09 08:46:43,137 - INFO - train_step=46400 loss=22471.328 time=20.415
2024-11-09 08:47:04,197 - INFO - train_step=46600 loss=10042.729 time=21.060
2024-11-09 08:47:24,112 - INFO - train_step=46800 loss=6774.748 time=19.914
2024-11-09 08:47:43,174 - INFO - train_step=47000 loss=7222.149 time=19.062
2024-11-09 08:48:35,375 - INFO - train_step=47000 avg_return=-442.483
2024-11-09 08:48:56,740 - INFO - train_step=47200 loss=5983.084 time=73.567
2024-11-09 08:49:17,174 - INFO - train_step=47400 loss=8751.277 time=20.434
2024-11-09 08:49:37,873 - INFO - train_step=47600 loss=2890220.250 time=20.698
2024-11-09 08:49:58,957 - INFO - train_step=47800 loss=86387.094 time=21.084
2024-11-09 08:50:18,730 - INFO - train_step=48000 loss=25249.301 time=19.774
2024-11-09 08:51:10,113 - INFO - train_step=48000 avg_return=-290.611
2024-11-09 08:51:31,306 - INFO - train_step=48200 loss=6774.703 time=72.576
2024-11-09 08:51:52,371 - INFO - train_step=48400 loss=5119.979 time=21.064
2024-11-09 08:52:12,269 - INFO - train_step=48600 loss=5327.442 time=19.898
2024-11-09 08:52:33,338 - INFO - train_step=48800 loss=16144165.000 time=21.069
2024-11-09 08:52:53,738 - INFO - train_step=49000 loss=4591733.500 time=20.401
2024-11-09 08:53:44,806 - INFO - train_step=49000 avg_return=-150.391
2024-11-09 08:54:05,783 - INFO - train_step=49200 loss=125821.289 time=72.045
2024-11-09 08:54:27,013 - INFO - train_step=49400 loss=73991.859 time=21.229
2024-11-09 08:54:47,598 - INFO - train_step=49600 loss=40207.094 time=20.585
2024-11-09 08:55:08,491 - INFO - train_step=49800 loss=32445.359 time=20.893
2024-11-09 08:55:29,436 - INFO - train_step=50000 loss=18697.416 time=20.946
2024-11-09 08:56:19,923 - INFO - train_step=50000 avg_return=-134.280
2024-11-09 08:56:19,923 - INFO - total_time=7609.760
2024-11-09 08:56:19,923 - INFO - saving, checkpointPath_toSave=./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model
2024-11-09 08:56:19,924 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/0
2024-11-09 08:56:19,960 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/0/ckpt-50000
2024-11-09 08:56:19,960 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/1
2024-11-09 08:56:19,990 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/1/ckpt-50000
2024-11-09 08:56:19,991 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/2
2024-11-09 08:56:20,013 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/2/ckpt-50000
2024-11-09 08:56:20,014 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/3
2024-11-09 08:56:20,031 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/3/ckpt-50000
2024-11-09 08:56:20,032 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/4
2024-11-09 08:56:20,044 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_064340/model/4/ckpt-50000
