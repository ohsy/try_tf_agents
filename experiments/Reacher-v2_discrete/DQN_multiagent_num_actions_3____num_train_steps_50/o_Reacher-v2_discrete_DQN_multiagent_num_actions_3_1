2024-11-09 13:04:11.168963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-09 13:04:11.169022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-09 13:04:11.169948: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-09 13:04:11.176651: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-09 13:04:12.090808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'Reacher-v2_discrete', '-a', 'DQN_multiagent', '-n', '3']
2024-11-09 13:04:14.259562: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-09 13:04:14.259618: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-09 13:04:14.259624: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-09 13:04:14.259810: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-09 13:04:14.259839: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-09 13:04:14.259845: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-09 13:04:14,277 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 50, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-09 13:04:14,277 - INFO - args=Namespace(environment='Reacher-v2_discrete', environment_wrapper=None, agent='DQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3)
2024-11-09 13:04:14,277 - INFO - environment=Reacher-v2_discrete
2024-11-09 13:04:14,277 - INFO - envWrapper=None
2024-11-09 13:04:14,277 - INFO - agent=DQN_multiagent
2024-11-09 13:04:14,414 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))
2024-11-09 13:04:14,415 - INFO - tf_action_spec: BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))
2024-11-09 13:04:14,415 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))})
2024-11-09 13:04:14,559 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308)),
 'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 13:04:14,743 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 13:04:17,715 - INFO - random_policy avg_return=-77.63558197021484
2024-11-09 13:04:17,715 - INFO - replay_buffer.capacity=10000
2024-11-09 13:04:17,720 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-09 13:05:17,745 - INFO - after filling with random_policies, replay_buffer.num_frames()=10000
2024-11-09 13:05:25,153 - INFO - before training, avg_return=-61.63608932495117
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 13:05:25,218 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 13:05:40,800 - INFO - train_step=1 loss=3.415 time=15.646
2024-11-09 13:05:48,334 - INFO - train_step=1 avg_return=-33.278
2024-11-09 13:05:48,368 - INFO - train_step=2 loss=2.914 time=7.568
2024-11-09 13:05:55,500 - INFO - train_step=2 avg_return=-14.346
2024-11-09 13:05:55,529 - INFO - train_step=3 loss=2.413 time=7.162
2024-11-09 13:06:02,936 - INFO - train_step=3 avg_return=-12.075
2024-11-09 13:06:02,970 - INFO - train_step=4 loss=3.336 time=7.440
2024-11-09 13:06:10,336 - INFO - train_step=4 avg_return=-13.423
2024-11-09 13:06:10,368 - INFO - train_step=5 loss=3.564 time=7.398
2024-11-09 13:06:17,766 - INFO - train_step=5 avg_return=-12.138
2024-11-09 13:06:17,799 - INFO - train_step=6 loss=3.182 time=7.431
2024-11-09 13:06:25,198 - INFO - train_step=6 avg_return=-10.685
2024-11-09 13:06:25,230 - INFO - train_step=7 loss=3.424 time=7.432
2024-11-09 13:06:31,657 - INFO - train_step=7 avg_return=-10.580
2024-11-09 13:06:31,689 - INFO - train_step=8 loss=3.577 time=6.459
2024-11-09 13:06:39,194 - INFO - train_step=8 avg_return=-8.397
2024-11-09 13:06:39,226 - INFO - train_step=9 loss=3.218 time=7.537
2024-11-09 13:06:45,357 - INFO - train_step=9 avg_return=-11.372
2024-11-09 13:06:45,380 - INFO - train_step=10 loss=3.513 time=6.154
2024-11-09 13:06:50,105 - INFO - train_step=10 avg_return=-8.925
2024-11-09 13:06:50,127 - INFO - train_step=11 loss=2.997 time=4.747
2024-11-09 13:06:54,817 - INFO - train_step=11 avg_return=-12.646
2024-11-09 13:06:54,840 - INFO - train_step=12 loss=3.699 time=4.713
2024-11-09 13:06:59,544 - INFO - train_step=12 avg_return=-15.396
2024-11-09 13:06:59,567 - INFO - train_step=13 loss=3.838 time=4.726
2024-11-09 13:07:06,885 - INFO - train_step=13 avg_return=-11.276
2024-11-09 13:07:06,918 - INFO - train_step=14 loss=4.406 time=7.352
2024-11-09 13:07:12,461 - INFO - train_step=14 avg_return=-11.913
2024-11-09 13:07:12,482 - INFO - train_step=15 loss=4.416 time=5.564
2024-11-09 13:07:17,976 - INFO - train_step=15 avg_return=-12.118
2024-11-09 13:07:18,009 - INFO - train_step=16 loss=4.409 time=5.526
2024-11-09 13:07:25,495 - INFO - train_step=16 avg_return=-12.375
2024-11-09 13:07:25,529 - INFO - train_step=17 loss=4.294 time=7.520
2024-11-09 13:07:33,014 - INFO - train_step=17 avg_return=-11.961
2024-11-09 13:07:33,047 - INFO - train_step=18 loss=5.220 time=7.518
2024-11-09 13:07:40,823 - INFO - train_step=18 avg_return=-11.042
2024-11-09 13:07:40,858 - INFO - train_step=19 loss=3.999 time=7.811
2024-11-09 13:07:48,603 - INFO - train_step=19 avg_return=-11.972
2024-11-09 13:07:48,636 - INFO - train_step=20 loss=4.668 time=7.777
2024-11-09 13:07:56,131 - INFO - train_step=20 avg_return=-11.556
2024-11-09 13:07:56,165 - INFO - train_step=21 loss=7.356 time=7.529
2024-11-09 13:08:03,671 - INFO - train_step=21 avg_return=-11.614
2024-11-09 13:08:03,705 - INFO - train_step=22 loss=11.992 time=7.540
2024-11-09 13:08:11,222 - INFO - train_step=22 avg_return=-10.912
2024-11-09 13:08:11,254 - INFO - train_step=23 loss=5.095 time=7.550
2024-11-09 13:08:18,765 - INFO - train_step=23 avg_return=-13.633
2024-11-09 13:08:18,814 - INFO - train_step=24 loss=5.323 time=7.559
2024-11-09 13:08:26,275 - INFO - train_step=24 avg_return=-11.552
2024-11-09 13:08:26,309 - INFO - train_step=25 loss=15.021 time=7.496
2024-11-09 13:08:33,820 - INFO - train_step=25 avg_return=-11.371
2024-11-09 13:08:33,859 - INFO - train_step=26 loss=9.927 time=7.550
2024-11-09 13:08:41,371 - INFO - train_step=26 avg_return=-10.382
2024-11-09 13:08:41,410 - INFO - train_step=27 loss=6.892 time=7.551
2024-11-09 13:08:48,929 - INFO - train_step=27 avg_return=-10.168
2024-11-09 13:08:48,963 - INFO - train_step=28 loss=7.492 time=7.553
2024-11-09 13:08:56,361 - INFO - train_step=28 avg_return=-8.931
2024-11-09 13:08:56,393 - INFO - train_step=29 loss=13.461 time=7.430
2024-11-09 13:09:03,782 - INFO - train_step=29 avg_return=-10.133
2024-11-09 13:09:03,818 - INFO - train_step=30 loss=11.195 time=7.424
2024-11-09 13:09:11,213 - INFO - train_step=30 avg_return=-12.744
2024-11-09 13:09:11,248 - INFO - train_step=31 loss=10.814 time=7.430
2024-11-09 13:09:16,469 - INFO - train_step=31 avg_return=-11.732
2024-11-09 13:09:16,496 - INFO - train_step=32 loss=27.391 time=5.248
2024-11-09 13:09:23,669 - INFO - train_step=32 avg_return=-9.597
2024-11-09 13:09:23,693 - INFO - train_step=33 loss=21.799 time=7.197
2024-11-09 13:09:31,068 - INFO - train_step=33 avg_return=-8.113
2024-11-09 13:09:31,101 - INFO - train_step=34 loss=18.908 time=7.408
2024-11-09 13:09:38,496 - INFO - train_step=34 avg_return=-12.887
2024-11-09 13:09:38,528 - INFO - train_step=35 loss=39.355 time=7.427
2024-11-09 13:09:45,171 - INFO - train_step=35 avg_return=-11.463
2024-11-09 13:09:45,193 - INFO - train_step=36 loss=16.210 time=6.666
2024-11-09 13:09:49,903 - INFO - train_step=36 avg_return=-15.352
2024-11-09 13:09:49,926 - INFO - train_step=37 loss=22.997 time=4.733
2024-11-09 13:09:54,633 - INFO - train_step=37 avg_return=-11.528
2024-11-09 13:09:54,656 - INFO - train_step=38 loss=16.793 time=4.730
2024-11-09 13:10:01,212 - INFO - train_step=38 avg_return=-12.427
2024-11-09 13:10:01,245 - INFO - train_step=39 loss=16.242 time=6.589
2024-11-09 13:10:08,264 - INFO - train_step=39 avg_return=-10.592
2024-11-09 13:10:08,287 - INFO - train_step=40 loss=16.045 time=7.042
2024-11-09 13:10:13,897 - INFO - train_step=40 avg_return=-12.680
2024-11-09 13:10:13,920 - INFO - train_step=41 loss=72.512 time=5.634
2024-11-09 13:10:19,816 - INFO - train_step=41 avg_return=-13.256
2024-11-09 13:10:19,848 - INFO - train_step=42 loss=22.351 time=5.928
2024-11-09 13:10:26,521 - INFO - train_step=42 avg_return=-10.888
2024-11-09 13:10:26,544 - INFO - train_step=43 loss=23.565 time=6.695
2024-11-09 13:10:31,245 - INFO - train_step=43 avg_return=-10.471
2024-11-09 13:10:31,267 - INFO - train_step=44 loss=15.180 time=4.724
2024-11-09 13:10:35,979 - INFO - train_step=44 avg_return=-7.925
2024-11-09 13:10:36,002 - INFO - train_step=45 loss=34.329 time=4.734
2024-11-09 13:10:41,389 - INFO - train_step=45 avg_return=-12.135
2024-11-09 13:10:41,411 - INFO - train_step=46 loss=26.917 time=5.409
2024-11-09 13:10:46,310 - INFO - train_step=46 avg_return=-10.934
2024-11-09 13:10:46,334 - INFO - train_step=47 loss=10.397 time=4.922
2024-11-09 13:10:51,023 - INFO - train_step=47 avg_return=-13.289
2024-11-09 13:10:51,046 - INFO - train_step=48 loss=13.779 time=4.712
2024-11-09 13:10:55,606 - INFO - train_step=48 avg_return=-10.592
2024-11-09 13:10:55,627 - INFO - train_step=49 loss=32.730 time=4.581
2024-11-09 13:11:00,198 - INFO - train_step=49 avg_return=-12.419
2024-11-09 13:11:00,228 - INFO - train_step=50 loss=17.447 time=4.601
2024-11-09 13:11:07,396 - INFO - train_step=50 avg_return=-10.712
2024-11-09 13:11:07,396 - INFO - total_time=349.651
2024-11-09 13:11:07,396 - INFO - saving, checkpointPath_toSave=./result/Reacher-v2_discrete_DQN_multiagent_1109_130414/model
2024-11-09 13:11:07,397 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_DQN_multiagent_1109_130414/model/0
2024-11-09 13:11:07,450 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_DQN_multiagent_1109_130414/model/0/ckpt-50
2024-11-09 13:11:07,451 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_DQN_multiagent_1109_130414/model/1
2024-11-09 13:11:07,472 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_DQN_multiagent_1109_130414/model/1/ckpt-50
