2024-11-09 13:03:54.384786: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-09 13:03:54.384841: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-09 13:03:54.385520: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-09 13:03:54.390184: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-09 13:03:54.957751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'Reacher-v2_discrete', '-a', 'DQN_multiagent', '-n', '3']
2024-11-09 13:03:56.413987: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-09 13:03:56.414026: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-09 13:03:56.414031: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-09 13:03:56.414181: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-09 13:03:56.414201: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-09 13:03:56.414205: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-09 13:03:56,427 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 50, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-09 13:03:56,427 - INFO - args=Namespace(environment='Reacher-v2_discrete', environment_wrapper=None, agent='DQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3)
2024-11-09 13:03:56,427 - INFO - environment=Reacher-v2_discrete
2024-11-09 13:03:56,427 - INFO - envWrapper=None
2024-11-09 13:03:56,427 - INFO - agent=DQN_multiagent
2024-11-09 13:03:56,545 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))
2024-11-09 13:03:56,545 - INFO - tf_action_spec: BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))
2024-11-09 13:03:56,545 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))})
2024-11-09 13:03:56,639 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308)),
 'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 13:03:56,749 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 13:03:58,445 - INFO - random_policy avg_return=-74.83857727050781
2024-11-09 13:03:58,445 - INFO - replay_buffer.capacity=10000
2024-11-09 13:03:58,448 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-09 13:04:38,553 - INFO - after filling with random_policies, replay_buffer.num_frames()=10000
2024-11-09 13:04:45,991 - INFO - before training, avg_return=-106.28083801269531
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 13:04:46,056 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 13:05:01,828 - INFO - train_step=1 loss=5.225 time=15.836
2024-11-09 13:05:09,357 - INFO - train_step=1 avg_return=-106.213
2024-11-09 13:05:09,392 - INFO - train_step=2 loss=4.380 time=7.564
2024-11-09 13:05:16,914 - INFO - train_step=2 avg_return=-102.905
2024-11-09 13:05:16,945 - INFO - train_step=3 loss=4.521 time=7.553
2024-11-09 13:05:21,669 - INFO - train_step=3 avg_return=-61.400
2024-11-09 13:05:21,692 - INFO - train_step=4 loss=4.082 time=4.747
2024-11-09 13:05:26,444 - INFO - train_step=4 avg_return=-48.399
2024-11-09 13:05:26,468 - INFO - train_step=5 loss=4.325 time=4.776
2024-11-09 13:05:32,115 - INFO - train_step=5 avg_return=-29.326
2024-11-09 13:05:32,138 - INFO - train_step=6 loss=3.786 time=5.670
2024-11-09 13:05:36,864 - INFO - train_step=6 avg_return=-20.610
2024-11-09 13:05:36,897 - INFO - train_step=7 loss=3.956 time=4.759
2024-11-09 13:05:44,499 - INFO - train_step=7 avg_return=-14.689
2024-11-09 13:05:44,532 - INFO - train_step=8 loss=3.745 time=7.636
2024-11-09 13:05:52,172 - INFO - train_step=8 avg_return=-12.950
2024-11-09 13:05:52,206 - INFO - train_step=9 loss=4.896 time=7.673
2024-11-09 13:06:00,029 - INFO - train_step=9 avg_return=-11.299
2024-11-09 13:06:00,063 - INFO - train_step=10 loss=3.821 time=7.858
2024-11-09 13:06:07,608 - INFO - train_step=10 avg_return=-11.117
2024-11-09 13:06:07,640 - INFO - train_step=11 loss=4.250 time=7.577
2024-11-09 13:06:15,179 - INFO - train_step=11 avg_return=-13.381
2024-11-09 13:06:15,211 - INFO - train_step=12 loss=3.560 time=7.571
2024-11-09 13:06:22,753 - INFO - train_step=12 avg_return=-13.841
2024-11-09 13:06:22,787 - INFO - train_step=13 loss=4.472 time=7.576
2024-11-09 13:06:30,346 - INFO - train_step=13 avg_return=-10.047
2024-11-09 13:06:30,379 - INFO - train_step=14 loss=3.645 time=7.592
2024-11-09 13:06:37,918 - INFO - train_step=14 avg_return=-12.980
2024-11-09 13:06:37,950 - INFO - train_step=15 loss=3.948 time=7.571
2024-11-09 13:06:45,489 - INFO - train_step=15 avg_return=-11.414
2024-11-09 13:06:45,522 - INFO - train_step=16 loss=5.584 time=7.572
2024-11-09 13:06:53,040 - INFO - train_step=16 avg_return=-12.769
2024-11-09 13:06:53,074 - INFO - train_step=17 loss=3.984 time=7.552
2024-11-09 13:07:00,603 - INFO - train_step=17 avg_return=-8.740
2024-11-09 13:07:00,636 - INFO - train_step=18 loss=6.205 time=7.562
2024-11-09 13:07:08,176 - INFO - train_step=18 avg_return=-9.867
2024-11-09 13:07:08,209 - INFO - train_step=19 loss=6.403 time=7.572
2024-11-09 13:07:15,762 - INFO - train_step=19 avg_return=-9.974
2024-11-09 13:07:15,796 - INFO - train_step=20 loss=6.086 time=7.587
2024-11-09 13:07:23,209 - INFO - train_step=20 avg_return=-12.656
2024-11-09 13:07:23,241 - INFO - train_step=21 loss=7.506 time=7.445
2024-11-09 13:07:29,722 - INFO - train_step=21 avg_return=-13.784
2024-11-09 13:07:29,760 - INFO - train_step=22 loss=5.617 time=6.519
2024-11-09 13:07:37,250 - INFO - train_step=22 avg_return=-15.385
2024-11-09 13:07:37,273 - INFO - train_step=23 loss=10.920 time=7.514
2024-11-09 13:07:44,550 - INFO - train_step=23 avg_return=-12.703
2024-11-09 13:07:44,582 - INFO - train_step=24 loss=7.727 time=7.309
2024-11-09 13:07:51,995 - INFO - train_step=24 avg_return=-11.179
2024-11-09 13:07:52,029 - INFO - train_step=25 loss=11.277 time=7.447
2024-11-09 13:07:59,446 - INFO - train_step=25 avg_return=-11.835
2024-11-09 13:07:59,479 - INFO - train_step=26 loss=9.881 time=7.450
2024-11-09 13:08:05,086 - INFO - train_step=26 avg_return=-10.760
2024-11-09 13:08:05,109 - INFO - train_step=27 loss=11.626 time=5.630
2024-11-09 13:08:09,842 - INFO - train_step=27 avg_return=-13.308
2024-11-09 13:08:09,869 - INFO - train_step=28 loss=17.401 time=4.761
2024-11-09 13:08:14,742 - INFO - train_step=28 avg_return=-11.801
2024-11-09 13:08:14,764 - INFO - train_step=29 loss=17.951 time=4.895
2024-11-09 13:08:19,870 - INFO - train_step=29 avg_return=-11.977
2024-11-09 13:08:19,903 - INFO - train_step=30 loss=13.280 time=5.138
2024-11-09 13:08:25,505 - INFO - train_step=30 avg_return=-9.679
2024-11-09 13:08:25,527 - INFO - train_step=31 loss=19.688 time=5.624
2024-11-09 13:08:31,851 - INFO - train_step=31 avg_return=-13.203
2024-11-09 13:08:31,884 - INFO - train_step=32 loss=8.977 time=6.357
2024-11-09 13:08:39,328 - INFO - train_step=32 avg_return=-8.662
2024-11-09 13:08:39,361 - INFO - train_step=33 loss=21.469 time=7.477
2024-11-09 13:08:46,894 - INFO - train_step=33 avg_return=-12.221
2024-11-09 13:08:46,926 - INFO - train_step=34 loss=19.236 time=7.565
2024-11-09 13:08:54,336 - INFO - train_step=34 avg_return=-14.802
2024-11-09 13:08:54,371 - INFO - train_step=35 loss=22.110 time=7.444
2024-11-09 13:09:01,192 - INFO - train_step=35 avg_return=-11.389
2024-11-09 13:09:01,226 - INFO - train_step=36 loss=12.646 time=6.855
2024-11-09 13:09:08,620 - INFO - train_step=36 avg_return=-11.219
2024-11-09 13:09:08,654 - INFO - train_step=37 loss=12.414 time=7.428
2024-11-09 13:09:16,064 - INFO - train_step=37 avg_return=-10.706
2024-11-09 13:09:16,097 - INFO - train_step=38 loss=13.128 time=7.443
2024-11-09 13:09:23,255 - INFO - train_step=38 avg_return=-11.961
2024-11-09 13:09:23,277 - INFO - train_step=39 loss=13.735 time=7.180
2024-11-09 13:09:30,413 - INFO - train_step=39 avg_return=-12.582
2024-11-09 13:09:30,445 - INFO - train_step=40 loss=25.106 time=7.168
2024-11-09 13:09:36,403 - INFO - train_step=40 avg_return=-14.276
2024-11-09 13:09:36,439 - INFO - train_step=41 loss=12.347 time=5.994
2024-11-09 13:09:43,823 - INFO - train_step=41 avg_return=-13.350
2024-11-09 13:09:43,857 - INFO - train_step=42 loss=19.322 time=7.418
2024-11-09 13:09:51,249 - INFO - train_step=42 avg_return=-8.965
2024-11-09 13:09:51,282 - INFO - train_step=43 loss=12.064 time=7.425
2024-11-09 13:09:58,668 - INFO - train_step=43 avg_return=-11.601
2024-11-09 13:09:58,703 - INFO - train_step=44 loss=18.853 time=7.421
2024-11-09 13:10:04,344 - INFO - train_step=44 avg_return=-11.665
2024-11-09 13:10:04,368 - INFO - train_step=45 loss=12.822 time=5.665
2024-11-09 13:10:10,758 - INFO - train_step=45 avg_return=-12.456
2024-11-09 13:10:10,791 - INFO - train_step=46 loss=22.371 time=6.424
2024-11-09 13:10:18,280 - INFO - train_step=46 avg_return=-12.059
2024-11-09 13:10:18,318 - INFO - train_step=47 loss=19.636 time=7.527
2024-11-09 13:10:25,756 - INFO - train_step=47 avg_return=-9.772
2024-11-09 13:10:25,791 - INFO - train_step=48 loss=36.296 time=7.473
2024-11-09 13:10:31,670 - INFO - train_step=48 avg_return=-9.272
2024-11-09 13:10:31,703 - INFO - train_step=49 loss=13.150 time=5.911
2024-11-09 13:10:37,692 - INFO - train_step=49 avg_return=-12.094
2024-11-09 13:10:37,721 - INFO - train_step=50 loss=31.107 time=6.018
2024-11-09 13:10:44,252 - INFO - train_step=50 avg_return=-12.399
2024-11-09 13:10:44,252 - INFO - total_time=365.699
2024-11-09 13:10:44,252 - INFO - saving, checkpointPath_toSave=./result/Reacher-v2_discrete_DQN_multiagent_1109_130356/model
2024-11-09 13:10:44,252 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_DQN_multiagent_1109_130356/model/0
2024-11-09 13:10:44,290 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_DQN_multiagent_1109_130356/model/0/ckpt-50
2024-11-09 13:10:44,290 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_DQN_multiagent_1109_130356/model/1
2024-11-09 13:10:44,304 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_DQN_multiagent_1109_130356/model/1/ckpt-50
