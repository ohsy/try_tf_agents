2024-11-09 09:01:42.315549: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-09 09:01:42.315619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-09 09:01:42.317379: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-09 09:01:42.323899: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-09 09:01:43.025775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'DaisoSokcho_discrete', '-a', 'DQN_multiagent', '-n', '3']
2024-11-09 09:01:44.839276: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-09 09:01:44.839375: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-09 09:01:44.839394: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-09 09:01:44.839822: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-09 09:01:44.839850: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-09 09:01:44.839854: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-09 09:01:44,855 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 50000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-09 09:01:44,855 - INFO - args=Namespace(environment='DaisoSokcho_discrete', environment_wrapper=None, agent='DQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3)
2024-11-09 09:01:44,855 - INFO - environment=DaisoSokcho_discrete
2024-11-09 09:01:44,855 - INFO - envWrapper=None
2024-11-09 09:01:44,855 - INFO - agent=DQN_multiagent
Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

2024-11-09 09:01:45,688 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))
2024-11-09 09:01:45,688 - INFO - tf_action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32))
2024-11-09 09:01:45,689 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))})
2024-11-09 09:01:45,917 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32)),
 'action': BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 09:01:46,041 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 09:02:19,060 - INFO - random_policy avg_return=-339.72869873046875
2024-11-09 09:02:19,060 - INFO - replay_buffer.capacity=10000
2024-11-09 09:02:19,063 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-09 09:08:12,255 - INFO - after filling with random_policies, replay_buffer.num_frames()=10000
2024-11-09 09:08:55,406 - INFO - before training, avg_return=-586.7847900390625
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 09:08:55,504 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
WARNING:tensorflow:5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7fe0f87bfeb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 09:09:21,652 - WARNING - 5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7fe0f87bfeb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 09:09:38,963 - INFO - train_step=200 loss=52601520.000 time=43.556
2024-11-09 09:09:56,199 - INFO - train_step=400 loss=272736320.000 time=17.236
2024-11-09 09:10:14,919 - INFO - train_step=600 loss=42210570240.000 time=18.720
2024-11-09 09:10:33,736 - INFO - train_step=800 loss=3184733952.000 time=18.817
2024-11-09 09:10:52,757 - INFO - train_step=1000 loss=4279132672.000 time=19.021
2024-11-09 09:11:38,961 - INFO - train_step=1000 avg_return=-461.002
2024-11-09 09:11:56,942 - INFO - train_step=1200 loss=9722672128.000 time=64.185
2024-11-09 09:12:15,036 - INFO - train_step=1400 loss=86282493952.000 time=18.094
2024-11-09 09:12:33,839 - INFO - train_step=1600 loss=69959319552.000 time=18.803
2024-11-09 09:12:52,839 - INFO - train_step=1800 loss=155838152704.000 time=19.000
2024-11-09 09:13:12,122 - INFO - train_step=2000 loss=74190413824.000 time=19.283
2024-11-09 09:14:00,571 - INFO - train_step=2000 avg_return=-366.530
2024-11-09 09:14:18,057 - INFO - train_step=2200 loss=15552268288.000 time=65.935
2024-11-09 09:14:36,092 - INFO - train_step=2400 loss=87269679104.000 time=18.035
2024-11-09 09:14:54,348 - INFO - train_step=2600 loss=11702018048.000 time=18.256
2024-11-09 09:15:13,810 - INFO - train_step=2800 loss=45182136320.000 time=19.463
2024-11-09 09:15:33,031 - INFO - train_step=3000 loss=92611895296.000 time=19.221
2024-11-09 09:16:21,931 - INFO - train_step=3000 avg_return=-366.046
2024-11-09 09:16:40,050 - INFO - train_step=3200 loss=19764477952.000 time=67.019
2024-11-09 09:16:58,196 - INFO - train_step=3400 loss=30100080640.000 time=18.146
2024-11-09 09:17:15,891 - INFO - train_step=3600 loss=8577766400.000 time=17.695
2024-11-09 09:17:34,593 - INFO - train_step=3800 loss=9721749504.000 time=18.701
2024-11-09 09:17:53,984 - INFO - train_step=4000 loss=12096372736.000 time=19.392
2024-11-09 09:18:43,338 - INFO - train_step=4000 avg_return=-421.465
2024-11-09 09:19:01,954 - INFO - train_step=4200 loss=9276915712.000 time=67.970
2024-11-09 09:19:20,246 - INFO - train_step=4400 loss=4492084736.000 time=18.292
2024-11-09 09:19:38,194 - INFO - train_step=4600 loss=5306533888.000 time=17.948
2024-11-09 09:19:56,704 - INFO - train_step=4800 loss=3140455168.000 time=18.511
2024-11-09 09:20:16,096 - INFO - train_step=5000 loss=3650235392.000 time=19.391
2024-11-09 09:21:03,890 - INFO - train_step=5000 avg_return=-445.997
2024-11-09 09:21:23,115 - INFO - train_step=5200 loss=3002515200.000 time=67.019
2024-11-09 09:21:42,153 - INFO - train_step=5400 loss=2482832640.000 time=19.039
2024-11-09 09:21:59,778 - INFO - train_step=5600 loss=2018278272.000 time=17.625
2024-11-09 09:22:17,748 - INFO - train_step=5800 loss=1367221120.000 time=17.970
2024-11-09 09:22:36,869 - INFO - train_step=6000 loss=848533888.000 time=19.121
2024-11-09 09:23:25,013 - INFO - train_step=6000 avg_return=-280.585
2024-11-09 09:23:43,907 - INFO - train_step=6200 loss=808653696.000 time=67.038
2024-11-09 09:24:03,452 - INFO - train_step=6400 loss=800798144.000 time=19.545
2024-11-09 09:24:21,429 - INFO - train_step=6600 loss=819535424.000 time=17.977
2024-11-09 09:24:39,082 - INFO - train_step=6800 loss=599428288.000 time=17.653
2024-11-09 09:24:57,102 - INFO - train_step=7000 loss=315141504.000 time=18.020
2024-11-09 09:25:45,719 - INFO - train_step=7000 avg_return=-267.940
2024-11-09 09:26:04,956 - INFO - train_step=7200 loss=219544480.000 time=67.853
2024-11-09 09:26:24,553 - INFO - train_step=7400 loss=162670816.000 time=19.597
2024-11-09 09:26:43,605 - INFO - train_step=7600 loss=228047504.000 time=19.051
2024-11-09 09:27:01,407 - INFO - train_step=7800 loss=403903232.000 time=17.803
2024-11-09 09:27:19,136 - INFO - train_step=8000 loss=207666032.000 time=17.728
2024-11-09 09:28:05,998 - INFO - train_step=8000 avg_return=-389.476
2024-11-09 09:28:25,307 - INFO - train_step=8200 loss=529855232.000 time=66.171
2024-11-09 09:28:44,781 - INFO - train_step=8400 loss=956801408.000 time=19.475
2024-11-09 09:29:04,178 - INFO - train_step=8600 loss=190847840.000 time=19.397
2024-11-09 09:29:22,135 - INFO - train_step=8800 loss=931885184.000 time=17.957
2024-11-09 09:29:39,910 - INFO - train_step=9000 loss=337901696.000 time=17.775
2024-11-09 09:30:26,562 - INFO - train_step=9000 avg_return=-338.196
2024-11-09 09:30:46,115 - INFO - train_step=9200 loss=342453216.000 time=66.205
2024-11-09 09:31:05,981 - INFO - train_step=9400 loss=384848480.000 time=19.866
2024-11-09 09:31:25,280 - INFO - train_step=9600 loss=377299744.000 time=19.299
2024-11-09 09:31:43,676 - INFO - train_step=9800 loss=294676000.000 time=18.396
2024-11-09 09:32:01,579 - INFO - train_step=10000 loss=168701664.000 time=17.904
2024-11-09 09:32:47,628 - INFO - train_step=10000 avg_return=-177.720
2024-11-09 09:33:07,306 - INFO - train_step=10200 loss=87706008.000 time=65.727
2024-11-09 09:33:27,102 - INFO - train_step=10400 loss=83686144.000 time=19.796
2024-11-09 09:33:46,278 - INFO - train_step=10600 loss=31065706.000 time=19.176
2024-11-09 09:34:05,670 - INFO - train_step=10800 loss=14501426.000 time=19.392
2024-11-09 09:34:23,185 - INFO - train_step=11000 loss=18134304.000 time=17.515
2024-11-09 09:35:08,318 - INFO - train_step=11000 avg_return=-385.921
2024-11-09 09:35:27,784 - INFO - train_step=11200 loss=14986926.000 time=64.599
2024-11-09 09:35:47,413 - INFO - train_step=11400 loss=12299388.000 time=19.629
2024-11-09 09:36:07,028 - INFO - train_step=11600 loss=13930289.000 time=19.615
2024-11-09 09:36:26,356 - INFO - train_step=11800 loss=4521535.500 time=19.328
2024-11-09 09:36:44,563 - INFO - train_step=12000 loss=3998921.750 time=18.207
2024-11-09 09:37:28,113 - INFO - train_step=12000 avg_return=-324.578
2024-11-09 09:37:47,154 - INFO - train_step=12200 loss=6936551.500 time=62.591
2024-11-09 09:38:06,863 - INFO - train_step=12400 loss=2138824.750 time=19.709
2024-11-09 09:38:25,936 - INFO - train_step=12600 loss=2774941.000 time=19.073
2024-11-09 09:38:45,505 - INFO - train_step=12800 loss=1564019.125 time=19.569
2024-11-09 09:39:04,636 - INFO - train_step=13000 loss=1201792.875 time=19.131
2024-11-09 09:39:47,857 - INFO - train_step=13000 avg_return=-359.757
2024-11-09 09:40:07,244 - INFO - train_step=13200 loss=1049887.250 time=62.608
2024-11-09 09:40:26,960 - INFO - train_step=13400 loss=1267665.500 time=19.716
2024-11-09 09:40:46,101 - INFO - train_step=13600 loss=2021688.375 time=19.141
2024-11-09 09:41:05,551 - INFO - train_step=13800 loss=999963.312 time=19.449
2024-11-09 09:41:24,593 - INFO - train_step=14000 loss=188024.219 time=19.042
2024-11-09 09:42:07,710 - INFO - train_step=14000 avg_return=-306.779
2024-11-09 09:42:26,346 - INFO - train_step=14200 loss=421440.250 time=61.753
2024-11-09 09:42:46,194 - INFO - train_step=14400 loss=472386.719 time=19.847
2024-11-09 09:43:05,160 - INFO - train_step=14600 loss=299261.906 time=18.967
2024-11-09 09:43:23,953 - INFO - train_step=14800 loss=376100.500 time=18.792
2024-11-09 09:43:43,827 - INFO - train_step=15000 loss=302535.562 time=19.874
2024-11-09 09:44:28,271 - INFO - train_step=15000 avg_return=-325.622
2024-11-09 09:44:46,439 - INFO - train_step=15200 loss=182968.375 time=62.612
2024-11-09 09:45:06,154 - INFO - train_step=15400 loss=382542.375 time=19.715
2024-11-09 09:45:25,492 - INFO - train_step=15600 loss=248295.859 time=19.337
2024-11-09 09:45:45,025 - INFO - train_step=15800 loss=1240608640.000 time=19.533
2024-11-09 09:46:04,261 - INFO - train_step=16000 loss=3580139008.000 time=19.236
2024-11-09 09:46:48,868 - INFO - train_step=16000 avg_return=-323.707
2024-11-09 09:47:07,160 - INFO - train_step=16200 loss=1791293440.000 time=62.900
2024-11-09 09:47:26,410 - INFO - train_step=16400 loss=400597376.000 time=19.249
2024-11-09 09:47:46,240 - INFO - train_step=16600 loss=84272400.000 time=19.830
2024-11-09 09:48:05,702 - INFO - train_step=16800 loss=109489632.000 time=19.462
2024-11-09 09:48:25,013 - INFO - train_step=17000 loss=37913844.000 time=19.310
2024-11-09 09:49:10,940 - INFO - train_step=17000 avg_return=-356.060
2024-11-09 09:49:29,517 - INFO - train_step=17200 loss=33776236.000 time=64.504
2024-11-09 09:49:47,946 - INFO - train_step=17400 loss=17770512.000 time=18.430
2024-11-09 09:50:07,293 - INFO - train_step=17600 loss=17212112.000 time=19.347
2024-11-09 09:50:26,419 - INFO - train_step=17800 loss=11609937.000 time=19.126
2024-11-09 09:50:45,329 - INFO - train_step=18000 loss=7114772.000 time=18.910
2024-11-09 09:51:32,036 - INFO - train_step=18000 avg_return=-592.495
2024-11-09 09:51:50,002 - INFO - train_step=18200 loss=1356369.250 time=64.673
2024-11-09 09:52:08,953 - INFO - train_step=18400 loss=1233407.500 time=18.950
2024-11-09 09:52:27,406 - INFO - train_step=18600 loss=2627497.750 time=18.454
2024-11-09 09:52:46,487 - INFO - train_step=18800 loss=76705168.000 time=19.081
2024-11-09 09:53:05,531 - INFO - train_step=19000 loss=48833620.000 time=19.044
2024-11-09 09:53:53,068 - INFO - train_step=19000 avg_return=-295.517
2024-11-09 09:54:11,150 - INFO - train_step=19200 loss=11059901.000 time=65.618
2024-11-09 09:54:29,548 - INFO - train_step=19400 loss=18290702.000 time=18.398
2024-11-09 09:54:47,829 - INFO - train_step=19600 loss=34576380.000 time=18.281
2024-11-09 09:55:06,773 - INFO - train_step=19800 loss=12720752.000 time=18.944
2024-11-09 09:55:25,593 - INFO - train_step=20000 loss=13723558.000 time=18.820
2024-11-09 09:56:13,112 - INFO - train_step=20000 avg_return=-364.224
2024-11-09 09:56:32,111 - INFO - train_step=20200 loss=4116878.000 time=66.518
2024-11-09 09:56:50,615 - INFO - train_step=20400 loss=3466291.250 time=18.504
2024-11-09 09:57:08,483 - INFO - train_step=20600 loss=4096311.500 time=17.868
2024-11-09 09:57:26,165 - INFO - train_step=20800 loss=960879.375 time=17.683
2024-11-09 09:57:43,061 - INFO - train_step=21000 loss=369548.000 time=16.896
2024-11-09 09:58:25,138 - INFO - train_step=21000 avg_return=-388.782
2024-11-09 09:58:42,519 - INFO - train_step=21200 loss=680756.625 time=59.458
2024-11-09 09:59:00,012 - INFO - train_step=21400 loss=916219.312 time=17.494
2024-11-09 09:59:16,933 - INFO - train_step=21600 loss=750701.688 time=16.920
2024-11-09 09:59:33,662 - INFO - train_step=21800 loss=257541.047 time=16.729
2024-11-09 09:59:50,351 - INFO - train_step=22000 loss=184919.406 time=16.688
2024-11-09 10:00:31,233 - INFO - train_step=22000 avg_return=-349.343
2024-11-09 10:00:48,684 - INFO - train_step=22200 loss=223289.484 time=58.334
2024-11-09 10:01:06,158 - INFO - train_step=22400 loss=194126.344 time=17.474
2024-11-09 10:01:23,065 - INFO - train_step=22600 loss=447605.125 time=16.907
2024-11-09 10:01:40,133 - INFO - train_step=22800 loss=633346.500 time=17.067
2024-11-09 10:01:56,883 - INFO - train_step=23000 loss=228156.203 time=16.751
2024-11-09 10:02:38,414 - INFO - train_step=23000 avg_return=-357.995
2024-11-09 10:02:56,085 - INFO - train_step=23200 loss=364952.375 time=59.202
2024-11-09 10:03:13,609 - INFO - train_step=23400 loss=281493.500 time=17.524
2024-11-09 10:03:30,572 - INFO - train_step=23600 loss=133305.375 time=16.962
2024-11-09 10:03:46,967 - INFO - train_step=23800 loss=279672.938 time=16.396
2024-11-09 10:04:04,164 - INFO - train_step=24000 loss=969794.750 time=17.197
2024-11-09 10:04:45,472 - INFO - train_step=24000 avg_return=-249.641
2024-11-09 10:05:03,190 - INFO - train_step=24200 loss=58287364.000 time=59.026
2024-11-09 10:05:20,631 - INFO - train_step=24400 loss=3514485.000 time=17.441
2024-11-09 10:05:37,256 - INFO - train_step=24600 loss=2801947.000 time=16.625
2024-11-09 10:05:53,928 - INFO - train_step=24800 loss=1440393.500 time=16.672
2024-11-09 10:06:10,710 - INFO - train_step=25000 loss=617144.750 time=16.782
2024-11-09 10:06:52,242 - INFO - train_step=25000 avg_return=-452.232
2024-11-09 10:07:09,779 - INFO - train_step=25200 loss=392363.469 time=59.068
2024-11-09 10:07:26,980 - INFO - train_step=25400 loss=253393.562 time=17.202
2024-11-09 10:07:43,833 - INFO - train_step=25600 loss=247531.172 time=16.853
2024-11-09 10:08:01,074 - INFO - train_step=25800 loss=156960.922 time=17.241
2024-11-09 10:08:18,277 - INFO - train_step=26000 loss=177969.688 time=17.203
2024-11-09 10:08:59,668 - INFO - train_step=26000 avg_return=-293.580
2024-11-09 10:09:17,622 - INFO - train_step=26200 loss=181388.047 time=59.345
2024-11-09 10:09:34,679 - INFO - train_step=26400 loss=245793.719 time=17.057
2024-11-09 10:09:51,590 - INFO - train_step=26600 loss=164303.984 time=16.911
2024-11-09 10:10:08,279 - INFO - train_step=26800 loss=2894368.000 time=16.689
2024-11-09 10:10:25,030 - INFO - train_step=27000 loss=4034461.500 time=16.751
2024-11-09 10:11:06,562 - INFO - train_step=27000 avg_return=-294.397
2024-11-09 10:11:23,899 - INFO - train_step=27200 loss=581971.438 time=58.869
2024-11-09 10:11:41,392 - INFO - train_step=27400 loss=295436.531 time=17.492
2024-11-09 10:11:58,499 - INFO - train_step=27600 loss=153265.188 time=17.108
2024-11-09 10:12:15,541 - INFO - train_step=27800 loss=126447.141 time=17.041
2024-11-09 10:12:32,331 - INFO - train_step=28000 loss=82842.148 time=16.791
2024-11-09 10:13:25,498 - INFO - train_step=28000 avg_return=-367.374
2024-11-09 10:13:48,490 - INFO - train_step=28200 loss=98438.008 time=76.159
2024-11-09 10:14:11,071 - INFO - train_step=28400 loss=63726.645 time=22.580
2024-11-09 10:14:34,513 - INFO - train_step=28600 loss=70026.305 time=23.442
2024-11-09 10:15:08,015 - INFO - train_step=28800 loss=79954.922 time=33.503
2024-11-09 10:15:50,564 - INFO - train_step=29000 loss=62059.031 time=42.549
2024-11-09 10:17:37,601 - INFO - train_step=29000 avg_return=-328.347
2024-11-09 10:18:08,579 - INFO - train_step=29200 loss=42425.117 time=138.015
2024-11-09 10:18:27,101 - INFO - train_step=29400 loss=96289.898 time=18.521
2024-11-09 10:18:47,912 - INFO - train_step=29600 loss=32170.744 time=20.811
2024-11-09 10:19:10,523 - INFO - train_step=29800 loss=48818.062 time=22.611
2024-11-09 10:19:32,091 - INFO - train_step=30000 loss=37233.664 time=21.568
2024-11-09 10:20:28,265 - INFO - train_step=30000 avg_return=-330.240
2024-11-09 10:21:00,101 - INFO - train_step=30200 loss=458287.500 time=88.010
2024-11-09 10:21:29,151 - INFO - train_step=30400 loss=91684.031 time=29.050
2024-11-09 10:21:56,387 - INFO - train_step=30600 loss=44426.875 time=27.236
2024-11-09 10:22:28,758 - INFO - train_step=30800 loss=50950.297 time=32.371
2024-11-09 10:22:53,155 - INFO - train_step=31000 loss=54876.043 time=24.397
2024-11-09 10:24:14,478 - INFO - train_step=31000 avg_return=-289.386
2024-11-09 10:24:42,700 - INFO - train_step=31200 loss=24663.252 time=109.545
2024-11-09 10:25:11,340 - INFO - train_step=31400 loss=27196.471 time=28.640
2024-11-09 10:25:43,372 - INFO - train_step=31600 loss=26325.459 time=32.032
2024-11-09 10:26:08,367 - INFO - train_step=31800 loss=34873.223 time=24.994
2024-11-09 10:26:40,525 - INFO - train_step=32000 loss=33695084.000 time=32.158
2024-11-09 10:27:54,461 - INFO - train_step=32000 avg_return=-519.808
2024-11-09 10:28:24,872 - INFO - train_step=32200 loss=2109837.750 time=104.347
2024-11-09 10:28:55,359 - INFO - train_step=32400 loss=674805.750 time=30.487
2024-11-09 10:29:21,608 - INFO - train_step=32600 loss=403820.031 time=26.248
2024-11-09 10:29:54,074 - INFO - train_step=32800 loss=153575.500 time=32.467
2024-11-09 10:30:18,383 - INFO - train_step=33000 loss=201743.047 time=24.308
2024-11-09 10:31:39,012 - INFO - train_step=33000 avg_return=-339.185
2024-11-09 10:32:08,880 - INFO - train_step=33200 loss=187040.391 time=110.497
2024-11-09 10:32:35,841 - INFO - train_step=33400 loss=78860.188 time=26.961
2024-11-09 10:33:07,961 - INFO - train_step=33600 loss=71345.633 time=32.120
2024-11-09 10:33:32,950 - INFO - train_step=33800 loss=54523.855 time=24.988
2024-11-09 10:34:04,081 - INFO - train_step=34000 loss=95706.203 time=31.131
2024-11-09 10:35:20,879 - INFO - train_step=34000 avg_return=-310.368
2024-11-09 10:35:48,878 - INFO - train_step=34200 loss=23606.797 time=104.797
2024-11-09 10:36:20,693 - INFO - train_step=34400 loss=31254.471 time=31.815
2024-11-09 10:36:46,385 - INFO - train_step=34600 loss=84758.766 time=25.691
2024-11-09 10:37:18,955 - INFO - train_step=34800 loss=22082.625 time=32.570
2024-11-09 10:37:44,518 - INFO - train_step=35000 loss=65382.977 time=25.563
2024-11-09 10:39:01,442 - INFO - train_step=35000 avg_return=-318.265
2024-11-09 10:39:32,020 - INFO - train_step=35200 loss=24516.066 time=107.502
2024-11-09 10:39:57,992 - INFO - train_step=35400 loss=23671.670 time=25.972
2024-11-09 10:40:30,098 - INFO - train_step=35600 loss=46948.070 time=32.106
2024-11-09 10:40:54,992 - INFO - train_step=35800 loss=39090.195 time=24.895
2024-11-09 10:41:25,911 - INFO - train_step=36000 loss=34717.559 time=30.919
2024-11-09 10:42:38,554 - INFO - train_step=36000 avg_return=-488.348
2024-11-09 10:43:07,562 - INFO - train_step=36200 loss=320952.875 time=101.650
2024-11-09 10:43:38,350 - INFO - train_step=36400 loss=89428.461 time=30.788
2024-11-09 10:44:04,947 - INFO - train_step=36600 loss=143324.484 time=26.597
2024-11-09 10:44:36,888 - INFO - train_step=36800 loss=31435.648 time=31.941
2024-11-09 10:45:01,834 - INFO - train_step=37000 loss=41180.625 time=24.946
2024-11-09 10:46:16,886 - INFO - train_step=37000 avg_return=-406.854
2024-11-09 10:46:45,138 - INFO - train_step=37200 loss=19822.357 time=103.304
2024-11-09 10:47:13,349 - INFO - train_step=37400 loss=208122.984 time=28.211
2024-11-09 10:47:44,803 - INFO - train_step=37600 loss=35522268.000 time=31.454
2024-11-09 10:48:10,555 - INFO - train_step=37800 loss=2593733.250 time=25.753
2024-11-09 10:48:41,819 - INFO - train_step=38000 loss=1035208.875 time=31.263
2024-11-09 10:49:57,816 - INFO - train_step=38000 avg_return=-549.453
2024-11-09 10:50:27,637 - INFO - train_step=38200 loss=447516.531 time=105.818
2024-11-09 10:50:58,265 - INFO - train_step=38400 loss=187266.938 time=30.628
2024-11-09 10:51:24,084 - INFO - train_step=38600 loss=167970.375 time=25.819
2024-11-09 10:51:55,629 - INFO - train_step=38800 loss=118901.016 time=31.545
2024-11-09 10:52:21,264 - INFO - train_step=39000 loss=50418.422 time=25.636
2024-11-09 10:53:40,657 - INFO - train_step=39000 avg_return=-458.275
2024-11-09 10:54:10,268 - INFO - train_step=39200 loss=46691.730 time=109.004
2024-11-09 10:54:37,688 - INFO - train_step=39400 loss=39980.605 time=27.420
2024-11-09 10:55:09,992 - INFO - train_step=39600 loss=46667.102 time=32.304
2024-11-09 10:55:34,999 - INFO - train_step=39800 loss=40155.844 time=25.007
2024-11-09 10:56:05,606 - INFO - train_step=40000 loss=30558.096 time=30.608
2024-11-09 10:57:22,687 - INFO - train_step=40000 avg_return=-474.036
2024-11-09 10:57:50,550 - INFO - train_step=40200 loss=36216.566 time=104.943
2024-11-09 10:58:22,081 - INFO - train_step=40400 loss=43347.301 time=31.531
2024-11-09 10:58:48,085 - INFO - train_step=40600 loss=16433.963 time=26.005
2024-11-09 10:59:18,900 - INFO - train_step=40800 loss=24448.896 time=30.814
2024-11-09 10:59:45,408 - INFO - train_step=41000 loss=35498.535 time=26.508
2024-11-09 11:01:01,364 - INFO - train_step=41000 avg_return=-389.650
2024-11-09 11:01:21,627 - INFO - train_step=41200 loss=26518.246 time=96.220
2024-11-09 11:01:43,818 - INFO - train_step=41400 loss=17623.408 time=22.190
2024-11-09 11:02:06,742 - INFO - train_step=41600 loss=22997.949 time=22.925
2024-11-09 11:02:29,082 - INFO - train_step=41800 loss=469420.969 time=22.340
2024-11-09 11:02:52,887 - INFO - train_step=42000 loss=11815939.000 time=23.805
2024-11-09 11:04:01,152 - INFO - train_step=42000 avg_return=-437.224
2024-11-09 11:04:26,344 - INFO - train_step=42200 loss=588224.438 time=93.457
2024-11-09 11:04:52,344 - INFO - train_step=42400 loss=229826.078 time=26.000
2024-11-09 11:05:17,176 - INFO - train_step=42600 loss=82991.938 time=24.832
2024-11-09 11:05:42,585 - INFO - train_step=42800 loss=61389.008 time=25.409
2024-11-09 11:06:06,727 - INFO - train_step=43000 loss=35773.836 time=24.141
2024-11-09 11:07:12,192 - INFO - train_step=43000 avg_return=-419.749
2024-11-09 11:07:37,570 - INFO - train_step=43200 loss=45558.039 time=90.843
2024-11-09 11:08:03,034 - INFO - train_step=43400 loss=33714.969 time=25.465
2024-11-09 11:08:28,628 - INFO - train_step=43600 loss=15392.787 time=25.594
2024-11-09 11:08:53,909 - INFO - train_step=43800 loss=19036.604 time=25.281
2024-11-09 11:09:19,326 - INFO - train_step=44000 loss=31443.102 time=25.417
2024-11-09 11:10:25,609 - INFO - train_step=44000 avg_return=-348.328
2024-11-09 11:10:51,152 - INFO - train_step=44200 loss=14549.733 time=91.826
2024-11-09 11:11:16,382 - INFO - train_step=44400 loss=23764.754 time=25.229
2024-11-09 11:11:41,678 - INFO - train_step=44600 loss=19375.945 time=25.297
2024-11-09 11:12:06,705 - INFO - train_step=44800 loss=15866.255 time=25.027
2024-11-09 11:12:31,023 - INFO - train_step=45000 loss=17432.939 time=24.317
2024-11-09 11:13:38,220 - INFO - train_step=45000 avg_return=-363.262
2024-11-09 11:14:04,100 - INFO - train_step=45200 loss=11021.670 time=93.077
2024-11-09 11:14:29,402 - INFO - train_step=45400 loss=13138066.000 time=25.302
2024-11-09 11:14:55,578 - INFO - train_step=45600 loss=1659068.125 time=26.175
2024-11-09 11:15:20,384 - INFO - train_step=45800 loss=258491.625 time=24.807
2024-11-09 11:15:44,747 - INFO - train_step=46000 loss=143473.469 time=24.363
2024-11-09 11:16:44,284 - INFO - train_step=46000 avg_return=-476.894
2024-11-09 11:17:05,548 - INFO - train_step=46200 loss=149223.109 time=80.801
2024-11-09 11:17:28,413 - INFO - train_step=46400 loss=46497.129 time=22.865
2024-11-09 11:17:51,864 - INFO - train_step=46600 loss=27235.570 time=23.451
2024-11-09 11:18:15,677 - INFO - train_step=46800 loss=36520.164 time=23.813
2024-11-09 11:18:39,084 - INFO - train_step=47000 loss=79401.875 time=23.407
2024-11-09 11:19:44,030 - INFO - train_step=47000 avg_return=-271.739
2024-11-09 11:20:09,006 - INFO - train_step=47200 loss=56651.926 time=89.921
2024-11-09 11:20:33,988 - INFO - train_step=47400 loss=22293.775 time=24.982
2024-11-09 11:20:59,012 - INFO - train_step=47600 loss=40665.152 time=25.024
2024-11-09 11:21:23,461 - INFO - train_step=47800 loss=15233.938 time=24.449
2024-11-09 11:21:47,060 - INFO - train_step=48000 loss=8051.926 time=23.599
2024-11-09 11:22:50,951 - INFO - train_step=48000 avg_return=-467.013
2024-11-09 11:23:14,772 - INFO - train_step=48200 loss=18986.389 time=87.712
2024-11-09 11:23:37,625 - INFO - train_step=48400 loss=14491.182 time=22.853
2024-11-09 11:24:00,619 - INFO - train_step=48600 loss=31946.459 time=22.994
2024-11-09 11:24:23,082 - INFO - train_step=48800 loss=14458.714 time=22.463
2024-11-09 11:24:45,877 - INFO - train_step=49000 loss=12389.325 time=22.795
2024-11-09 11:25:45,416 - INFO - train_step=49000 avg_return=-335.347
2024-11-09 11:26:08,419 - INFO - train_step=49200 loss=8894.815 time=82.542
2024-11-09 11:26:31,051 - INFO - train_step=49400 loss=3935942.000 time=22.632
2024-11-09 11:26:54,307 - INFO - train_step=49600 loss=100369.570 time=23.256
2024-11-09 11:27:16,808 - INFO - train_step=49800 loss=27310.908 time=22.500
2024-11-09 11:27:39,505 - INFO - train_step=50000 loss=13519.982 time=22.698
2024-11-09 11:28:37,881 - INFO - train_step=50000 avg_return=-372.847
2024-11-09 11:28:37,881 - INFO - total_time=8425.626
2024-11-09 11:28:37,881 - INFO - saving, checkpointPath_toSave=./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model
2024-11-09 11:28:37,882 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/0
2024-11-09 11:28:37,938 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/0/ckpt-50000
2024-11-09 11:28:37,938 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/1
2024-11-09 11:28:37,963 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/1/ckpt-50000
2024-11-09 11:28:37,964 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/2
2024-11-09 11:28:37,984 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/2/ckpt-50000
2024-11-09 11:28:37,984 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/3
2024-11-09 11:28:38,001 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/3/ckpt-50000
2024-11-09 11:28:38,002 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/4
2024-11-09 11:28:38,021 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090144/model/4/ckpt-50000
