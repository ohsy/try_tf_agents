2024-11-09 09:01:56.088910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-09 09:01:56.088973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-09 09:01:56.089779: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-09 09:01:56.097580: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-09 09:01:56.806801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'DaisoSokcho_discrete', '-a', 'DQN_multiagent', '-n', '3']
2024-11-09 09:01:58.728637: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-09 09:01:58.728690: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-09 09:01:58.728699: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-09 09:01:58.728904: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-09 09:01:58.728944: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-09 09:01:58.728953: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-09 09:01:58,758 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 50000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-09 09:01:58,759 - INFO - args=Namespace(environment='DaisoSokcho_discrete', environment_wrapper=None, agent='DQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3)
2024-11-09 09:01:58,759 - INFO - environment=DaisoSokcho_discrete
2024-11-09 09:01:58,759 - INFO - envWrapper=None
2024-11-09 09:01:58,759 - INFO - agent=DQN_multiagent
Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

2024-11-09 09:01:59,605 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))
2024-11-09 09:01:59,605 - INFO - tf_action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32))
2024-11-09 09:01:59,606 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))})
2024-11-09 09:01:59,934 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32)),
 'action': BoundedTensorSpec(shape=(5,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array([5, 7, 5, 5, 5], dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 09:02:00,075 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-09 09:02:32,132 - INFO - random_policy avg_return=-376.99664306640625
2024-11-09 09:02:32,132 - INFO - replay_buffer.capacity=10000
2024-11-09 09:02:32,135 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-09 09:08:19,811 - INFO - after filling with random_policies, replay_buffer.num_frames()=10000
2024-11-09 09:09:02,227 - INFO - before training, avg_return=-440.5069274902344
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-09 09:09:02,321 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
WARNING:tensorflow:5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7f773c5d3eb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 09:09:28,182 - WARNING - 5 out of the last 5 calls to <bound method TFAgent.train of <tf_agents.agents.dqn.dqn_agent.DqnAgent object at 0x7f773c5d3eb0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
2024-11-09 09:09:45,570 - INFO - train_step=200 loss=251492816.000 time=43.342
2024-11-09 09:10:03,533 - INFO - train_step=400 loss=4138529792.000 time=17.963
2024-11-09 09:10:22,026 - INFO - train_step=600 loss=30039732224.000 time=18.493
2024-11-09 09:10:40,316 - INFO - train_step=800 loss=2295757056.000 time=18.290
2024-11-09 09:10:58,731 - INFO - train_step=1000 loss=4255409152.000 time=18.415
2024-11-09 09:11:44,740 - INFO - train_step=1000 avg_return=-426.691
2024-11-09 09:12:02,992 - INFO - train_step=1200 loss=9236725760.000 time=64.261
2024-11-09 09:12:20,629 - INFO - train_step=1400 loss=66828615680.000 time=17.636
2024-11-09 09:12:39,810 - INFO - train_step=1600 loss=38809927680.000 time=19.182
2024-11-09 09:12:59,299 - INFO - train_step=1800 loss=96651067392.000 time=19.489
2024-11-09 09:13:18,397 - INFO - train_step=2000 loss=30185558016.000 time=19.098
2024-11-09 09:14:07,202 - INFO - train_step=2000 avg_return=-461.086
2024-11-09 09:14:25,338 - INFO - train_step=2200 loss=4941199360.000 time=66.941
2024-11-09 09:14:43,296 - INFO - train_step=2400 loss=22419429376.000 time=17.958
2024-11-09 09:15:02,245 - INFO - train_step=2600 loss=4656358400.000 time=18.948
2024-11-09 09:15:21,130 - INFO - train_step=2800 loss=3532109824.000 time=18.886
2024-11-09 09:15:40,038 - INFO - train_step=3000 loss=5130437120.000 time=18.908
2024-11-09 09:16:27,729 - INFO - train_step=3000 avg_return=-208.881
2024-11-09 09:16:45,995 - INFO - train_step=3200 loss=4286453504.000 time=65.957
2024-11-09 09:17:03,930 - INFO - train_step=3400 loss=10213793792.000 time=17.935
2024-11-09 09:17:22,181 - INFO - train_step=3600 loss=5783993344.000 time=18.251
2024-11-09 09:17:41,191 - INFO - train_step=3800 loss=5615771648.000 time=19.010
2024-11-09 09:18:00,257 - INFO - train_step=4000 loss=2265835008.000 time=19.066
2024-11-09 09:18:48,604 - INFO - train_step=4000 avg_return=-418.983
2024-11-09 09:19:07,854 - INFO - train_step=4200 loss=3870793216.000 time=67.597
2024-11-09 09:19:25,927 - INFO - train_step=4400 loss=2130294400.000 time=18.073
2024-11-09 09:19:44,015 - INFO - train_step=4600 loss=923694656.000 time=18.088
2024-11-09 09:20:03,004 - INFO - train_step=4800 loss=1098816000.000 time=18.989
2024-11-09 09:20:21,886 - INFO - train_step=5000 loss=969555136.000 time=18.883
2024-11-09 09:21:10,412 - INFO - train_step=5000 avg_return=-210.639
2024-11-09 09:21:30,138 - INFO - train_step=5200 loss=797058176.000 time=68.251
2024-11-09 09:21:48,175 - INFO - train_step=5400 loss=684266880.000 time=18.037
2024-11-09 09:22:05,729 - INFO - train_step=5600 loss=363391808.000 time=17.555
2024-11-09 09:22:23,147 - INFO - train_step=5800 loss=487134528.000 time=17.418
2024-11-09 09:22:42,755 - INFO - train_step=6000 loss=386247296.000 time=19.608
2024-11-09 09:23:30,845 - INFO - train_step=6000 avg_return=-363.512
2024-11-09 09:23:50,130 - INFO - train_step=6200 loss=690239488.000 time=67.375
2024-11-09 09:24:09,197 - INFO - train_step=6400 loss=231521200.000 time=19.067
2024-11-09 09:24:27,333 - INFO - train_step=6600 loss=125656472.000 time=18.136
2024-11-09 09:24:44,932 - INFO - train_step=6800 loss=221041232.000 time=17.599
2024-11-09 09:25:03,560 - INFO - train_step=7000 loss=114225856.000 time=18.628
2024-11-09 09:25:51,137 - INFO - train_step=7000 avg_return=-248.566
2024-11-09 09:26:10,617 - INFO - train_step=7200 loss=69658640.000 time=67.056
2024-11-09 09:26:30,405 - INFO - train_step=7400 loss=45063396.000 time=19.788
2024-11-09 09:26:48,663 - INFO - train_step=7600 loss=56701920.000 time=18.258
2024-11-09 09:27:06,473 - INFO - train_step=7800 loss=110005744.000 time=17.810
2024-11-09 09:27:23,733 - INFO - train_step=8000 loss=107625080.000 time=17.260
2024-11-09 09:28:11,332 - INFO - train_step=8000 avg_return=-383.318
2024-11-09 09:28:30,737 - INFO - train_step=8200 loss=109130944.000 time=67.004
2024-11-09 09:28:49,995 - INFO - train_step=8400 loss=29450406.000 time=19.259
2024-11-09 09:29:08,486 - INFO - train_step=8600 loss=125573784.000 time=18.491
2024-11-09 09:29:26,172 - INFO - train_step=8800 loss=112661856.000 time=17.685
2024-11-09 09:29:43,395 - INFO - train_step=9000 loss=128526152.000 time=17.224
2024-11-09 09:30:29,865 - INFO - train_step=9000 avg_return=-352.043
2024-11-09 09:30:49,604 - INFO - train_step=9200 loss=113403704.000 time=66.209
2024-11-09 09:31:08,722 - INFO - train_step=9400 loss=37863692.000 time=19.118
2024-11-09 09:31:28,237 - INFO - train_step=9600 loss=87378768.000 time=19.515
2024-11-09 09:31:46,432 - INFO - train_step=9800 loss=74115696.000 time=18.194
2024-11-09 09:32:03,691 - INFO - train_step=10000 loss=54489040.000 time=17.259
2024-11-09 09:32:49,031 - INFO - train_step=10000 avg_return=-147.015
2024-11-09 09:33:08,016 - INFO - train_step=10200 loss=46538880.000 time=64.325
2024-11-09 09:33:27,381 - INFO - train_step=10400 loss=19927802.000 time=19.364
2024-11-09 09:33:46,622 - INFO - train_step=10600 loss=15767952.000 time=19.241
2024-11-09 09:34:05,572 - INFO - train_step=10800 loss=11847596.000 time=18.950
2024-11-09 09:34:23,390 - INFO - train_step=11000 loss=4338335.500 time=17.818
2024-11-09 09:35:08,024 - INFO - train_step=11000 avg_return=-282.722
2024-11-09 09:35:27,178 - INFO - train_step=11200 loss=2617774.500 time=63.788
2024-11-09 09:35:46,901 - INFO - train_step=11400 loss=2493726.750 time=19.722
2024-11-09 09:36:06,146 - INFO - train_step=11600 loss=1761006.125 time=19.246
2024-11-09 09:36:25,483 - INFO - train_step=11800 loss=1065654.875 time=19.337
2024-11-09 09:36:43,883 - INFO - train_step=12000 loss=683844.688 time=18.400
2024-11-09 09:37:27,342 - INFO - train_step=12000 avg_return=-507.983
2024-11-09 09:37:46,908 - INFO - train_step=12200 loss=458878.250 time=63.025
2024-11-09 09:38:06,562 - INFO - train_step=12400 loss=35455344.000 time=19.654
2024-11-09 09:38:25,721 - INFO - train_step=12600 loss=50082900.000 time=19.159
2024-11-09 09:38:45,027 - INFO - train_step=12800 loss=15344975.000 time=19.306
2024-11-09 09:39:04,239 - INFO - train_step=13000 loss=5930028.500 time=19.212
2024-11-09 09:39:47,600 - INFO - train_step=13000 avg_return=-315.599
2024-11-09 09:40:07,014 - INFO - train_step=13200 loss=1142715.875 time=62.775
2024-11-09 09:40:26,665 - INFO - train_step=13400 loss=959235.250 time=19.651
2024-11-09 09:40:45,654 - INFO - train_step=13600 loss=909149.375 time=18.989
2024-11-09 09:41:05,144 - INFO - train_step=13800 loss=165751712.000 time=19.490
2024-11-09 09:41:24,263 - INFO - train_step=14000 loss=2666605312.000 time=19.119
2024-11-09 09:42:07,477 - INFO - train_step=14000 avg_return=-472.007
2024-11-09 09:42:26,057 - INFO - train_step=14200 loss=2744984576.000 time=61.793
2024-11-09 09:42:45,611 - INFO - train_step=14400 loss=1776446208.000 time=19.554
2024-11-09 09:43:04,615 - INFO - train_step=14600 loss=838693376.000 time=19.004
2024-11-09 09:43:24,067 - INFO - train_step=14800 loss=351601280.000 time=19.452
2024-11-09 09:43:43,629 - INFO - train_step=15000 loss=324717760.000 time=19.563
2024-11-09 09:44:27,512 - INFO - train_step=15000 avg_return=-232.679
2024-11-09 09:44:45,501 - INFO - train_step=15200 loss=117172376.000 time=61.871
2024-11-09 09:45:04,951 - INFO - train_step=15400 loss=127340296.000 time=19.450
2024-11-09 09:45:24,096 - INFO - train_step=15600 loss=31232678.000 time=19.145
2024-11-09 09:45:43,309 - INFO - train_step=15800 loss=51391360.000 time=19.213
2024-11-09 09:46:02,251 - INFO - train_step=16000 loss=1520167808.000 time=18.942
2024-11-09 09:46:47,861 - INFO - train_step=16000 avg_return=-257.912
2024-11-09 09:47:05,557 - INFO - train_step=16200 loss=1581165056.000 time=63.306
2024-11-09 09:47:24,536 - INFO - train_step=16400 loss=504023584.000 time=18.979
2024-11-09 09:47:44,422 - INFO - train_step=16600 loss=176426544.000 time=19.886
2024-11-09 09:48:03,744 - INFO - train_step=16800 loss=187065424.000 time=19.321
2024-11-09 09:48:22,806 - INFO - train_step=17000 loss=12611333120.000 time=19.063
2024-11-09 09:49:08,371 - INFO - train_step=17000 avg_return=-444.552
2024-11-09 09:49:26,391 - INFO - train_step=17200 loss=60788109312.000 time=63.585
2024-11-09 09:49:44,646 - INFO - train_step=17400 loss=28958330880.000 time=18.254
2024-11-09 09:50:03,676 - INFO - train_step=17600 loss=106626285568.000 time=19.030
2024-11-09 09:50:22,783 - INFO - train_step=17800 loss=70870425600.000 time=19.107
2024-11-09 09:50:41,871 - INFO - train_step=18000 loss=89787990016.000 time=19.088
2024-11-09 09:51:27,919 - INFO - train_step=18000 avg_return=-537.654
2024-11-09 09:51:46,056 - INFO - train_step=18200 loss=57413722112.000 time=64.186
2024-11-09 09:52:05,153 - INFO - train_step=18400 loss=43576156160.000 time=19.096
2024-11-09 09:52:23,143 - INFO - train_step=18600 loss=18170429440.000 time=17.990
2024-11-09 09:52:42,250 - INFO - train_step=18800 loss=20641034240.000 time=19.107
2024-11-09 09:53:01,698 - INFO - train_step=19000 loss=8649232384.000 time=19.448
2024-11-09 09:53:48,481 - INFO - train_step=19000 avg_return=-327.661
2024-11-09 09:54:06,661 - INFO - train_step=19200 loss=8617488384.000 time=64.963
2024-11-09 09:54:24,915 - INFO - train_step=19400 loss=3659007488.000 time=18.255
2024-11-09 09:54:42,785 - INFO - train_step=19600 loss=2645752576.000 time=17.870
2024-11-09 09:55:01,665 - INFO - train_step=19800 loss=956598976.000 time=18.879
2024-11-09 09:55:20,626 - INFO - train_step=20000 loss=1763811328.000 time=18.961
2024-11-09 09:56:08,140 - INFO - train_step=20000 avg_return=-248.512
2024-11-09 09:56:27,272 - INFO - train_step=20200 loss=364774400.000 time=66.646
2024-11-09 09:56:45,633 - INFO - train_step=20400 loss=562881152.000 time=18.361
2024-11-09 09:57:03,460 - INFO - train_step=20600 loss=587724928.000 time=17.827
2024-11-09 09:57:20,738 - INFO - train_step=20800 loss=967479424.000 time=17.278
2024-11-09 09:57:37,669 - INFO - train_step=21000 loss=165263472.000 time=16.931
2024-11-09 09:58:18,342 - INFO - train_step=21000 avg_return=-364.411
2024-11-09 09:58:35,327 - INFO - train_step=21200 loss=298259296.000 time=57.658
2024-11-09 09:58:52,909 - INFO - train_step=21400 loss=529677984.000 time=17.582
2024-11-09 09:59:09,929 - INFO - train_step=21600 loss=65515288.000 time=17.020
2024-11-09 09:59:26,905 - INFO - train_step=21800 loss=113166040.000 time=16.976
2024-11-09 09:59:43,910 - INFO - train_step=22000 loss=385401344.000 time=17.005
2024-11-09 10:00:25,936 - INFO - train_step=22000 avg_return=-525.647
2024-11-09 10:00:42,765 - INFO - train_step=22200 loss=410681696.000 time=58.855
2024-11-09 10:01:00,547 - INFO - train_step=22400 loss=47699564.000 time=17.782
2024-11-09 10:01:17,240 - INFO - train_step=22600 loss=36741080.000 time=16.692
2024-11-09 10:01:34,404 - INFO - train_step=22800 loss=11484843.000 time=17.165
2024-11-09 10:01:51,063 - INFO - train_step=23000 loss=21657372.000 time=16.658
2024-11-09 10:02:31,236 - INFO - train_step=23000 avg_return=-343.695
2024-11-09 10:02:47,487 - INFO - train_step=23200 loss=14450067.000 time=56.424
2024-11-09 10:03:05,411 - INFO - train_step=23400 loss=16893958.000 time=17.924
2024-11-09 10:03:22,440 - INFO - train_step=23600 loss=59622228.000 time=17.029
2024-11-09 10:03:38,982 - INFO - train_step=23800 loss=109847432.000 time=16.542
2024-11-09 10:03:56,286 - INFO - train_step=24000 loss=10297519.000 time=17.303
2024-11-09 10:04:37,656 - INFO - train_step=24000 avg_return=-224.638
2024-11-09 10:04:53,931 - INFO - train_step=24200 loss=53355692.000 time=57.645
2024-11-09 10:05:11,560 - INFO - train_step=24400 loss=52984352.000 time=17.629
2024-11-09 10:05:28,700 - INFO - train_step=24600 loss=24475874.000 time=17.141
2024-11-09 10:05:45,746 - INFO - train_step=24800 loss=20437352.000 time=17.046
2024-11-09 10:06:02,545 - INFO - train_step=25000 loss=118496408.000 time=16.799
2024-11-09 10:06:43,801 - INFO - train_step=25000 avg_return=-478.865
2024-11-09 10:07:00,067 - INFO - train_step=25200 loss=48084356.000 time=57.522
2024-11-09 10:07:17,933 - INFO - train_step=25400 loss=6070688.500 time=17.866
2024-11-09 10:07:34,784 - INFO - train_step=25600 loss=295992096.000 time=16.851
2024-11-09 10:07:52,027 - INFO - train_step=25800 loss=61780248.000 time=17.243
2024-11-09 10:08:08,398 - INFO - train_step=26000 loss=9865336.000 time=16.372
2024-11-09 10:08:49,822 - INFO - train_step=26000 avg_return=-499.226
2024-11-09 10:09:05,834 - INFO - train_step=26200 loss=44876816.000 time=57.436
2024-11-09 10:09:23,102 - INFO - train_step=26400 loss=20168042.000 time=17.268
2024-11-09 10:09:40,665 - INFO - train_step=26600 loss=12309041.000 time=17.563
2024-11-09 10:09:57,618 - INFO - train_step=26800 loss=73301248.000 time=16.953
2024-11-09 10:10:14,487 - INFO - train_step=27000 loss=16932488.000 time=16.869
2024-11-09 10:10:56,413 - INFO - train_step=27000 avg_return=-488.377
2024-11-09 10:11:12,432 - INFO - train_step=27200 loss=19466694.000 time=57.945
2024-11-09 10:11:30,276 - INFO - train_step=27400 loss=12601880.000 time=17.843
2024-11-09 10:11:47,189 - INFO - train_step=27600 loss=3620801.250 time=16.913
2024-11-09 10:12:04,062 - INFO - train_step=27800 loss=2922564.500 time=16.873
2024-11-09 10:12:20,955 - INFO - train_step=28000 loss=4934095.500 time=16.893
2024-11-09 10:13:13,768 - INFO - train_step=28000 avg_return=-372.204
2024-11-09 10:13:36,337 - INFO - train_step=28200 loss=3509147.250 time=75.382
2024-11-09 10:13:59,200 - INFO - train_step=28400 loss=1524942.250 time=22.863
2024-11-09 10:14:21,664 - INFO - train_step=28600 loss=5263267.000 time=22.464
2024-11-09 10:14:47,713 - INFO - train_step=28800 loss=3230251.250 time=26.049
2024-11-09 10:15:26,309 - INFO - train_step=29000 loss=3627470.250 time=38.595
2024-11-09 10:17:19,890 - INFO - train_step=29000 avg_return=-417.455
2024-11-09 10:17:46,019 - INFO - train_step=29200 loss=7750161.500 time=139.710
2024-11-09 10:18:15,581 - INFO - train_step=29400 loss=2672555.250 time=29.563
2024-11-09 10:18:33,286 - INFO - train_step=29600 loss=3576829.250 time=17.704
2024-11-09 10:18:55,432 - INFO - train_step=29800 loss=4159659.750 time=22.146
2024-11-09 10:19:18,154 - INFO - train_step=30000 loss=4176366.250 time=22.722
2024-11-09 10:20:22,117 - INFO - train_step=30000 avg_return=-285.518
2024-11-09 10:20:55,446 - INFO - train_step=30200 loss=6324314.000 time=97.292
2024-11-09 10:21:21,457 - INFO - train_step=30400 loss=1490063.500 time=26.011
2024-11-09 10:21:51,668 - INFO - train_step=30600 loss=724424.750 time=30.211
2024-11-09 10:22:21,094 - INFO - train_step=30800 loss=1549045.625 time=29.426
2024-11-09 10:22:47,090 - INFO - train_step=31000 loss=849949.312 time=25.996
2024-11-09 10:24:08,406 - INFO - train_step=31000 avg_return=-299.858
2024-11-09 10:24:32,690 - INFO - train_step=31200 loss=1793777.000 time=105.600
2024-11-09 10:25:04,664 - INFO - train_step=31400 loss=4196587.000 time=31.974
2024-11-09 10:25:32,614 - INFO - train_step=31600 loss=748159.000 time=27.950
2024-11-09 10:26:00,210 - INFO - train_step=31800 loss=427713.062 time=27.596
2024-11-09 10:26:30,925 - INFO - train_step=32000 loss=252661.812 time=30.715
2024-11-09 10:27:44,538 - INFO - train_step=32000 avg_return=-382.409
2024-11-09 10:28:17,075 - INFO - train_step=32200 loss=130192.836 time=106.150
2024-11-09 10:28:42,995 - INFO - train_step=32400 loss=267879.000 time=25.920
2024-11-09 10:29:13,794 - INFO - train_step=32600 loss=267813.062 time=30.799
2024-11-09 10:29:42,591 - INFO - train_step=32800 loss=313416.125 time=28.797
2024-11-09 10:30:08,600 - INFO - train_step=33000 loss=238693.531 time=26.010
2024-11-09 10:31:29,502 - INFO - train_step=33000 avg_return=-261.111
2024-11-09 10:31:55,074 - INFO - train_step=33200 loss=1144838.500 time=106.473
2024-11-09 10:32:27,291 - INFO - train_step=33400 loss=208710.672 time=32.217
2024-11-09 10:32:55,308 - INFO - train_step=33600 loss=258719.406 time=28.017
2024-11-09 10:33:23,721 - INFO - train_step=33800 loss=5398644.500 time=28.413
2024-11-09 10:33:55,182 - INFO - train_step=34000 loss=292155.969 time=31.461
2024-11-09 10:35:04,759 - INFO - train_step=34000 avg_return=-320.874
2024-11-09 10:35:36,720 - INFO - train_step=34200 loss=125765.312 time=101.538
2024-11-09 10:36:03,231 - INFO - train_step=34400 loss=177928.812 time=26.511
2024-11-09 10:36:34,017 - INFO - train_step=34600 loss=185412.625 time=30.786
2024-11-09 10:37:02,851 - INFO - train_step=34800 loss=248422.641 time=28.834
2024-11-09 10:37:29,758 - INFO - train_step=35000 loss=157110.312 time=26.907
2024-11-09 10:38:49,656 - INFO - train_step=35000 avg_return=-234.719
2024-11-09 10:39:14,419 - INFO - train_step=35200 loss=150935.562 time=104.662
2024-11-09 10:39:46,554 - INFO - train_step=35400 loss=348063.188 time=32.134
2024-11-09 10:40:14,830 - INFO - train_step=35600 loss=1509730.375 time=28.276
2024-11-09 10:40:43,254 - INFO - train_step=35800 loss=275122.656 time=28.424
2024-11-09 10:41:13,803 - INFO - train_step=36000 loss=201797.062 time=30.550
2024-11-09 10:42:28,201 - INFO - train_step=36000 avg_return=-269.095
2024-11-09 10:42:59,907 - INFO - train_step=36200 loss=153990.422 time=106.103
2024-11-09 10:43:26,791 - INFO - train_step=36400 loss=5846951.500 time=26.884
2024-11-09 10:43:56,574 - INFO - train_step=36600 loss=248107.094 time=29.782
2024-11-09 10:44:26,754 - INFO - train_step=36800 loss=161238.719 time=30.180
2024-11-09 10:44:52,706 - INFO - train_step=37000 loss=220792.094 time=25.953
2024-11-09 10:46:12,678 - INFO - train_step=37000 avg_return=-257.536
2024-11-09 10:46:39,004 - INFO - train_step=37200 loss=138028.828 time=106.298
2024-11-09 10:47:09,541 - INFO - train_step=37400 loss=87138.938 time=30.537
2024-11-09 10:47:38,946 - INFO - train_step=37600 loss=36907244.000 time=29.405
2024-11-09 10:48:05,874 - INFO - train_step=37800 loss=202419552.000 time=26.928
2024-11-09 10:48:37,747 - INFO - train_step=38000 loss=60076324.000 time=31.873
2024-11-09 10:49:48,614 - INFO - train_step=38000 avg_return=-224.397
2024-11-09 10:50:20,353 - INFO - train_step=38200 loss=10384680.000 time=102.605
2024-11-09 10:50:47,312 - INFO - train_step=38400 loss=3591229.500 time=26.959
2024-11-09 10:51:17,139 - INFO - train_step=38600 loss=2462165.000 time=29.827
2024-11-09 10:51:47,175 - INFO - train_step=38800 loss=1976026.125 time=30.036
2024-11-09 10:52:13,141 - INFO - train_step=39000 loss=627749.438 time=25.966
2024-11-09 10:53:30,031 - INFO - train_step=39000 avg_return=-463.569
2024-11-09 10:53:55,837 - INFO - train_step=39200 loss=1653223.250 time=102.697
2024-11-09 10:54:27,146 - INFO - train_step=39400 loss=2154610.500 time=31.309
2024-11-09 10:54:55,611 - INFO - train_step=39600 loss=317036.688 time=28.465
2024-11-09 10:55:23,940 - INFO - train_step=39800 loss=573881.375 time=28.329
2024-11-09 10:55:54,602 - INFO - train_step=40000 loss=549049.875 time=30.662
2024-11-09 10:57:08,318 - INFO - train_step=40000 avg_return=-235.904
2024-11-09 10:57:38,992 - INFO - train_step=40200 loss=1075684.750 time=104.390
2024-11-09 10:58:06,551 - INFO - train_step=40400 loss=358372.844 time=27.559
2024-11-09 10:58:36,208 - INFO - train_step=40600 loss=792435.688 time=29.657
2024-11-09 10:59:05,620 - INFO - train_step=40800 loss=160840.219 time=29.412
2024-11-09 10:59:32,240 - INFO - train_step=41000 loss=196451.906 time=26.620
2024-11-09 11:00:50,939 - INFO - train_step=41000 avg_return=-408.116
2024-11-09 11:01:13,601 - INFO - train_step=41200 loss=5632571.000 time=101.362
2024-11-09 11:01:34,736 - INFO - train_step=41400 loss=594493.875 time=21.135
2024-11-09 11:01:57,473 - INFO - train_step=41600 loss=87323.945 time=22.737
2024-11-09 11:02:20,345 - INFO - train_step=41800 loss=70299.125 time=22.872
2024-11-09 11:02:43,105 - INFO - train_step=42000 loss=145623.188 time=22.760
2024-11-09 11:03:47,525 - INFO - train_step=42000 avg_return=-210.038
2024-11-09 11:04:11,687 - INFO - train_step=42200 loss=487693.438 time=88.583
2024-11-09 11:04:37,427 - INFO - train_step=42400 loss=858501.500 time=25.740
2024-11-09 11:05:03,201 - INFO - train_step=42600 loss=588830.188 time=25.774
2024-11-09 11:05:28,424 - INFO - train_step=42800 loss=316844.781 time=25.223
2024-11-09 11:05:53,567 - INFO - train_step=43000 loss=207185.469 time=25.143
2024-11-09 11:07:00,036 - INFO - train_step=43000 avg_return=-384.954
2024-11-09 11:07:25,192 - INFO - train_step=43200 loss=42454.621 time=91.625
2024-11-09 11:07:50,982 - INFO - train_step=43400 loss=68713.234 time=25.790
2024-11-09 11:08:16,624 - INFO - train_step=43600 loss=183029.797 time=25.642
2024-11-09 11:08:42,011 - INFO - train_step=43800 loss=192945.406 time=25.387
2024-11-09 11:09:07,643 - INFO - train_step=44000 loss=12096735.000 time=25.632
2024-11-09 11:10:12,610 - INFO - train_step=44000 avg_return=-476.333
2024-11-09 11:10:37,339 - INFO - train_step=44200 loss=6595292.500 time=89.696
2024-11-09 11:11:02,939 - INFO - train_step=44400 loss=690112.938 time=25.600
2024-11-09 11:11:28,366 - INFO - train_step=44600 loss=398624.094 time=25.427
2024-11-09 11:11:53,969 - INFO - train_step=44800 loss=210943.094 time=25.603
2024-11-09 11:12:18,536 - INFO - train_step=45000 loss=2374050.500 time=24.567
2024-11-09 11:13:25,306 - INFO - train_step=45000 avg_return=-339.695
2024-11-09 11:13:50,494 - INFO - train_step=45200 loss=552603.625 time=91.958
2024-11-09 11:14:16,132 - INFO - train_step=45400 loss=63644.355 time=25.637
2024-11-09 11:14:42,412 - INFO - train_step=45600 loss=95597.836 time=26.280
2024-11-09 11:15:07,777 - INFO - train_step=45800 loss=1748238.125 time=25.365
2024-11-09 11:15:32,263 - INFO - train_step=46000 loss=386378.469 time=24.487
2024-11-09 11:16:32,925 - INFO - train_step=46000 avg_return=-418.310
2024-11-09 11:16:53,891 - INFO - train_step=46200 loss=152199.094 time=81.628
2024-11-09 11:17:15,532 - INFO - train_step=46400 loss=2884473.000 time=21.640
2024-11-09 11:17:38,682 - INFO - train_step=46600 loss=105717.141 time=23.151
2024-11-09 11:18:02,857 - INFO - train_step=46800 loss=59362.871 time=24.175
2024-11-09 11:18:26,837 - INFO - train_step=47000 loss=42670.309 time=23.980
2024-11-09 11:19:31,076 - INFO - train_step=47000 avg_return=-330.029
2024-11-09 11:19:55,674 - INFO - train_step=47200 loss=36921.168 time=88.837
2024-11-09 11:20:20,489 - INFO - train_step=47400 loss=32904.742 time=24.815
2024-11-09 11:20:45,448 - INFO - train_step=47600 loss=50564.234 time=24.959
2024-11-09 11:21:10,099 - INFO - train_step=47800 loss=73841.336 time=24.652
2024-11-09 11:21:34,223 - INFO - train_step=48000 loss=34097.105 time=24.124
2024-11-09 11:22:39,137 - INFO - train_step=48000 avg_return=-446.607
2024-11-09 11:23:03,588 - INFO - train_step=48200 loss=69990.750 time=89.364
2024-11-09 11:23:27,137 - INFO - train_step=48400 loss=89752.578 time=23.549
2024-11-09 11:23:50,335 - INFO - train_step=48600 loss=42405.668 time=23.198
2024-11-09 11:24:12,610 - INFO - train_step=48800 loss=40444.938 time=22.275
2024-11-09 11:24:35,223 - INFO - train_step=49000 loss=33201.797 time=22.613
2024-11-09 11:25:32,119 - INFO - train_step=49000 avg_return=-325.669
2024-11-09 11:25:55,386 - INFO - train_step=49200 loss=31508.500 time=80.162
2024-11-09 11:26:18,360 - INFO - train_step=49400 loss=18488.676 time=22.974
2024-11-09 11:26:41,443 - INFO - train_step=49600 loss=40440.059 time=23.083
2024-11-09 11:27:04,430 - INFO - train_step=49800 loss=61528.945 time=22.987
2024-11-09 11:27:27,327 - INFO - train_step=50000 loss=9944840.000 time=22.898
2024-11-09 11:28:27,558 - INFO - train_step=50000 avg_return=-421.634
2024-11-09 11:28:27,558 - INFO - total_time=8407.747
2024-11-09 11:28:27,558 - INFO - saving, checkpointPath_toSave=./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model
2024-11-09 11:28:27,559 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/0
2024-11-09 11:28:27,602 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/0/ckpt-50000
2024-11-09 11:28:27,602 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/1
2024-11-09 11:28:27,627 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/1/ckpt-50000
2024-11-09 11:28:27,627 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/2
2024-11-09 11:28:27,647 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/2/ckpt-50000
2024-11-09 11:28:27,648 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/3
2024-11-09 11:28:27,668 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/3/ckpt-50000
2024-11-09 11:28:27,668 - INFO - No checkpoint available at ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/4
2024-11-09 11:28:27,689 - INFO - Saved checkpoint: ./result/DaisoSokcho_discrete_DQN_multiagent_1109_090158/model/4/ckpt-50000
