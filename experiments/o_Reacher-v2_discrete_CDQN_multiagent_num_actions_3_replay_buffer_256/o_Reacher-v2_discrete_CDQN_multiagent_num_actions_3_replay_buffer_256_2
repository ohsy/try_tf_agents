2024-11-12 20:32:11.854289: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/Users/yoh/tf_venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020
  warnings.warn(
online arguments=['play_mini.py', '-e', 'Reacher-v2_discrete', '-a', 'CDQN_multiagent', '-n', '3']
2024-11-12 20:32:17,207 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 10000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'replay_buffer_max_length': 256, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 256, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-12 20:32:17,208 - INFO - args=Namespace(environment='Reacher-v2_discrete', environment_wrapper=None, agent='CDQN_multiagent', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=3, num_init_collect_steps=None)
2024-11-12 20:32:17,208 - INFO - environment=Reacher-v2_discrete
2024-11-12 20:32:17,208 - INFO - envWrapper=None
2024-11-12 20:32:17,208 - INFO - agent=CDQN_multiagent
objc[19725]: Class GLFWApplicationDelegate is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x139bce778) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13e3127e8). One of the two will be used. Which one is undefined.
objc[19725]: Class GLFWWindowDelegate is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x139bce700) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13e312810). One of the two will be used. Which one is undefined.
objc[19725]: Class GLFWContentView is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x139bce7a0) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13e312860). One of the two will be used. Which one is undefined.
objc[19725]: Class GLFWWindow is implemented in both /Users/yoh/.mujoco/mujoco210/bin/libglfw.3.dylib (0x139bce818) and /Users/yoh/tf_venv/lib/python3.9/site-packages/glfw/libglfw.3.dylib (0x13e3128d8). One of the two will be used. Which one is undefined.
2024-11-12 20:32:18,469 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))
2024-11-12 20:32:18,470 - INFO - tf_action_spec: BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32))
2024-11-12 20:32:18,471 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308))})
2024-11-12 20:32:18,872 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(11,), dtype=tf.float64, name='observation', minimum=array(-1.797693e+308), maximum=array(1.797693e+308)),
 'action': BoundedTensorSpec(shape=(2,), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-12 20:32:19,095 - WARNING - From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-12 20:32:22,906 - INFO - random_policy avg_return=-77.5912094116211
2024-11-12 20:32:22,922 - INFO - replay_buffer.capacity=256
2024-11-12 20:32:22,930 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-12 20:32:24,856 - INFO - after filling with random_policies, replay_buffer.num_frames()=256
2024-11-12 20:32:35,279 - INFO - before training, avg_return=-19.30508804321289
WARNING:tensorflow:From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-12 20:32:35,516 - WARNING - From /Users/yoh/tf_venv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.
Instructions for updating:
back_prop=False is deprecated. Consider using tf.stop_gradient instead.
Instead of:
results = tf.foldr(fn, elems, back_prop=False)
Use:
results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))
2024-11-12 20:32:52,027 - INFO - train_step=40 loss=7.427 time=16.745
2024-11-12 20:32:54,724 - INFO - train_step=80 loss=7.513 time=2.696
2024-11-12 20:32:57,350 - INFO - train_step=120 loss=7.103 time=2.626
2024-11-12 20:32:59,974 - INFO - train_step=160 loss=7.391 time=2.624
2024-11-12 20:33:02,430 - INFO - train_step=200 loss=7.053 time=2.456
2024-11-12 20:33:13,112 - INFO - train_step=200 avg_return=-27.757
2024-11-12 20:33:15,713 - INFO - train_step=240 loss=7.084 time=13.283
2024-11-12 20:33:18,323 - INFO - train_step=280 loss=7.103 time=2.610
2024-11-12 20:33:20,971 - INFO - train_step=320 loss=7.038 time=2.648
2024-11-12 20:33:23,582 - INFO - train_step=360 loss=6.698 time=2.611
2024-11-12 20:33:26,160 - INFO - train_step=400 loss=6.699 time=2.578
2024-11-12 20:33:37,622 - INFO - train_step=400 avg_return=-15.091
2024-11-12 20:33:40,242 - INFO - train_step=440 loss=6.353 time=14.083
2024-11-12 20:33:42,988 - INFO - train_step=480 loss=6.268 time=2.745
2024-11-12 20:33:46,111 - INFO - train_step=520 loss=6.502 time=3.123
2024-11-12 20:33:49,160 - INFO - train_step=560 loss=5.886 time=3.050
2024-11-12 20:33:51,902 - INFO - train_step=600 loss=5.319 time=2.742
2024-11-12 20:34:05,115 - INFO - train_step=600 avg_return=-13.662
2024-11-12 20:34:08,604 - INFO - train_step=640 loss=5.484 time=16.702
2024-11-12 20:34:11,679 - INFO - train_step=680 loss=5.669 time=3.076
2024-11-12 20:34:14,983 - INFO - train_step=720 loss=5.200 time=3.304
2024-11-12 20:34:18,059 - INFO - train_step=760 loss=4.648 time=3.076
2024-11-12 20:34:20,884 - INFO - train_step=800 loss=5.199 time=2.825
2024-11-12 20:34:32,475 - INFO - train_step=800 avg_return=-50.524
2024-11-12 20:34:34,963 - INFO - train_step=840 loss=6.141 time=14.079
2024-11-12 20:34:37,622 - INFO - train_step=880 loss=5.894 time=2.658
2024-11-12 20:34:40,239 - INFO - train_step=920 loss=5.455 time=2.617
2024-11-12 20:34:42,854 - INFO - train_step=960 loss=5.538 time=2.616
2024-11-12 20:34:45,451 - INFO - train_step=1000 loss=5.749 time=2.597
2024-11-12 20:34:56,423 - INFO - train_step=1000 avg_return=-12.418
2024-11-12 20:34:58,760 - INFO - train_step=1040 loss=5.865 time=13.309
2024-11-12 20:35:01,279 - INFO - train_step=1080 loss=5.763 time=2.519
2024-11-12 20:35:04,099 - INFO - train_step=1120 loss=5.773 time=2.820
2024-11-12 20:35:06,726 - INFO - train_step=1160 loss=6.012 time=2.628
2024-11-12 20:35:09,646 - INFO - train_step=1200 loss=6.286 time=2.920
2024-11-12 20:35:20,801 - INFO - train_step=1200 avg_return=-16.680
2024-11-12 20:35:23,009 - INFO - train_step=1240 loss=6.156 time=13.363
2024-11-12 20:35:25,759 - INFO - train_step=1280 loss=6.010 time=2.750
2024-11-12 20:35:28,407 - INFO - train_step=1320 loss=5.912 time=2.648
2024-11-12 20:35:31,042 - INFO - train_step=1360 loss=6.171 time=2.635
2024-11-12 20:35:34,413 - INFO - train_step=1400 loss=6.081 time=3.371
2024-11-12 20:35:48,159 - INFO - train_step=1400 avg_return=-12.197
2024-11-12 20:35:50,579 - INFO - train_step=1440 loss=5.878 time=16.166
2024-11-12 20:35:53,260 - INFO - train_step=1480 loss=6.026 time=2.681
2024-11-12 20:35:56,116 - INFO - train_step=1520 loss=6.467 time=2.856
2024-11-12 20:35:58,753 - INFO - train_step=1560 loss=5.931 time=2.637
2024-11-12 20:36:01,598 - INFO - train_step=1600 loss=6.197 time=2.845
2024-11-12 20:36:13,697 - INFO - train_step=1600 avg_return=-14.995
2024-11-12 20:36:16,067 - INFO - train_step=1640 loss=5.983 time=14.469
2024-11-12 20:36:18,636 - INFO - train_step=1680 loss=5.876 time=2.569
2024-11-12 20:36:21,403 - INFO - train_step=1720 loss=5.798 time=2.767
2024-11-12 20:36:24,150 - INFO - train_step=1760 loss=5.813 time=2.747
2024-11-12 20:36:26,835 - INFO - train_step=1800 loss=5.846 time=2.685
2024-11-12 20:36:38,998 - INFO - train_step=1800 avg_return=-14.825
2024-11-12 20:36:41,150 - INFO - train_step=1840 loss=5.682 time=14.315
2024-11-12 20:36:44,458 - INFO - train_step=1880 loss=5.770 time=3.307
2024-11-12 20:36:48,129 - INFO - train_step=1920 loss=5.818 time=3.672
2024-11-12 20:36:51,296 - INFO - train_step=1960 loss=5.834 time=3.166
2024-11-12 20:36:54,162 - INFO - train_step=2000 loss=5.770 time=2.866
2024-11-12 20:37:07,141 - INFO - train_step=2000 avg_return=-12.176
2024-11-12 20:37:10,453 - INFO - train_step=2040 loss=5.801 time=16.292
2024-11-12 20:37:14,260 - INFO - train_step=2080 loss=6.102 time=3.807
2024-11-12 20:37:17,640 - INFO - train_step=2120 loss=6.395 time=3.380
2024-11-12 20:37:20,912 - INFO - train_step=2160 loss=6.418 time=3.272
2024-11-12 20:37:24,287 - INFO - train_step=2200 loss=6.380 time=3.375
2024-11-12 20:37:36,617 - INFO - train_step=2200 avg_return=-21.431
2024-11-12 20:37:38,956 - INFO - train_step=2240 loss=6.436 time=14.669
2024-11-12 20:37:41,667 - INFO - train_step=2280 loss=6.274 time=2.711
2024-11-12 20:37:44,426 - INFO - train_step=2320 loss=6.206 time=2.759
2024-11-12 20:37:47,188 - INFO - train_step=2360 loss=5.891 time=2.762
2024-11-12 20:37:49,886 - INFO - train_step=2400 loss=5.987 time=2.698
2024-11-12 20:38:01,367 - INFO - train_step=2400 avg_return=-12.017
2024-11-12 20:38:03,575 - INFO - train_step=2440 loss=6.021 time=13.688
2024-11-12 20:38:06,144 - INFO - train_step=2480 loss=5.915 time=2.570
2024-11-12 20:38:08,980 - INFO - train_step=2520 loss=5.823 time=2.836
2024-11-12 20:38:11,847 - INFO - train_step=2560 loss=5.960 time=2.867
2024-11-12 20:38:14,538 - INFO - train_step=2600 loss=5.857 time=2.691
2024-11-12 20:38:25,903 - INFO - train_step=2600 avg_return=-17.031
2024-11-12 20:38:28,056 - INFO - train_step=2640 loss=5.820 time=13.517
2024-11-12 20:38:30,534 - INFO - train_step=2680 loss=6.081 time=2.478
2024-11-12 20:38:33,130 - INFO - train_step=2720 loss=6.271 time=2.596
2024-11-12 20:38:35,819 - INFO - train_step=2760 loss=6.390 time=2.689
2024-11-12 20:38:38,487 - INFO - train_step=2800 loss=6.495 time=2.668
2024-11-12 20:38:50,975 - INFO - train_step=2800 avg_return=-12.023
2024-11-12 20:38:53,224 - INFO - train_step=2840 loss=6.539 time=14.737
2024-11-12 20:38:55,701 - INFO - train_step=2880 loss=6.375 time=2.477
2024-11-12 20:38:58,481 - INFO - train_step=2920 loss=6.294 time=2.780
2024-11-12 20:39:01,268 - INFO - train_step=2960 loss=6.310 time=2.788
2024-11-12 20:39:04,290 - INFO - train_step=3000 loss=6.451 time=3.021
2024-11-12 20:39:17,446 - INFO - train_step=3000 avg_return=-14.101
2024-11-12 20:39:19,570 - INFO - train_step=3040 loss=6.318 time=15.280
2024-11-12 20:39:22,078 - INFO - train_step=3080 loss=6.420 time=2.508
2024-11-12 20:39:24,795 - INFO - train_step=3120 loss=6.033 time=2.717
2024-11-12 20:39:28,244 - INFO - train_step=3160 loss=6.176 time=3.449
2024-11-12 20:39:31,273 - INFO - train_step=3200 loss=6.234 time=3.029
2024-11-12 20:39:42,957 - INFO - train_step=3200 avg_return=-14.014
2024-11-12 20:39:45,032 - INFO - train_step=3240 loss=6.530 time=13.759
2024-11-12 20:39:47,431 - INFO - train_step=3280 loss=6.607 time=2.399
2024-11-12 20:39:49,930 - INFO - train_step=3320 loss=5.947 time=2.499
2024-11-12 20:39:52,550 - INFO - train_step=3360 loss=6.005 time=2.620
2024-11-12 20:39:55,105 - INFO - train_step=3400 loss=6.508 time=2.555
2024-11-12 20:40:07,455 - INFO - train_step=3400 avg_return=-40.006
2024-11-12 20:40:09,468 - INFO - train_step=3440 loss=5.453 time=14.362
2024-11-12 20:40:12,160 - INFO - train_step=3480 loss=6.043 time=2.692
2024-11-12 20:40:14,731 - INFO - train_step=3520 loss=6.503 time=2.571
2024-11-12 20:40:17,345 - INFO - train_step=3560 loss=5.939 time=2.614
2024-11-12 20:40:19,953 - INFO - train_step=3600 loss=6.336 time=2.608
2024-11-12 20:40:31,546 - INFO - train_step=3600 avg_return=-13.419
2024-11-12 20:40:33,652 - INFO - train_step=3640 loss=6.227 time=13.699
2024-11-12 20:40:35,969 - INFO - train_step=3680 loss=6.127 time=2.318
2024-11-12 20:40:38,408 - INFO - train_step=3720 loss=6.167 time=2.439
2024-11-12 20:40:41,062 - INFO - train_step=3760 loss=6.273 time=2.654
2024-11-12 20:40:43,624 - INFO - train_step=3800 loss=6.037 time=2.562
2024-11-12 20:40:56,004 - INFO - train_step=3800 avg_return=-34.703
2024-11-12 20:40:58,017 - INFO - train_step=3840 loss=6.214 time=14.393
2024-11-12 20:41:00,499 - INFO - train_step=3880 loss=6.275 time=2.481
2024-11-12 20:41:03,176 - INFO - train_step=3920 loss=6.089 time=2.677
2024-11-12 20:41:06,160 - INFO - train_step=3960 loss=6.316 time=2.985
2024-11-12 20:41:08,948 - INFO - train_step=4000 loss=6.111 time=2.788
2024-11-12 20:41:21,204 - INFO - train_step=4000 avg_return=-13.214
2024-11-12 20:41:23,309 - INFO - train_step=4040 loss=5.965 time=14.360
2024-11-12 20:41:25,989 - INFO - train_step=4080 loss=6.183 time=2.681
2024-11-12 20:41:28,717 - INFO - train_step=4120 loss=6.356 time=2.728
2024-11-12 20:41:31,393 - INFO - train_step=4160 loss=6.252 time=2.676
2024-11-12 20:41:34,231 - INFO - train_step=4200 loss=6.404 time=2.838
2024-11-12 20:41:46,811 - INFO - train_step=4200 avg_return=-31.048
2024-11-12 20:41:48,988 - INFO - train_step=4240 loss=6.847 time=14.757
2024-11-12 20:41:51,385 - INFO - train_step=4280 loss=6.705 time=2.397
2024-11-12 20:41:54,109 - INFO - train_step=4320 loss=6.501 time=2.724
2024-11-12 20:41:56,679 - INFO - train_step=4360 loss=6.300 time=2.570
2024-11-12 20:41:59,596 - INFO - train_step=4400 loss=5.954 time=2.917
2024-11-12 20:42:12,313 - INFO - train_step=4400 avg_return=-10.929
2024-11-12 20:42:14,550 - INFO - train_step=4440 loss=5.937 time=14.955
2024-11-12 20:42:17,041 - INFO - train_step=4480 loss=5.908 time=2.489
2024-11-12 20:42:19,519 - INFO - train_step=4520 loss=5.976 time=2.479
2024-11-12 20:42:22,342 - INFO - train_step=4560 loss=5.696 time=2.823
2024-11-12 20:42:25,306 - INFO - train_step=4600 loss=5.586 time=2.965
2024-11-12 20:42:39,311 - INFO - train_step=4600 avg_return=-13.178
2024-11-12 20:42:42,371 - INFO - train_step=4640 loss=5.779 time=17.065
2024-11-12 20:42:45,324 - INFO - train_step=4680 loss=5.816 time=2.954
2024-11-12 20:42:49,082 - INFO - train_step=4720 loss=5.933 time=3.758
2024-11-12 20:42:52,857 - INFO - train_step=4760 loss=5.886 time=3.775
2024-11-12 20:42:55,903 - INFO - train_step=4800 loss=6.051 time=3.046
2024-11-12 20:43:08,633 - INFO - train_step=4800 avg_return=-20.462
2024-11-12 20:43:10,738 - INFO - train_step=4840 loss=6.272 time=14.835
2024-11-12 20:43:13,270 - INFO - train_step=4880 loss=5.828 time=2.532
2024-11-12 20:43:15,759 - INFO - train_step=4920 loss=5.873 time=2.489
2024-11-12 20:43:18,752 - INFO - train_step=4960 loss=6.100 time=2.993
2024-11-12 20:43:21,589 - INFO - train_step=5000 loss=5.761 time=2.838
2024-11-12 20:43:33,740 - INFO - train_step=5000 avg_return=-12.094
2024-11-12 20:43:35,573 - INFO - train_step=5040 loss=5.738 time=13.983
2024-11-12 20:43:37,961 - INFO - train_step=5080 loss=5.839 time=2.388
2024-11-12 20:43:40,366 - INFO - train_step=5120 loss=5.987 time=2.405
2024-11-12 20:43:42,829 - INFO - train_step=5160 loss=5.933 time=2.463
2024-11-12 20:43:45,711 - INFO - train_step=5200 loss=6.130 time=2.882
2024-11-12 20:43:59,405 - INFO - train_step=5200 avg_return=-10.674
2024-11-12 20:44:01,639 - INFO - train_step=5240 loss=6.411 time=15.928
2024-11-12 20:44:04,970 - INFO - train_step=5280 loss=6.549 time=3.331
2024-11-12 20:44:07,483 - INFO - train_step=5320 loss=6.298 time=2.513
2024-11-12 20:44:10,020 - INFO - train_step=5360 loss=6.094 time=2.538
2024-11-12 20:44:12,718 - INFO - train_step=5400 loss=6.126 time=2.698
2024-11-12 20:44:24,870 - INFO - train_step=5400 avg_return=-23.516
2024-11-12 20:44:26,681 - INFO - train_step=5440 loss=6.238 time=13.962
2024-11-12 20:44:29,219 - INFO - train_step=5480 loss=5.623 time=2.538
2024-11-12 20:44:31,867 - INFO - train_step=5520 loss=5.706 time=2.648
2024-11-12 20:44:34,478 - INFO - train_step=5560 loss=5.943 time=2.611
2024-11-12 20:44:37,395 - INFO - train_step=5600 loss=6.043 time=2.918
2024-11-12 20:44:50,462 - INFO - train_step=5600 avg_return=-22.874
2024-11-12 20:44:52,309 - INFO - train_step=5640 loss=5.995 time=14.914
2024-11-12 20:44:54,573 - INFO - train_step=5680 loss=5.912 time=2.263
2024-11-12 20:44:56,956 - INFO - train_step=5720 loss=5.900 time=2.383
2024-11-12 20:44:59,379 - INFO - train_step=5760 loss=5.701 time=2.424
2024-11-12 20:45:01,960 - INFO - train_step=5800 loss=5.817 time=2.581
2024-11-12 20:45:14,159 - INFO - train_step=5800 avg_return=-17.598
2024-11-12 20:45:15,959 - INFO - train_step=5840 loss=5.740 time=13.999
2024-11-12 20:45:18,238 - INFO - train_step=5880 loss=5.629 time=2.279
2024-11-12 20:45:21,124 - INFO - train_step=5920 loss=5.575 time=2.887
2024-11-12 20:45:24,644 - INFO - train_step=5960 loss=5.570 time=3.520
2024-11-12 20:45:27,579 - INFO - train_step=6000 loss=5.814 time=2.935
2024-11-12 20:45:44,940 - INFO - train_step=6000 avg_return=-12.703
2024-11-12 20:45:46,902 - INFO - train_step=6040 loss=5.841 time=19.323
2024-11-12 20:45:49,180 - INFO - train_step=6080 loss=5.885 time=2.277
2024-11-12 20:45:51,670 - INFO - train_step=6120 loss=5.538 time=2.491
2024-11-12 20:45:54,141 - INFO - train_step=6160 loss=5.398 time=2.471
2024-11-12 20:45:56,665 - INFO - train_step=6200 loss=5.698 time=2.524
2024-11-12 20:46:09,256 - INFO - train_step=6200 avg_return=-10.800
2024-11-12 20:46:11,720 - INFO - train_step=6240 loss=5.480 time=15.055
2024-11-12 20:46:14,639 - INFO - train_step=6280 loss=5.829 time=2.919
2024-11-12 20:46:17,426 - INFO - train_step=6320 loss=5.895 time=2.787
2024-11-12 20:46:19,894 - INFO - train_step=6360 loss=5.716 time=2.468
2024-11-12 20:46:22,440 - INFO - train_step=6400 loss=5.747 time=2.546
2024-11-12 20:46:36,040 - INFO - train_step=6400 avg_return=-13.240
2024-11-12 20:46:37,985 - INFO - train_step=6440 loss=5.917 time=15.546
2024-11-12 20:46:40,343 - INFO - train_step=6480 loss=5.859 time=2.358
2024-11-12 20:46:42,776 - INFO - train_step=6520 loss=5.842 time=2.432
2024-11-12 20:46:45,217 - INFO - train_step=6560 loss=5.661 time=2.441
2024-11-12 20:46:47,721 - INFO - train_step=6600 loss=5.630 time=2.504
2024-11-12 20:47:02,413 - INFO - train_step=6600 avg_return=-23.155
2024-11-12 20:47:04,438 - INFO - train_step=6640 loss=5.581 time=16.717
2024-11-12 20:47:06,867 - INFO - train_step=6680 loss=5.890 time=2.429
2024-11-12 20:47:09,489 - INFO - train_step=6720 loss=5.940 time=2.623
2024-11-12 20:47:12,006 - INFO - train_step=6760 loss=5.937 time=2.516
2024-11-12 20:47:14,447 - INFO - train_step=6800 loss=5.788 time=2.441
2024-11-12 20:47:27,714 - INFO - train_step=6800 avg_return=-54.714
2024-11-12 20:47:29,579 - INFO - train_step=6840 loss=5.751 time=15.132
2024-11-12 20:47:31,899 - INFO - train_step=6880 loss=5.653 time=2.319
2024-11-12 20:47:34,297 - INFO - train_step=6920 loss=5.643 time=2.398
2024-11-12 20:47:36,801 - INFO - train_step=6960 loss=5.676 time=2.505
2024-11-12 20:47:39,233 - INFO - train_step=7000 loss=5.687 time=2.431
2024-11-12 20:47:52,210 - INFO - train_step=7000 avg_return=-23.907
2024-11-12 20:47:54,780 - INFO - train_step=7040 loss=5.661 time=15.547
2024-11-12 20:47:57,416 - INFO - train_step=7080 loss=5.602 time=2.636
2024-11-12 20:47:59,915 - INFO - train_step=7120 loss=5.621 time=2.498
2024-11-12 20:48:02,576 - INFO - train_step=7160 loss=5.711 time=2.661
2024-11-12 20:48:05,218 - INFO - train_step=7200 loss=5.464 time=2.642
2024-11-12 20:48:18,505 - INFO - train_step=7200 avg_return=-18.778
2024-11-12 20:48:20,441 - INFO - train_step=7240 loss=5.516 time=15.223
2024-11-12 20:48:22,749 - INFO - train_step=7280 loss=5.398 time=2.308
2024-11-12 20:48:25,277 - INFO - train_step=7320 loss=5.641 time=2.529
2024-11-12 20:48:28,339 - INFO - train_step=7360 loss=5.943 time=3.062
2024-11-12 20:48:31,124 - INFO - train_step=7400 loss=5.780 time=2.785
2024-11-12 20:48:45,467 - INFO - train_step=7400 avg_return=-9.854
2024-11-12 20:48:47,478 - INFO - train_step=7440 loss=5.699 time=16.355
2024-11-12 20:48:49,791 - INFO - train_step=7480 loss=5.419 time=2.312
2024-11-12 20:48:52,378 - INFO - train_step=7520 loss=5.871 time=2.588
2024-11-12 20:48:55,138 - INFO - train_step=7560 loss=5.774 time=2.760
2024-11-12 20:48:57,751 - INFO - train_step=7600 loss=5.922 time=2.613
2024-11-12 20:49:12,201 - INFO - train_step=7600 avg_return=-28.313
2024-11-12 20:49:14,019 - INFO - train_step=7640 loss=6.265 time=16.268
2024-11-12 20:49:16,165 - INFO - train_step=7680 loss=6.401 time=2.146
2024-11-12 20:49:18,582 - INFO - train_step=7720 loss=6.539 time=2.417
2024-11-12 20:49:21,139 - INFO - train_step=7760 loss=6.547 time=2.556
2024-11-12 20:49:23,789 - INFO - train_step=7800 loss=6.394 time=2.650
2024-11-12 20:49:37,314 - INFO - train_step=7800 avg_return=-14.702
2024-11-12 20:49:39,188 - INFO - train_step=7840 loss=5.934 time=15.399
2024-11-12 20:49:41,400 - INFO - train_step=7880 loss=5.904 time=2.213
2024-11-12 20:49:44,065 - INFO - train_step=7920 loss=5.768 time=2.665
2024-11-12 20:49:46,679 - INFO - train_step=7960 loss=5.640 time=2.614
2024-11-12 20:49:49,385 - INFO - train_step=8000 loss=5.525 time=2.705
2024-11-12 20:50:04,153 - INFO - train_step=8000 avg_return=-18.189
2024-11-12 20:50:06,180 - INFO - train_step=8040 loss=5.610 time=16.795
2024-11-12 20:50:08,369 - INFO - train_step=8080 loss=5.727 time=2.189
2024-11-12 20:50:10,939 - INFO - train_step=8120 loss=5.864 time=2.570
2024-11-12 20:50:13,523 - INFO - train_step=8160 loss=6.084 time=2.583
2024-11-12 20:50:15,973 - INFO - train_step=8200 loss=6.051 time=2.451
2024-11-12 20:50:29,692 - INFO - train_step=8200 avg_return=-18.562
2024-11-12 20:50:31,569 - INFO - train_step=8240 loss=6.026 time=15.596
2024-11-12 20:50:33,854 - INFO - train_step=8280 loss=6.131 time=2.285
2024-11-12 20:50:36,388 - INFO - train_step=8320 loss=6.055 time=2.534
2024-11-12 20:50:38,824 - INFO - train_step=8360 loss=5.914 time=2.437
2024-11-12 20:50:41,411 - INFO - train_step=8400 loss=5.803 time=2.587
2024-11-12 20:50:55,258 - INFO - train_step=8400 avg_return=-12.029
2024-11-12 20:50:57,047 - INFO - train_step=8440 loss=5.813 time=15.636
2024-11-12 20:50:59,155 - INFO - train_step=8480 loss=5.734 time=2.108
2024-11-12 20:51:01,569 - INFO - train_step=8520 loss=5.922 time=2.414
2024-11-12 20:51:04,026 - INFO - train_step=8560 loss=5.729 time=2.457
2024-11-12 20:51:06,542 - INFO - train_step=8600 loss=6.094 time=2.516
2024-11-12 20:51:21,635 - INFO - train_step=8600 avg_return=-13.848
2024-11-12 20:51:23,692 - INFO - train_step=8640 loss=6.251 time=17.150
2024-11-12 20:51:26,006 - INFO - train_step=8680 loss=6.195 time=2.313
2024-11-12 20:51:29,135 - INFO - train_step=8720 loss=6.161 time=3.130
2024-11-12 20:51:31,679 - INFO - train_step=8760 loss=6.252 time=2.544
2024-11-12 20:51:34,119 - INFO - train_step=8800 loss=6.111 time=2.440
2024-11-12 20:51:47,688 - INFO - train_step=8800 avg_return=-10.202
2024-11-12 20:51:49,447 - INFO - train_step=8840 loss=5.939 time=15.328
2024-11-12 20:51:51,589 - INFO - train_step=8880 loss=6.013 time=2.142
2024-11-12 20:51:54,017 - INFO - train_step=8920 loss=6.258 time=2.427
2024-11-12 20:51:56,434 - INFO - train_step=8960 loss=6.042 time=2.418
2024-11-12 20:51:59,152 - INFO - train_step=9000 loss=6.081 time=2.718
2024-11-12 20:52:13,452 - INFO - train_step=9000 avg_return=-15.032
2024-11-12 20:52:16,234 - INFO - train_step=9040 loss=6.034 time=17.082
2024-11-12 20:52:19,942 - INFO - train_step=9080 loss=6.097 time=3.708
2024-11-12 20:52:22,937 - INFO - train_step=9120 loss=6.015 time=2.995
2024-11-12 20:52:26,097 - INFO - train_step=9160 loss=5.924 time=3.160
2024-11-12 20:52:29,264 - INFO - train_step=9200 loss=5.996 time=3.167
2024-11-12 20:52:43,395 - INFO - train_step=9200 avg_return=-57.325
2024-11-12 20:52:45,153 - INFO - train_step=9240 loss=6.211 time=15.889
2024-11-12 20:52:47,371 - INFO - train_step=9280 loss=6.208 time=2.218
2024-11-12 20:52:49,939 - INFO - train_step=9320 loss=6.174 time=2.568
2024-11-12 20:52:52,422 - INFO - train_step=9360 loss=6.170 time=2.483
2024-11-12 20:52:55,068 - INFO - train_step=9400 loss=6.403 time=2.646
2024-11-12 20:53:08,815 - INFO - train_step=9400 avg_return=-14.912
2024-11-12 20:53:10,623 - INFO - train_step=9440 loss=6.082 time=15.555
2024-11-12 20:53:12,750 - INFO - train_step=9480 loss=6.048 time=2.126
2024-11-12 20:53:15,210 - INFO - train_step=9520 loss=5.968 time=2.460
2024-11-12 20:53:17,920 - INFO - train_step=9560 loss=6.018 time=2.710
2024-11-12 20:53:20,736 - INFO - train_step=9600 loss=5.973 time=2.815
2024-11-12 20:53:35,272 - INFO - train_step=9600 avg_return=-21.715
2024-11-12 20:53:37,152 - INFO - train_step=9640 loss=5.829 time=16.417
2024-11-12 20:53:39,274 - INFO - train_step=9680 loss=5.781 time=2.122
2024-11-12 20:53:41,731 - INFO - train_step=9720 loss=5.974 time=2.457
2024-11-12 20:53:44,238 - INFO - train_step=9760 loss=5.994 time=2.507
2024-11-12 20:53:46,684 - INFO - train_step=9800 loss=5.526 time=2.446
2024-11-12 20:54:00,480 - INFO - train_step=9800 avg_return=-13.363
2024-11-12 20:54:02,243 - INFO - train_step=9840 loss=5.671 time=15.559
2024-11-12 20:54:04,735 - INFO - train_step=9880 loss=5.870 time=2.492
2024-11-12 20:54:07,166 - INFO - train_step=9920 loss=5.881 time=2.430
2024-11-12 20:54:09,628 - INFO - train_step=9960 loss=6.003 time=2.462
2024-11-12 20:54:12,203 - INFO - train_step=10000 loss=6.140 time=2.576
2024-11-12 20:54:25,534 - INFO - train_step=10000 avg_return=-16.012
2024-11-12 20:54:25,534 - INFO - total_time=1320.678
2024-11-12 20:54:25,534 - INFO - saving, checkpointPath_toSave=./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model
2024-11-12 20:54:25,545 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/0
2024-11-12 20:54:25,616 - INFO - Sharding callback duration: 117
2024-11-12 20:54:25,638 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/0/ckpt-10000
2024-11-12 20:54:25,639 - INFO - No checkpoint available at ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/1
2024-11-12 20:54:25,665 - INFO - Sharding callback duration: 23
2024-11-12 20:54:25,682 - INFO - Saved checkpoint: ./result/Reacher-v2_discrete_CDQN_multiagent_1112_203217/model/1/ckpt-10000
