2024-11-17 23:49:47.837278: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-11-17 23:49:47.837323: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-11-17 23:49:47.838001: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-11-17 23:49:47.842473: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-11-17 23:49:48.446058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
online arguments=['play.py', '-e', 'DaisoSokcho', '-a', 'TD3', '-i', '100']
2024-11-17 23:49:49.766635: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2024-11-17 23:49:49.766679: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: sohubuntuserver
2024-11-17 23:49:49.766684: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: sohubuntuserver
2024-11-17 23:49:49.766861: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 555.42.2
2024-11-17 23:49:49.766885: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 555.42.2
2024-11-17 23:49:49.766889: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 555.42.2
2024-11-17 23:49:49,782 - INFO - config={'dtype': 'float32', 'intdtype': 'int32', 'resultPath': './result', 'isGPUUsed': False, 'log_level_name': 'INFO', '# log_level_name': 'like INFO or DEBUG', 'environment': 'CartPole-v0', 'environment_wrapper': None, 'agent': 'DQN', 'replay_buffer': 'tf_uniform', 'driver': 'dynamic_step', 'num_actions_discretized': 3, '# num_actions_discretized: for ActionDiscretizeWrapper': None, 'num_train_steps': 10000, '# num_train_steps_to_log': 200, '# num_train_steps_to_eval': 1000, '# num_train_steps_to_save_model': 10000, 'num_episodes_to_eval': 10, '# for CDQN': None, 'num_atoms': 51, 'min_q_value': -20, 'max_q_value': 20, 'n_step_update': 2, 'qnet_fc_layer_params': [128, 64], 'actor_fc_layer_params': [256, 256], '# actor_fc_layer_params': '[32, 32] for Pendulum', 'critic_observation_fc_layer_params': None, '#critic_observation_fc_layer_params': [64, 64], '# critic_observation_fc_layer_params': '[32, 32] for Pendulum', 'critic_action_fc_layer_params': None, '#critic_action_fc_layer_params': [64, 64], '# critic_action_fc_layer_params': '[32, 32] for Pendulum', 'critic_joint_fc_layer_params': [256, 256], '# critic_joint_fc_layer_params': '[128, 16] for Pendulum', 'value_fc_layer_params': [256, 256], 'batch_size': 64, 'learning_rate': 0.001, 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0006, 'alpha_learning_rate': 0.0003, 'target_update_tau': 0.005, 'target_update_period': 1, 'gamma': 0.99, 'reward_scale_factor': 1.0, 'epsilon_greedy': 0.1, 'replay_buffer_max_length': 10000, '# num_frames = capacity = max_length * env.batch_size and default env.batch_size = 1': None, 'num_init_collect_steps': 10000, 'num_collect_steps_per_train_step': 1, 'num_init_collect_episodes': 10, 'num_collect_episodes_per_train_step': 30, '# for PPO': None, 'num_parallel_envs': 30, 'num_env_steps': 20000, 'num_epochs': 25, 'reverb_port': 8008, '#  ending': None}
2024-11-17 23:49:49,782 - INFO - args=Namespace(environment='DaisoSokcho', environment_wrapper=None, agent='TD3', replay_buffer=None, driver=None, checkpoint_path=None, reverb_checkpoint_path=None, num_actions=None, num_init_collect_steps=100, epsilon_greedy=None)
2024-11-17 23:49:49,782 - INFO - environment=DaisoSokcho
2024-11-17 23:49:49,782 - INFO - envWrapper=None
2024-11-17 23:49:49,782 - INFO - agent=TD3
Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

Unit Timestep : 10 min
               timestamp        date  days  ...  E_ehp_5   T_oa_max   T_oa_min
0    2023-03-23 08:00:00  2023-03-23    81  ...      0.0  13.145000   6.873333
1    2023-03-23 08:10:00  2023-03-23    81  ...      0.0  13.145000   6.873333
2    2023-03-23 08:20:00  2023-03-23    81  ...      0.0  13.145000   6.873333
3    2023-03-23 08:30:00  2023-03-23    81  ...      0.0  13.145000   6.873333
4    2023-03-23 08:40:00  2023-03-23    81  ...      0.0  13.145000   6.873333
...                  ...         ...   ...  ...      ...        ...        ...
2683 2023-06-21 21:10:00  2023-06-21   171  ...  15339.0  18.151667  18.018333
2684 2023-06-21 21:20:00  2023-06-21   171  ...  27858.0  18.118333  18.018333
2685 2023-06-21 21:30:00  2023-06-21   171  ...  29052.0  18.085000  18.018333
2686 2023-06-21 21:40:00  2023-06-21   171  ...   4897.0  18.051667  18.018333
2687 2023-06-21 21:50:00  2023-06-21   171  ...     24.0  18.018333  18.018333

[2688 rows x 25 columns]
[Data INFO] #episodes(dates): 32 (#train: 28, #test: 4)

2024-11-17 23:49:50,426 - INFO - tf_observation_spec: BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))
2024-11-17 23:49:50,426 - INFO - tf_action_spec: BoundedTensorSpec(shape=(5,), dtype=tf.float32, name='action', minimum=array([0., 0., 0., 0., 0.], dtype=float32), maximum=array([5., 7., 5., 5., 5.], dtype=float32))
2024-11-17 23:49:50,426 - INFO - tf_time_step_spec: TimeStep(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32))})
2024-11-17 23:49:50,761 - INFO - tf_agent_collect_data_spec: Trajectory(
{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'observation': BoundedTensorSpec(shape=(13,), dtype=tf.float32, name='observation', minimum=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), maximum=array([ 365., 1440.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   40.,   10.,   60.,  400.], dtype=float32)),
 'action': BoundedTensorSpec(shape=(5,), dtype=tf.float32, name='action', minimum=array([0., 0., 0., 0., 0.], dtype=float32), maximum=array([5., 7., 5., 5., 5.], dtype=float32)),
 'policy_info': (),
 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),
 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),
 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})
WARNING:tensorflow:From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-17 23:49:50,869 - WARNING - From /home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.
Instructions for updating:
Use `as_dataset(..., single_deterministic_pass=False) instead.
2024-11-17 23:50:13,812 - INFO - random_policy avg_return=-350.28265380859375
2024-11-17 23:50:13,812 - INFO - replay_buffer.capacity=10000
2024-11-17 23:50:13,815 - INFO - before filling or restoring with checkpointer, replay_buffer.num_frames()=0
2024-11-17 23:50:16,747 - INFO - after filling with random_policy, replay_buffer.num_frames()=101
2024-11-17 23:50:42,208 - INFO - before training, avg_return=-305.1029052734375
2024-11-17 23:50:57,274 - INFO - train_step=40 loss=323.082 time=15.065
2024-11-17 23:51:02,434 - INFO - train_step=80 loss=365.904 time=5.161
2024-11-17 23:51:08,162 - INFO - train_step=120 loss=87.321 time=5.727
2024-11-17 23:51:13,391 - INFO - train_step=160 loss=370.514 time=5.230
2024-11-17 23:51:17,635 - INFO - train_step=200 loss=85.489 time=4.243
2024-11-17 23:51:44,767 - INFO - train_step=200 avg_return=-635.912
2024-11-17 23:51:49,983 - INFO - train_step=240 loss=367.956 time=32.348
2024-11-17 23:51:55,460 - INFO - train_step=280 loss=161.955 time=5.477
2024-11-17 23:52:00,633 - INFO - train_step=320 loss=94.028 time=5.173
2024-11-17 23:52:05,840 - INFO - train_step=360 loss=332.326 time=5.207
2024-11-17 23:52:09,664 - INFO - train_step=400 loss=623.910 time=3.824
2024-11-17 23:52:36,677 - INFO - train_step=400 avg_return=-519.421
2024-11-17 23:52:41,723 - INFO - train_step=440 loss=173.868 time=32.059
2024-11-17 23:52:47,113 - INFO - train_step=480 loss=106.013 time=5.390
2024-11-17 23:52:52,217 - INFO - train_step=520 loss=378.952 time=5.104
2024-11-17 23:52:57,235 - INFO - train_step=560 loss=215.977 time=5.018
2024-11-17 23:53:01,194 - INFO - train_step=600 loss=472.898 time=3.959
2024-11-17 23:53:28,647 - INFO - train_step=600 avg_return=-185.450
2024-11-17 23:53:33,826 - INFO - train_step=640 loss=248.446 time=32.632
2024-11-17 23:53:39,451 - INFO - train_step=680 loss=228.394 time=5.625
2024-11-17 23:53:44,680 - INFO - train_step=720 loss=286.137 time=5.230
2024-11-17 23:53:49,479 - INFO - train_step=760 loss=125.238 time=4.799
2024-11-17 23:53:53,229 - INFO - train_step=800 loss=151.033 time=3.749
2024-11-17 23:54:18,926 - INFO - train_step=800 avg_return=-177.728
2024-11-17 23:54:24,188 - INFO - train_step=840 loss=188.623 time=30.960
2024-11-17 23:54:29,347 - INFO - train_step=880 loss=181.244 time=5.159
2024-11-17 23:54:34,457 - INFO - train_step=920 loss=134.835 time=5.110
2024-11-17 23:54:39,748 - INFO - train_step=960 loss=153.358 time=5.290
2024-11-17 23:54:43,764 - INFO - train_step=1000 loss=237.705 time=4.017
2024-11-17 23:55:09,029 - INFO - train_step=1000 avg_return=-171.290
2024-11-17 23:55:14,502 - INFO - train_step=1040 loss=183.200 time=30.737
2024-11-17 23:55:19,687 - INFO - train_step=1080 loss=269.505 time=5.185
2024-11-17 23:55:24,817 - INFO - train_step=1120 loss=273.366 time=5.130
2024-11-17 23:55:30,267 - INFO - train_step=1160 loss=205.128 time=5.450
2024-11-17 23:55:34,561 - INFO - train_step=1200 loss=181.648 time=4.294
2024-11-17 23:56:01,691 - INFO - train_step=1200 avg_return=-182.667
2024-11-17 23:56:07,033 - INFO - train_step=1240 loss=248.926 time=32.472
2024-11-17 23:56:12,242 - INFO - train_step=1280 loss=382.723 time=5.209
2024-11-17 23:56:17,613 - INFO - train_step=1320 loss=370.426 time=5.371
2024-11-17 23:56:22,358 - INFO - train_step=1360 loss=242.549 time=4.745
2024-11-17 23:56:26,702 - INFO - train_step=1400 loss=197.818 time=4.344
2024-11-17 23:56:53,969 - INFO - train_step=1400 avg_return=-179.722
2024-11-17 23:56:59,015 - INFO - train_step=1440 loss=230.827 time=32.313
2024-11-17 23:57:04,093 - INFO - train_step=1480 loss=259.795 time=5.078
2024-11-17 23:57:09,426 - INFO - train_step=1520 loss=273.428 time=5.333
2024-11-17 23:57:13,900 - INFO - train_step=1560 loss=543.120 time=4.474
2024-11-17 23:57:18,134 - INFO - train_step=1600 loss=379.190 time=4.234
2024-11-17 23:57:44,244 - INFO - train_step=1600 avg_return=-175.555
2024-11-17 23:57:48,970 - INFO - train_step=1640 loss=230.922 time=30.836
2024-11-17 23:57:54,142 - INFO - train_step=1680 loss=346.804 time=5.172
2024-11-17 23:57:59,678 - INFO - train_step=1720 loss=266.100 time=5.536
2024-11-17 23:58:04,518 - INFO - train_step=1760 loss=210.287 time=4.840
2024-11-17 23:58:09,042 - INFO - train_step=1800 loss=265.210 time=4.524
2024-11-17 23:58:37,286 - INFO - train_step=1800 avg_return=-171.701
2024-11-17 23:58:41,742 - INFO - train_step=1840 loss=262.370 time=32.699
2024-11-17 23:58:47,252 - INFO - train_step=1880 loss=298.259 time=5.510
2024-11-17 23:58:52,384 - INFO - train_step=1920 loss=278.940 time=5.133
2024-11-17 23:58:56,974 - INFO - train_step=1960 loss=428.489 time=4.589
2024-11-17 23:59:01,159 - INFO - train_step=2000 loss=386.725 time=4.185
2024-11-17 23:59:27,347 - INFO - train_step=2000 avg_return=-196.822
2024-11-17 23:59:31,755 - INFO - train_step=2040 loss=290.649 time=30.596
2024-11-17 23:59:37,319 - INFO - train_step=2080 loss=268.955 time=5.565
2024-11-17 23:59:42,220 - INFO - train_step=2120 loss=364.413 time=4.901
2024-11-17 23:59:47,069 - INFO - train_step=2160 loss=403.963 time=4.848
2024-11-17 23:59:51,626 - INFO - train_step=2200 loss=220.105 time=4.558
2024-11-18 00:00:19,159 - INFO - train_step=2200 avg_return=-177.862
2024-11-18 00:00:23,779 - INFO - train_step=2240 loss=245.133 time=32.152
2024-11-18 00:00:28,998 - INFO - train_step=2280 loss=447.626 time=5.219
2024-11-18 00:00:33,983 - INFO - train_step=2320 loss=345.427 time=4.985
2024-11-18 00:00:38,775 - INFO - train_step=2360 loss=531.484 time=4.793
2024-11-18 00:00:43,078 - INFO - train_step=2400 loss=441.123 time=4.303
2024-11-18 00:01:10,542 - INFO - train_step=2400 avg_return=-185.693
2024-11-18 00:01:15,490 - INFO - train_step=2440 loss=182.162 time=32.412
2024-11-18 00:01:20,500 - INFO - train_step=2480 loss=622.908 time=5.010
2024-11-18 00:01:25,642 - INFO - train_step=2520 loss=373.122 time=5.142
2024-11-18 00:01:30,510 - INFO - train_step=2560 loss=359.788 time=4.868
2024-11-18 00:01:34,778 - INFO - train_step=2600 loss=438.844 time=4.268
2024-11-18 00:02:01,937 - INFO - train_step=2600 avg_return=-171.959
2024-11-18 00:02:06,885 - INFO - train_step=2640 loss=382.831 time=32.107
2024-11-18 00:02:11,922 - INFO - train_step=2680 loss=490.176 time=5.037
2024-11-18 00:02:16,985 - INFO - train_step=2720 loss=298.084 time=5.063
2024-11-18 00:02:22,070 - INFO - train_step=2760 loss=618.786 time=5.085
2024-11-18 00:02:26,368 - INFO - train_step=2800 loss=417.148 time=4.299
2024-11-18 00:02:53,837 - INFO - train_step=2800 avg_return=-180.097
2024-11-18 00:02:58,762 - INFO - train_step=2840 loss=409.252 time=32.393
2024-11-18 00:03:03,895 - INFO - train_step=2880 loss=446.644 time=5.134
2024-11-18 00:03:09,184 - INFO - train_step=2920 loss=489.133 time=5.288
2024-11-18 00:03:13,801 - INFO - train_step=2960 loss=349.330 time=4.618
2024-11-18 00:03:17,837 - INFO - train_step=3000 loss=283.875 time=4.036
2024-11-18 00:03:45,796 - INFO - train_step=3000 avg_return=-169.270
2024-11-18 00:03:51,011 - INFO - train_step=3040 loss=312.980 time=33.174
2024-11-18 00:03:56,092 - INFO - train_step=3080 loss=321.536 time=5.081
2024-11-18 00:04:01,368 - INFO - train_step=3120 loss=300.223 time=5.277
2024-11-18 00:04:06,069 - INFO - train_step=3160 loss=549.221 time=4.701
2024-11-18 00:04:10,072 - INFO - train_step=3200 loss=329.365 time=4.003
2024-11-18 00:04:37,467 - INFO - train_step=3200 avg_return=-194.628
2024-11-18 00:04:42,519 - INFO - train_step=3240 loss=671.030 time=32.447
2024-11-18 00:04:47,997 - INFO - train_step=3280 loss=332.914 time=5.478
2024-11-18 00:04:52,842 - INFO - train_step=3320 loss=496.350 time=4.845
2024-11-18 00:04:57,435 - INFO - train_step=3360 loss=380.280 time=4.594
2024-11-18 00:05:01,516 - INFO - train_step=3400 loss=276.104 time=4.080
2024-11-18 00:05:29,462 - INFO - train_step=3400 avg_return=-180.641
2024-11-18 00:05:34,394 - INFO - train_step=3440 loss=313.617 time=32.878
2024-11-18 00:05:39,916 - INFO - train_step=3480 loss=233.675 time=5.522
2024-11-18 00:05:44,908 - INFO - train_step=3520 loss=272.929 time=4.992
2024-11-18 00:05:49,392 - INFO - train_step=3560 loss=300.098 time=4.484
2024-11-18 00:05:53,240 - INFO - train_step=3600 loss=404.336 time=3.848
2024-11-18 00:06:21,169 - INFO - train_step=3600 avg_return=-172.569
2024-11-18 00:06:26,055 - INFO - train_step=3640 loss=379.231 time=32.815
2024-11-18 00:06:31,305 - INFO - train_step=3680 loss=285.774 time=5.250
2024-11-18 00:06:36,264 - INFO - train_step=3720 loss=300.593 time=4.958
2024-11-18 00:06:40,834 - INFO - train_step=3760 loss=287.380 time=4.571
2024-11-18 00:06:44,391 - INFO - train_step=3800 loss=281.412 time=3.556
2024-11-18 00:07:10,683 - INFO - train_step=3800 avg_return=-199.544
2024-11-18 00:07:16,043 - INFO - train_step=3840 loss=283.982 time=31.653
2024-11-18 00:07:21,049 - INFO - train_step=3880 loss=185.246 time=5.005
2024-11-18 00:07:26,121 - INFO - train_step=3920 loss=357.292 time=5.072
2024-11-18 00:07:31,014 - INFO - train_step=3960 loss=312.379 time=4.893
2024-11-18 00:07:35,167 - INFO - train_step=4000 loss=224.356 time=4.153
2024-11-18 00:08:02,452 - INFO - train_step=4000 avg_return=-170.045
2024-11-18 00:08:07,800 - INFO - train_step=4040 loss=310.156 time=32.633
2024-11-18 00:08:12,828 - INFO - train_step=4080 loss=289.783 time=5.028
2024-11-18 00:08:18,072 - INFO - train_step=4120 loss=257.670 time=5.244
2024-11-18 00:08:22,639 - INFO - train_step=4160 loss=259.144 time=4.568
2024-11-18 00:08:26,635 - INFO - train_step=4200 loss=281.813 time=3.995
2024-11-18 00:08:54,208 - INFO - train_step=4200 avg_return=-165.923
2024-11-18 00:08:59,669 - INFO - train_step=4240 loss=404.372 time=33.035
2024-11-18 00:09:04,777 - INFO - train_step=4280 loss=196.387 time=5.108
2024-11-18 00:09:09,974 - INFO - train_step=4320 loss=231.527 time=5.197
2024-11-18 00:09:14,381 - INFO - train_step=4360 loss=614.165 time=4.407
2024-11-18 00:09:18,160 - INFO - train_step=4400 loss=256.831 time=3.779
2024-11-18 00:09:45,198 - INFO - train_step=4400 avg_return=-191.440
2024-11-18 00:09:49,952 - INFO - train_step=4440 loss=239.036 time=31.792
2024-11-18 00:09:55,096 - INFO - train_step=4480 loss=247.163 time=5.144
2024-11-18 00:10:00,505 - INFO - train_step=4520 loss=308.380 time=5.409
2024-11-18 00:10:04,882 - INFO - train_step=4560 loss=366.522 time=4.377
2024-11-18 00:10:08,827 - INFO - train_step=4600 loss=253.550 time=3.945
2024-11-18 00:10:38,180 - INFO - train_step=4600 avg_return=-187.439
2024-11-18 00:10:42,788 - INFO - train_step=4640 loss=238.118 time=33.961
2024-11-18 00:10:47,796 - INFO - train_step=4680 loss=198.874 time=5.008
2024-11-18 00:10:53,061 - INFO - train_step=4720 loss=204.465 time=5.265
2024-11-18 00:10:57,222 - INFO - train_step=4760 loss=262.508 time=4.161
2024-11-18 00:11:01,096 - INFO - train_step=4800 loss=201.409 time=3.873
2024-11-18 00:11:29,984 - INFO - train_step=4800 avg_return=-179.958
2024-11-18 00:11:34,561 - INFO - train_step=4840 loss=165.155 time=33.466
2024-11-18 00:11:39,872 - INFO - train_step=4880 loss=338.355 time=5.311
2024-11-18 00:11:44,744 - INFO - train_step=4920 loss=316.674 time=4.872
2024-11-18 00:11:48,720 - INFO - train_step=4960 loss=253.829 time=3.975
2024-11-18 00:11:52,615 - INFO - train_step=5000 loss=194.042 time=3.895
2024-11-18 00:12:20,619 - INFO - train_step=5000 avg_return=-201.409
2024-11-18 00:12:25,249 - INFO - train_step=5040 loss=198.109 time=32.635
2024-11-18 00:12:30,619 - INFO - train_step=5080 loss=283.421 time=5.370
2024-11-18 00:12:35,544 - INFO - train_step=5120 loss=187.584 time=4.925
2024-11-18 00:12:39,750 - INFO - train_step=5160 loss=254.625 time=4.206
2024-11-18 00:12:43,566 - INFO - train_step=5200 loss=394.665 time=3.816
2024-11-18 00:13:11,094 - INFO - train_step=5200 avg_return=-190.026
2024-11-18 00:13:15,568 - INFO - train_step=5240 loss=230.402 time=32.002
2024-11-18 00:13:20,560 - INFO - train_step=5280 loss=220.814 time=4.992
2024-11-18 00:13:25,685 - INFO - train_step=5320 loss=301.957 time=5.125
2024-11-18 00:13:30,224 - INFO - train_step=5360 loss=189.660 time=4.539
2024-11-18 00:13:33,823 - INFO - train_step=5400 loss=289.153 time=3.599
2024-11-18 00:14:00,984 - INFO - train_step=5400 avg_return=-172.349
2024-11-18 00:14:05,809 - INFO - train_step=5440 loss=180.470 time=31.986
2024-11-18 00:14:10,416 - INFO - train_step=5480 loss=187.834 time=4.607
2024-11-18 00:14:15,298 - INFO - train_step=5520 loss=151.965 time=4.882
2024-11-18 00:14:19,991 - INFO - train_step=5560 loss=300.103 time=4.693
2024-11-18 00:14:24,029 - INFO - train_step=5600 loss=178.169 time=4.038
2024-11-18 00:14:50,872 - INFO - train_step=5600 avg_return=-200.115
2024-11-18 00:14:55,623 - INFO - train_step=5640 loss=237.773 time=31.594
2024-11-18 00:15:00,021 - INFO - train_step=5680 loss=230.341 time=4.398
2024-11-18 00:15:04,828 - INFO - train_step=5720 loss=140.544 time=4.807
2024-11-18 00:15:09,743 - INFO - train_step=5760 loss=198.833 time=4.915
2024-11-18 00:15:14,247 - INFO - train_step=5800 loss=123.439 time=4.503
2024-11-18 00:15:41,232 - INFO - train_step=5800 avg_return=-178.227
2024-11-18 00:15:45,703 - INFO - train_step=5840 loss=282.963 time=31.456
2024-11-18 00:15:50,289 - INFO - train_step=5880 loss=193.446 time=4.586
2024-11-18 00:15:55,245 - INFO - train_step=5920 loss=244.644 time=4.956
2024-11-18 00:15:59,853 - INFO - train_step=5960 loss=142.001 time=4.607
2024-11-18 00:16:04,372 - INFO - train_step=6000 loss=198.498 time=4.519
2024-11-18 00:16:31,944 - INFO - train_step=6000 avg_return=-237.474
2024-11-18 00:16:35,831 - INFO - train_step=6040 loss=182.901 time=31.459
2024-11-18 00:16:40,258 - INFO - train_step=6080 loss=131.518 time=4.427
2024-11-18 00:16:45,207 - INFO - train_step=6120 loss=203.501 time=4.950
2024-11-18 00:16:50,053 - INFO - train_step=6160 loss=186.032 time=4.845
2024-11-18 00:16:54,574 - INFO - train_step=6200 loss=171.155 time=4.522
2024-11-18 00:17:23,271 - INFO - train_step=6200 avg_return=-244.866
2024-11-18 00:17:27,352 - INFO - train_step=6240 loss=202.207 time=32.778
2024-11-18 00:17:31,859 - INFO - train_step=6280 loss=208.839 time=4.507
2024-11-18 00:17:36,729 - INFO - train_step=6320 loss=141.556 time=4.870
2024-11-18 00:17:41,541 - INFO - train_step=6360 loss=140.908 time=4.811
2024-11-18 00:17:46,403 - INFO - train_step=6400 loss=167.090 time=4.863
2024-11-18 00:18:13,588 - INFO - train_step=6400 avg_return=-257.300
2024-11-18 00:18:17,470 - INFO - train_step=6440 loss=175.200 time=31.066
2024-11-18 00:18:22,045 - INFO - train_step=6480 loss=220.753 time=4.576
2024-11-18 00:18:26,662 - INFO - train_step=6520 loss=154.458 time=4.617
2024-11-18 00:18:31,448 - INFO - train_step=6560 loss=157.715 time=4.786
2024-11-18 00:18:36,194 - INFO - train_step=6600 loss=155.187 time=4.746
2024-11-18 00:19:04,969 - INFO - train_step=6600 avg_return=-225.018
2024-11-18 00:19:08,983 - INFO - train_step=6640 loss=190.713 time=32.789
2024-11-18 00:19:13,703 - INFO - train_step=6680 loss=171.658 time=4.720
2024-11-18 00:19:18,267 - INFO - train_step=6720 loss=184.173 time=4.564
2024-11-18 00:19:23,041 - INFO - train_step=6760 loss=151.284 time=4.774
2024-11-18 00:19:27,913 - INFO - train_step=6800 loss=210.988 time=4.872
2024-11-18 00:19:55,582 - INFO - train_step=6800 avg_return=-241.481
2024-11-18 00:19:59,654 - INFO - train_step=6840 loss=216.723 time=31.741
2024-11-18 00:20:03,918 - INFO - train_step=6880 loss=154.004 time=4.264
2024-11-18 00:20:08,493 - INFO - train_step=6920 loss=169.022 time=4.575
2024-11-18 00:20:13,617 - INFO - train_step=6960 loss=174.932 time=5.124
2024-11-18 00:20:18,263 - INFO - train_step=7000 loss=169.946 time=4.646
2024-11-18 00:20:46,871 - INFO - train_step=7000 avg_return=-231.339
2024-11-18 00:20:51,014 - INFO - train_step=7040 loss=186.459 time=32.751
2024-11-18 00:20:55,317 - INFO - train_step=7080 loss=184.836 time=4.303
2024-11-18 00:20:59,847 - INFO - train_step=7120 loss=138.316 time=4.531
2024-11-18 00:21:04,829 - INFO - train_step=7160 loss=169.639 time=4.982
2024-11-18 00:21:09,558 - INFO - train_step=7200 loss=129.546 time=4.729
2024-11-18 00:21:38,397 - INFO - train_step=7200 avg_return=-231.929
2024-11-18 00:21:42,541 - INFO - train_step=7240 loss=143.147 time=32.983
2024-11-18 00:21:46,617 - INFO - train_step=7280 loss=162.779 time=4.076
2024-11-18 00:21:51,501 - INFO - train_step=7320 loss=160.688 time=4.884
2024-11-18 00:21:56,223 - INFO - train_step=7360 loss=144.673 time=4.722
2024-11-18 00:22:00,714 - INFO - train_step=7400 loss=153.240 time=4.491
2024-11-18 00:22:29,082 - INFO - train_step=7400 avg_return=-241.868
2024-11-18 00:22:32,750 - INFO - train_step=7440 loss=160.028 time=32.036
2024-11-18 00:22:36,786 - INFO - train_step=7480 loss=150.629 time=4.036
2024-11-18 00:22:41,660 - INFO - train_step=7520 loss=156.489 time=4.875
2024-11-18 00:22:46,186 - INFO - train_step=7560 loss=145.304 time=4.526
2024-11-18 00:22:50,782 - INFO - train_step=7600 loss=157.667 time=4.596
2024-11-18 00:23:19,836 - INFO - train_step=7600 avg_return=-255.689
2024-11-18 00:23:23,460 - INFO - train_step=7640 loss=203.696 time=32.678
2024-11-18 00:23:27,474 - INFO - train_step=7680 loss=189.177 time=4.013
2024-11-18 00:23:32,133 - INFO - train_step=7720 loss=144.701 time=4.659
2024-11-18 00:23:36,529 - INFO - train_step=7760 loss=164.807 time=4.396
2024-11-18 00:23:41,073 - INFO - train_step=7800 loss=183.628 time=4.545
2024-11-18 00:24:10,265 - INFO - train_step=7800 avg_return=-249.093
2024-11-18 00:24:13,731 - INFO - train_step=7840 loss=184.272 time=32.658
2024-11-18 00:24:17,911 - INFO - train_step=7880 loss=175.504 time=4.179
2024-11-18 00:24:22,012 - INFO - train_step=7920 loss=151.455 time=4.101
2024-11-18 00:24:26,531 - INFO - train_step=7960 loss=165.686 time=4.519
2024-11-18 00:24:31,245 - INFO - train_step=8000 loss=144.383 time=4.713
2024-11-18 00:25:00,659 - INFO - train_step=8000 avg_return=-239.201
2024-11-18 00:25:04,234 - INFO - train_step=8040 loss=161.139 time=32.990
2024-11-18 00:25:08,300 - INFO - train_step=8080 loss=158.869 time=4.066
2024-11-18 00:25:12,334 - INFO - train_step=8120 loss=137.544 time=4.034
2024-11-18 00:25:16,917 - INFO - train_step=8160 loss=150.780 time=4.583
2024-11-18 00:25:21,466 - INFO - train_step=8200 loss=140.589 time=4.549
2024-11-18 00:25:52,206 - INFO - train_step=8200 avg_return=-253.724
2024-11-18 00:25:55,694 - INFO - train_step=8240 loss=145.067 time=34.227
2024-11-18 00:25:59,976 - INFO - train_step=8280 loss=140.208 time=4.282
2024-11-18 00:26:03,897 - INFO - train_step=8320 loss=143.228 time=3.921
2024-11-18 00:26:08,667 - INFO - train_step=8360 loss=138.894 time=4.770
2024-11-18 00:26:12,768 - INFO - train_step=8400 loss=147.952 time=4.101
2024-11-18 00:26:43,119 - INFO - train_step=8400 avg_return=-246.895
2024-11-18 00:26:46,881 - INFO - train_step=8440 loss=149.206 time=34.113
2024-11-18 00:26:50,994 - INFO - train_step=8480 loss=142.502 time=4.113
2024-11-18 00:26:55,108 - INFO - train_step=8520 loss=148.978 time=4.113
2024-11-18 00:26:59,772 - INFO - train_step=8560 loss=200.901 time=4.665
2024-11-18 00:27:03,873 - INFO - train_step=8600 loss=162.022 time=4.101
2024-11-18 00:27:34,652 - INFO - train_step=8600 avg_return=-236.900
2024-11-18 00:27:38,814 - INFO - train_step=8640 loss=148.424 time=34.941
2024-11-18 00:27:42,926 - INFO - train_step=8680 loss=242.388 time=4.112
2024-11-18 00:27:46,887 - INFO - train_step=8720 loss=154.294 time=3.961
2024-11-18 00:27:51,685 - INFO - train_step=8760 loss=148.326 time=4.798
2024-11-18 00:27:55,842 - INFO - train_step=8800 loss=161.244 time=4.157
2024-11-18 00:28:25,900 - INFO - train_step=8800 avg_return=-201.141
2024-11-18 00:28:29,830 - INFO - train_step=8840 loss=202.146 time=33.988
2024-11-18 00:28:33,838 - INFO - train_step=8880 loss=137.829 time=4.008
2024-11-18 00:28:38,195 - INFO - train_step=8920 loss=156.633 time=4.356
2024-11-18 00:28:42,602 - INFO - train_step=8960 loss=132.508 time=4.407
2024-11-18 00:28:46,614 - INFO - train_step=9000 loss=129.067 time=4.012
2024-11-18 00:29:17,198 - INFO - train_step=9000 avg_return=-223.136
2024-11-18 00:29:20,942 - INFO - train_step=9040 loss=141.864 time=34.328
2024-11-18 00:29:24,990 - INFO - train_step=9080 loss=132.532 time=4.048
2024-11-18 00:29:29,292 - INFO - train_step=9120 loss=144.836 time=4.302
2024-11-18 00:29:33,624 - INFO - train_step=9160 loss=155.359 time=4.332
2024-11-18 00:29:37,607 - INFO - train_step=9200 loss=129.014 time=3.982
2024-11-18 00:30:07,582 - INFO - train_step=9200 avg_return=-205.850
2024-11-18 00:30:11,186 - INFO - train_step=9240 loss=136.939 time=33.580
2024-11-18 00:30:15,297 - INFO - train_step=9280 loss=133.302 time=4.111
2024-11-18 00:30:19,666 - INFO - train_step=9320 loss=124.614 time=4.369
2024-11-18 00:30:23,955 - INFO - train_step=9360 loss=126.582 time=4.289
2024-11-18 00:30:28,418 - INFO - train_step=9400 loss=132.879 time=4.463
2024-11-18 00:30:59,089 - INFO - train_step=9400 avg_return=-212.115
2024-11-18 00:31:02,929 - INFO - train_step=9440 loss=133.678 time=34.512
2024-11-18 00:31:07,234 - INFO - train_step=9480 loss=108.387 time=4.304
2024-11-18 00:31:11,310 - INFO - train_step=9520 loss=109.151 time=4.077
2024-11-18 00:31:15,434 - INFO - train_step=9560 loss=133.925 time=4.124
2024-11-18 00:31:19,788 - INFO - train_step=9600 loss=115.242 time=4.354
2024-11-18 00:31:50,303 - INFO - train_step=9600 avg_return=-235.111
2024-11-18 00:31:54,084 - INFO - train_step=9640 loss=136.984 time=34.296
2024-11-18 00:31:58,355 - INFO - train_step=9680 loss=117.734 time=4.272
2024-11-18 00:32:02,524 - INFO - train_step=9720 loss=129.059 time=4.168
2024-11-18 00:32:06,611 - INFO - train_step=9760 loss=163.124 time=4.087
2024-11-18 00:32:11,078 - INFO - train_step=9800 loss=142.710 time=4.468
2024-11-18 00:32:41,221 - INFO - train_step=9800 avg_return=-195.461
2024-11-18 00:32:45,331 - INFO - train_step=9840 loss=111.974 time=34.252
2024-11-18 00:32:49,425 - INFO - train_step=9880 loss=122.812 time=4.095
2024-11-18 00:32:53,543 - INFO - train_step=9920 loss=118.997 time=4.118
2024-11-18 00:32:57,682 - INFO - train_step=9960 loss=121.677 time=4.139
2024-11-18 00:33:01,943 - INFO - train_step=10000 loss=108.128 time=4.261
2024-11-18 00:33:32,279 - INFO - train_step=10000 avg_return=-216.713
2024-11-18 00:33:32,279 - INFO - total_time=2595.532
2024-11-18 00:33:32,279 - INFO - saving, checkpointPath_toSave=./result/DaisoSokcho_TD3_1117_234949/model
2024-11-18 00:33:32,280 - INFO - Checkpoint available: ./result/DaisoSokcho_TD3_1117_234949/model/ckpt-10000
Traceback (most recent call last):
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 782, in _restore_from_tensors
    assigned_variable = shape_safe_assign_variable_handle(
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 314, in shape_safe_assign_variable_handle
    shape.assert_is_compatible_with(value_tensor.shape)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py", line 1384, in assert_is_compatible_with
    raise ValueError("Shapes %s and %s are incompatible" % (self, other))
ValueError: Shapes (256,) and (256, 1) are incompatible

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/soh/works/tf/try_tf_agents/play.py", line 663, in <module>
  File "/home/soh/works/tf/try_tf_agents/game.py", line 88, in run
    train_checkpointer = common.Checkpointer(
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tf_agents/utils/common.py", line 1075, in __init__
    self._load_status = self._checkpoint.restore(
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py", line 2707, in restore
    status = self.read(save_path, options=options)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py", line 2570, in read
    result = self._saver.restore(save_path=save_path, options=options)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py", line 1479, in restore
    checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root,
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py", line 62, in restore
    restore_ops = self._restore_descendants(reader)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/restore.py", line 463, in _restore_descendants
    current_position.checkpoint.restore_saveables(
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/checkpoint.py", line 379, in restore_saveables
    registered_savers).restore(self.save_path_tensor, self.options)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py", line 499, in restore
    restore_ops = restore_fn()
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/checkpoint/functional_saver.py", line 467, in restore_fn
    ret = restore_fn(restored_tensors)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py", line 747, in _restore_from_tensors
    return saveable_object_to_restore_fn(self.saveables)(restored_tensors)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py", line 784, in _restore_from_tensors
    restore_ops[saveable.name] = saveable.restore(
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/training/saving/saveable_object_util.py", line 602, in restore
    ret = restore_fn(restored_tensor_dict)
  File "/home/soh/tf_venv/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 785, in _restore_from_tensors
    raise ValueError(
ValueError: Received incompatible tensor with shape (256, 1) when attempting to restore variable with shape (256,) and name Adam/m/CriticNetwork/joint_mlp/dense0/bias:0.
WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
2024-11-18 00:33:32,481 - WARNING - Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).save_counter
2024-11-18 00:33:32,481 - WARNING - Value in checkpoint could not be found in the restored object: (root).save_counter
